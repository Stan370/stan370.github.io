<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>StanBlog</title>
  
  
  <link href="https://stan370.github.io/atom.xml" rel="self"/>
  
  <link href="https://stan370.github.io/"/>
  <updated>2025-08-01T17:10:15.073Z</updated>
  <id>https://stan370.github.io/</id>
  
  <author>
    <name>Stan ke</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Not Enough RAM! Gemma3n vs Qwen3 on 16Gb device Test, Building My Private AI Assistant</title>
    <link href="https://stan370.github.io/2025/08/02/LLM-Finetune/"/>
    <id>https://stan370.github.io/2025/08/02/LLM-Finetune/</id>
    <published>2025-08-01T16:45:54.000Z</published>
    <updated>2025-08-01T17:10:15.073Z</updated>
    
    <content type="html"><![CDATA[<p>Running large language models like Gemma 3 on a Mac mini M4 with only 16GB of RAM quickly forced me to confront the hard limits of local inference. Initially, I tried running the 12B quantized GGUF models via Ollama, but kept hitting 500 errors—turns out, even Q4_0 quantization wasn’t enough to fit the model into available memory. Digging deeper, I realized that most of the 16GB RAM was already claimed by macOS and background services, leaving barely 6–7GB free for inference.</p><p>Instead of forcing it, I shifted strategy: I profiled my system memory using vm_stat, trimmed background processes, and tested multiple quantization levels (Q4, Q5, even Q8) across models. Still, running 12B remained unstable. The breakthrough came when I discovered the MLX community’s Apple-optimized versions of Gemma.<br>These use Metal-backed GPU acceleration and memory-efficient formats like int4, making it possible to run 7B and even 12B models smoothly on the same hardware. By choosing the right quantization and inference backend (MLX over GGUF), I found a setup that balances speed, memory, and model capability, all locally on Apple Silicon.</p><p>So this week, I went full mad-scientist mode trying to pick the <strong>best model to finetune</strong> for a secure, local, codable chatbot experience. The contenders? <strong>Gemma 3B/7B</strong> and <strong>Qwen3-7B/8B</strong>. My goals were clear:</p><ul><li>Must run on my Mac mini (M4, 16GB RAM)</li><li>Must respond like a helpful dev agent — not lobotomized</li><li>Must be <strong>finetunable</strong> (via LoRA or QLoRA, ideally)</li><li>Must support <strong>private data integration</strong> (RAG or post-training)</li><li>Must be able to <strong>code</strong>, explain, and assist</li></ul><p>This document details my exploration of large language models, including my experiments with quantization and fine-tuning.</p><p><strong>Phase 0: Qwen3 vs. Gemma3 – Which to Choose?</strong></p><p>Simply put, Qwen3 (especially Qwen3-8B) performs better with instruction tuning – it has a more flexible language style and answers feel more “human.” Gemma3 is more akin to a Google-led team,<br>with a cleaner architecture and a stronger focus on research, making it ideal for DIY projects. However, the default base version doesn’t chat at all; you need to train it yourself or select a<br>version with an “it” suffix.</p><p><strong>The key takeaway here is: a bad model isn’t necessarily a bad model – it’s often just under-trained.</strong></p><p><strong>Phase 1: What is DeepSeek Abliteration and Why Does it Work?</strong></p><p>Recently, DeepSeek pulled off a clever move: they used the chain-of-thought output from their large model, DeepSeek-R1-0528, to distill Qwen3-8B. This resulted in a new model:</p><p>DeepSeek-R1-0528-Qwen3-8B-GGUF</p><p>Technically, it’s a fine-tuned branch of Qwen3, optimized through DeepSeek’s R1 method.</p><p>Models like:</p><ul><li>LLaMA3-Instruct</li><li>MythoMax / Hermes2</li><li>OpenChat 3.5</li></ul><p>fall into the same category – they use custom SFT (Supervised Fine-Tuning) data and RLHF (Reinforcement Learning from Human Feedback) / Preference Tuning to train base models into specific<br>behaviors.</p><p><strong>Example:</strong></p><p>Prompt: “Please write a Python function to determine if a string is a palindrome.”</p><ul><li>Qwen3-8B-Base: Outputs a lot of explanations, but no code.</li><li>DeepSeek Abliterated Qwen3-8B: Directly provides the function body, test cases, and an explanation of why.</li></ul><p><strong>This demonstrates the power of abliteration – it re-teaches a previously cautious model to think and output complete code logic.</strong></p><p><strong>Phase 2: Technical Deep Dive into Model Quantization (Especially for Local Deployment)</strong></p><p>If you’re using a Mac mini or a laptop with 32GB of memory or less, quantization is a topic you can’t ignore.</p><p><strong>What is Base Model Quantization?</strong></p><p>Base models are the original, un-instruction-tuned large models, having undergone massive self-supervised training. Quantization is the process of compressing the float16/32 weights into int4,<br>int8, etc. formats.</p><table><thead><tr><th>Model Size</th><th>Precision</th><th>Memory Usage</th><th>Inference Speed</th></tr></thead><tbody><tr><td>FP16</td><td>High</td><td>High</td><td>Slow</td></tr><tr><td>Q4_0</td><td>Medium-Low</td><td>Very Low</td><td>Fast</td></tr><tr><td>Q4_K_M</td><td>Medium-High</td><td>Low</td><td>Fast</td></tr><tr><td>Q8_0</td><td>High</td><td>Medium-High</td><td>Slightly Slow</td></tr></tbody></table><h2 id="Compare">Compare</h2><table><thead><tr><th>模型</th><th>大小</th><th>RAM 需求</th><th>TPS</th><th>中文能力</th><th>适合</th></tr></thead><tbody><tr><td>Gemma-3n E4B Q4_K_M</td><td>~4B</td><td>&lt;6GB</td><td>✅ 快</td><td>一般</td><td>本地日常使用、agent</td></tr><tr><td>Qwen3-14B Q4_K_M</td><td>~14B</td><td>13–16GB+</td><td>❌ 慢</td><td>很强</td><td>离线高质量推理，慢也能忍</td></tr><tr><td>Qwen1.5-7B Q4_K_M</td><td>~7B</td><td>7–9GB</td><td>⚠ 中</td><td>强</td><td>折中选择</td></tr></tbody></table><p>Therefore, when deploying on Ollama, llama.cpp, or mlc-llm, choose the appropriate GGUF version – Q4_K_M and Q8_0 offer a good balance.</p><p><strong>Phase 3: Understanding the Model Repository Structure (Using Qwen as an Example)</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Qwen/Qwen3-8B-Base</span><br><span class="line">├── Adapters (8)</span><br><span class="line">├── Finetunes (80)</span><br><span class="line">├── Merges (3)</span><br><span class="line">└── Quantizations (30)</span><br></pre></td></tr></table></figure><p><strong>Interpretation:</strong></p><ul><li><strong>Base:</strong> The original model.</li><li><strong>Adapters:</strong> LoRA (Low-Rank Adaptation) fine-tuning modules.</li><li><strong>Finetunes:</strong> Full or mixed fine-tuning versions.</li><li><strong>Merges:</strong> Weight combinations from multiple finetunes.</li><li><strong>Quantizations:</strong> Quantized format versions (like GGUF).</li></ul><hr><h2 id="Benchmarks-Tradeoffs-—-Qwen3-vs-Gemma3">Benchmarks &amp; Tradeoffs — Qwen3 vs Gemma3</h2><p>Let’s cut to it: <strong>Qwen3</strong> models are generally more <em>chatty</em>, multilingual, with better instruction tuning (especially for their Chat versions). But <strong>Gemma3</strong> has some architectural advantages, like being more <strong>open</strong>, more compact, and <strong>Google Research-backed</strong>.</p><p>But here’s where it gets spicy — <strong>Gemma3 Base</strong> is not finetuned for chat out-of-the-box. Same with Qwen3 Base. So if you’re not careful, you’ll think they “suck” when in reality, they’re just <em>raw</em>. The value is in finetuning them <em>your way</em>.</p><p>I tried running:</p><ul><li><code>gemma-3b-it-Q4_K_M</code> (int4 quant via GGUF)</li><li><code>qwen3-8b-base-Q4_K_M</code></li><li><code>deepseek-moe-16x1.3b</code> just for fun</li></ul><p>Load times were fine. But when asked to “write a function to parse JSON,” only Qwen3 understood my vague prompt. Gemma3 gave up like it was trained on StackOverflow flags.</p><hr><p>I stumbled on a distilled model called:</p><blockquote><p><code>DeepSeek-R1-0528-Qwen3-8B-GGUF</code></p></blockquote><p>This is <strong>Qwen3-8B Base</strong>, post-trained using chain-of-thought data from DeepSeek’s raw model. It’s sharper, more logical, and yes, slightly deranged in a good way. I ran some evals:</p><p><strong>Prompt</strong>: “Implement a WebSocket server in Go”<br><strong>Vanilla Qwen3-8B-Base</strong>: Half answer, talks about goroutines, no code.<br><strong>Abliterated DeepSeek-Qwen3-8B</strong>: Full server, with error handling, log statements, and config options.</p><p>Conclusion? Abliteration works — if your model is overaligned, abliterate it with purpose.</p><hr><h2 id="Can-It-Run-Locally-and-Privately">Can It Run Locally and Privately?</h2><p>Yes. With <strong>llama.cpp</strong>, <strong>ggml/gguf</strong> formats, and <strong>OpenWebUI</strong>, you can run a fully uncensored assistant on macOS. For better UX and parameter tweaking (temperature, top_p, stop words), I used OpenWebUI and KoboldCpp.</p><p>Settings that worked for me:</p><ul><li>Temperature: <code>0.7</code></li><li>Top_p: <code>0.95</code></li><li>Context length: <code>4096</code> (up to 8192 if you dare)</li></ul><p>This way, the model never calls OpenAI. Everything is <strong>local</strong>, encrypted, and yours. You can even hook it into a vector DB (like Chroma or Milvus) for <strong>RAG-style knowledge injection</strong>.</p><ol><li>First, select the appropriate GGUF (recommend Q4_K_M or Q8_0).</li><li>Then, consider whether you want a specific finetune type (e.g., chat, coder, instruction).</li></ol><p>If the model is base + adapter, ensure your framework supports adapters (e.g., llama.cpp &gt; v0.2).</p><hr><p>Here’s what I ended up running:</p><ul><li><strong>Base</strong>: <code>DeepSeek-R1-0528-Qwen3-8B-Q4_K_M</code></li><li><strong>Frontend</strong>: OpenWebUI or custom Vite/React wrapper</li><li><strong>Backend</strong>: llama.cpp compiled for Metal (M4 optimized)</li><li><strong>Memory Budget</strong>: ~12GB RAM peak for Qwen3-8B</li><li><strong>Custom Finetune</strong>: Alpaca-style SFT on coding prompts (still training…)</li></ul><hr><h2 id="Tips-for-Future-Hackers">Tips for Future Hackers</h2><ol><li><p>If it says “chat” and acts dumb, it’s probably <strong>over-aligned</strong>. Post-train it.</p></li><li><p>Look into <strong>abliteration techniques</strong> — distilled thought traces are more valuable than safety data.</p></li><li><p>Don’t waste time with RLHF-ed-only models if you’re building a <strong>coder</strong> assistant.</p></li><li><p>Use <code>gguf</code> formats for performance, especially on Apple Silicon. Compile with Metal backend.</p></li><li><p>Learn to <em>smell</em> lobotomized models. They always avoid certain topics, answer vaguely, and fail to write full functions.</p></li><li><p>Local deployment isn’t complicated; quantization and Ollama can handle it.</p></li><li><p>Don’t let excessive alignment limit your model’s capabilities.</p></li><li><p>If you’re looking for privacy, security, and customization, local LLM is the only solution.</p></li></ol><h2 id="Coming-Next-Local-LoRA-fine-tune-and-Gemma3n-image-and-audio-test">Coming Next: Local LoRA fine tune and Gemma3n image and audio test</h2><p>I want to see how small I can go and still retain quality coding assistance. Spoiler: Gemma3-2B already shows promise with some light training, but hallucination risk is high.</p><p>—</p><p>That’s it. From confusion to abliteration to building my private dev assistant, this journey taught me one thing: <strong>you don’t need OpenAI</strong> to build a good coder chatbot. You just need good data, good models, and the will to destroy and rebuild.</p><p>If you’re curious or want to try abliteration yourself, ping me. I’ll share my LoRA configs, ggml hacks, and more.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Running large language models like Gemma 3 on a Mac mini M4 with only 16GB of RAM quickly forced me to confront the hard limits of local </summary>
      
    
    
    
    
    <category term="LLM" scheme="https://stan370.github.io/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>并发效率与多线程安全</title>
    <link href="https://stan370.github.io/2025/07/28/Concurrency/"/>
    <id>https://stan370.github.io/2025/07/28/Concurrency/</id>
    <published>2025-07-28T07:56:18.000Z</published>
    <updated>2025-07-28T07:56:26.830Z</updated>
    
    <content type="html"><![CDATA[<p>why you need to learn 并发与多线程?<br>最直观的服务器处理多客户端访问的方式，就是为每个连接创建一个线程，或者更早期操作系统里甚至是一个进程。虽然线程比进程更轻量，切换成本也更低，但每连接一个线程在并发量大时仍会面临两个问题：</p><p>线程创建/销毁有系统开销（malloc stack、context switch）。</p><p>线程是稀缺资源，系统线程数有上限（如 Linux 默认 1024~65535）。</p><p>所以，现代服务端架构更倾向于使用线程池来复用线程资源。线程池中每个线程从任务队列中取任务处理，避免了反复创建/销毁的开销。</p><p>但线程池引入后面临另一个问题：I/O 阻塞会浪费线程资源。如果一个线程执行 read(socket) 被阻塞，而连接上没有数据，那么整个线程就“卡住”了，不能服务其他连接。</p><p>为了避免这个问题，我们可以将 socket 设置为非阻塞模式。这样 read() 不会阻塞，而是立即返回，如果没有数据，就返回错误码 EAGAIN。线程就可以在用户空间“轮询”所有 socket。</p><p>但这种方式会导致高 CPU 占用，尤其在连接数多时效率低。</p><p>所以引入了 I/O 多路复用技术（如 select、poll、epoll），它允许一个线程通过一个系统调用（如 epoll_wait）同时监听多个连接的状态，一旦某些连接可读（或可写），内核就通知我们“这些连接准备好了”，我们再去 read()，避免了不必要的轮询。</p><p>这就是像 Nginx、Redis、Node.js、netty 等高并发服务采用的基础模式：I/O 多路复用 + 非阻塞 I/O + 事件驱动模型。Reactor模式称为反应器模式或应答者模式，是基于事件驱动的设计模式，拥有一个或多个并发输入源，有一个服务处理器和多个请求处理器，服务处理器会同步的将输入的请求事件以多路复用的方式分发给相应的请求处理器。<br>单 Reactor 单线程（Redis）<br>所有 I/O + 业务逻辑都在一个线程中串行完成</p><p>简单、性能好（但业务处理不能太重）</p><p>单 Reactor 多线程（Nginx）<br>Reactor 只负责监听/调度，业务逻辑交给线程池处理</p><p>主从 Reactor（Netty）<br>主 Reactor 接收连接</p><p>从 Reactor 负责具体数据读写</p><p>分离 accept 和 IO 阶段，提高可扩展性<br>Proactor 是把任务交给操作系统 / runtime，让它完成后通知你处理结果</p><p>当你需要让程序快速处理大量数据或高频率的任务时，并发和多线程能帮你充分发挥多核处理器的优势。这就像是给你的应用装上了多台引擎，使得任务处理更加迅速高效。掌握并发和多线程，可以让你更高效地使用系统资源，比如CPU和内存。这就像是你在分配资源时，能做到心中有数，不让系统资源闲置浪费。<br>避免常见陷阱：竞争条件、死锁和资源匮乏等线程问题在并发编程中很常见。对这些问题的深入理解有助于开发人员编写避免此类陷阱的代码，从而开发出更强大、更可靠的软件。</p><p>并发性（concurrency）是指程序、算法或问题的不同部分或单元可以在同一时间段内无序地在CPU上执行，但不会影响最终结果的能力。换句话说，并发性允许程序的不同部分同时进行，但它们的执行顺序可以是灵活的，只要最终的结果不受影响。</p><p>并发Concurrent：无论上一个开始执行的任务是否完成，当前任务都可以开始执行 （也就是说，A B 顺序执行的话，A 一定会比 B 先完成，而并发执行则不一定。） 与可以一起执行的并行（parallel）相对的是不可以一起执行的串行（serial）</p><p>从宏观方面来说，并发就是同时进行多种时间，实际上，这几种时间，并不是同时进行的，而是交替进行的，而由于CPU的运算速度非常的快，同一时间只有一个线程运行</p><p>并行：则是真正意义上的同时进行多种事情。这种只可以在多核CPU的基础上完成。</p><p>综上，并发与并行并不是互斥的概念，只是前者关注的是任务的抽象调度、后者关注的是任务的实际执行。而它们又是相关的</p><p>在并发编程中，可见性、原子性和有序性是指导并发程序正确性的重要概念，与上述三大问题（竞态条件、死锁和内存同步）密切相关。</p><p><strong>可见性（Visibility）：</strong></p><p>可见性指的是一个线程对共享变量的修改是否能够被其他线程立即观察到。在多线程环境中，由于CPU缓存、编译器优化等因素，一个线程对共享数据的修改可能不会立即被其他线程所感知，造成不一致的结果。<strong>通过合适的同步机制（如互斥锁、原子操作、内存屏障等）可以确保对共享变量的修改对其他线程是可见的，从而保证了程序的正确性。</strong></p><p><strong>原子性（Atomicity）：</strong></p><p>原子性是指一个操作要么完全执行，要么完全不执行，不存在中间状态。在并发环境中，多个线程可能同时访问同一个变量，当一个线程正在修改某个共享变量时，如果没有适当的同步机制，其他线程可能会读取到不一致的状态。使用原子操作或锁可以确保某个操作是原子的，即在执行过程中不会被中断或影响。</p><p>原子性操作在并发编程中至关重要，它确保了一组操作的<strong>不可分割性和中间状态的不可见性</strong>。通过使用基本类型的原子操作、锁机制、原子变量和数据库事务等技术，我们可以有效地避免竞态条件，确保数据的一致性和正确性。</p><p><strong>有序性（Ordering）：</strong></p><p>有序性指的是程序中的操作在执行时保持其指令顺序，不会出现乱序执行的情况。在现代CPU中，由于指令重排优化，CPU 可能会重新排序指令以提高性能。对于并发编程来说，这可能会导致线程之间操作的执行顺序与代码编写的顺序不一致。使用内存屏障（Memory Barriers）或同步机制可以确保指令不会被重排，从而保持操作的有序性。</p><p><strong>关系：</strong></p><ul><li><strong>竞态条件</strong>通常与可见性和原子性有关。竞态条件可能发生在多个线程对共享资源的读写操作上，如果没有适当的同步机制来确保可见性和原子性，就可能导致不确定的结果。</li><li><strong>死锁</strong>可能与有序性有关，当多个线程按照不同的顺序获取锁或资源时，可能会产生死锁。合理地规划资源获取顺序可以避免死锁的发生。</li><li><strong>内存同步问题</strong>与可见性、原子性和有序性密切相关。解决内存同步问题需要确保对共享变量的修改对其他线程是可见的（可见性）、原子操作能够保证操作的完整性（原子性），以及指令执行的有序性。</li></ul><h3 id="同步问题">同步问题</h3><p>**线程同步（Thread Synchronization）**是指在多线程编程中，为了避免多个线程之间对共享资源的并发访问引发的问题（如竞争条件、死锁等），需要采取措施来协调线程的执行，以确保线程之间的操作按照期望的顺序进行。线程同步的目的是保证多个线程能够有序地访问共享资源，避免数据的不一致和错误。</p><h2 id="常见的线程同步机制包括：">常见的线程同步机制包括：</h2><ol><li><p><strong>互斥锁（Mutex）：</strong> 互斥锁是一种最基本的线程同步机制，用于保护共享资源免受并发访问。一次只有一个线程能够持有互斥锁，其他线程必须等待直到锁被释放。这样可以防止多个线程同时修改同一资源。</p></li><li><p><strong>信号量（Semaphore）：</strong> 信号量是一种计数器，用于控制多个线程对共享资源的访问。它可以用来<strong>限制同时访问资源的线程数量</strong>，也可以用于线程间的通信。</p></li><li><p><strong>条件变量（Condition Variable）：</strong> 条件变量用于在线程之间传递信息，以及在某些条件满足时唤醒等待的线程。它通常和互斥锁一起使用，以实现更复杂的同步需求。</p></li><li><p><strong>读写锁（Read-Write Lock）：</strong> 读写锁允许多个线程同时读取共享资源，但只允许一个线程进行写操作。这可以提高读操作的并发性能。多个读线程可以同时获得锁，写线程会阻塞其他写线程和读线程。<strong>乐观锁</strong></p></li><li><p><strong>原子操作（Atomic Operations）：</strong> 原子操作是不可中断的操作，可以在单个指令中完成。它们可以用于保护简单的共享数据结构，避免竞争条件。</p></li><li><p><strong>自旋锁</strong>： 自旋锁与互斥量类似，但它不使线程进入阻塞态；而是在获取锁之前一直占用CPU，处于忙等（自旋）状态。</p></li><li><p><strong>屏障（Barrier）：</strong> 屏障用于等待多个线程都达到某个点，然后再继续执行后续操作，常用于需要多个线程协同完成的任务。</p></li><li><p><strong>乐观锁</strong>：乐观锁是一种假设在大多数情况下不会发生冲突的锁。它不会在访问共享资源之前获取锁，而是在更新共享资源时进行检查。如果检测到其他线程已经更新了共享资源，那么当前线程可能需要重试或者采取其他措施来处理冲突。乐观锁通常用于多读的场景，可以提高吞吐量。</p></li><li><p><strong>悲观锁</strong>：悲观锁是一种假设在大多数情况下会发生冲突的锁。它在访问共享资源之前获取锁，并假定其他线程会干扰。悲观锁通常用于写入操作，以确保在写入共享资源时不会发生冲突。</p></li></ol><p>乐观锁的实现方式主要有两种：CAS机制和版本号机制。</p><p>对于ABA问题，比较有效的方案是引入版本号，内存中的值每发生一次变化，版本号都+1；在进行CAS操作时，不仅比较内存中的值，也会比较版本号，只有当二者都没有变化时，CAS才能执行成功。Java中的AtomicStampedReference类便是使用版本号来解决ABA问题的。</p><p>除了CAS，版本号机制也可以用来实现乐观锁。版本号机制的基本思路是在数据中增加一个字段version，表示该数据的版本号，每当数据被修改，版本号加1。当某个线程查询数据时，将该数据的版本号一起查出来；当该线程更新数据时，判断当前版本号与之前读取的版本号是否一致，如果一致才进行操作。</p><p>临界区 对临界资源进行访问的那段代码称为临界区。</p><p>为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。</p><p>// entry section // critical section; // exit section</p><ol><li>同步与互斥 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。 互斥：多个进程在同一时刻只有一个进程能进入临界区。</li><li>信号量 信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。</li></ol><p>down : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0； up ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。 down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。</p><p>如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。</p><p><strong>互斥锁</strong></p><p>1严格轮换法 加入锁变量 2 Peterson算法 进程0出临界区后进程1才会离开忙等</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">typedef int semaphore; semaphore mutex = <span class="number">1</span>; </span><br><span class="line"><span class="keyword">void</span> <span class="title function_">P1</span>(<span class="params"></span>) { <span class="title function_">down</span>(&amp;mutex);</span><br><span class="line"> <span class="comment">// 临界区 up(&amp;mutex); }</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">P2</span>(<span class="params"></span>) { <span class="title function_">down</span>(&amp;mutex); <span class="comment">// 临界区 up(&amp;mutex); } 使用信号量实现生产者-消费者</span></span><br></pre></td></tr></table></figure><p>问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。</p><p>因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。</p><p>为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。</p><p>注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。</p><h1>异步编程</h1><p>异步（Asynchronous）：异步编程是一种处理并发操作的方式，其中不需要等待一个操作完成才能执行下一个操作。在异步编程中，一个操作的启动不会阻塞程序的其他部分，<strong>而是允许程序继续执行其他操作，之后当异步操作完成时，程序会得到通知或回调。<strong>这种方式可以提高程序的响应性和并发性。但</strong>由于资源有限，进程的执行不是一贯到底的，这就是进程的异步性。 异步和同步是相对的，同步就是顺序执行，执行完一个再执行下一个，需要等待、协调运行</strong></p><p>“异步阻塞” 意味着可能存在某些情况下，虽然使用了异步编程的方式，但在某些时刻程序仍然被阻塞，等待某些操作的完成。这种情况可能发生在以下情形下：</p><ul><li>某些异步操作内部使用了同步操作，导致当前线程在等待这些同步操作完成时被阻塞。</li><li>异步操作之间存在依赖关系，某个异步操作必须等待另一个异步操作完成后才能执行。</li><li>程序中的某些部分仍然采用同步编程方式，而不是全面采用异步编程。</li></ul><p>要避免异步操作中的阻塞，通常需要使用异步编程框架和模式，以确保在异步操作中也不会阻塞程序的其他部分。这包括使用回调、Promise、异步/await等机制来管理异步操作的执行顺序和依赖关系，从而实现真正的非阻塞异步编程。</p><p>eg.       我们以经典的读取文件的模型举例。（对操作系统而言，所有的输入输出设备都被抽象成文件。）</p><p>在发起读取文件的请求时，应用层会调用系统内核的 I/O 接口。</p><p>如果应用层调用的是阻塞型 I/O，那么在调用之后，应用层即刻被挂起，一直出于等待数据返回的状态，直到系统内核从磁盘读取完数据并返回给应用层，应用层才用获得的数据进行接下来的其他操作。</p><p>如果应用层调用的是非阻塞 I/O，那么调用后，系统内核会立即返回（虽然还没有文件内容的数据），应用层并不会被挂起，它可以做其他任意它想做的操作。（至于文件内容数据如何返回给应用层，这已经超出了阻塞和非阻塞的辨别范畴。）</p><p>阻塞和非阻塞解决了应用层等待数据返回时的状态问题，那系统内核获取到的数据到底如何返回给应用层呢？是否是阻塞还是非阻塞，<strong>关注的是接口调用（发出请求）后等待数据返回时的状态。</strong></p><p>同步还是异步，<strong>关注的是任务完成时消息通知的方式。由调用方盲目主动问询的方式是同步调用，由被调用方主动通知调用方任务已完成的方式是<a href="https://www.zhihu.com/search?q=%E5%BC%82%E6%AD%A5%E8%B0%83%E7%94%A8&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2222707398%22%7D">异步调用</a>。</strong></p><h2 id="JAVA中的线程安全">JAVA中的线程安全</h2><p><strong>Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。</strong></p><p>Java提供了volatile关键字来<strong>保证可见性</strong>。当一个共享变量被volatile修饰时，它会保证修改的值会<strong>立即</strong>被更新到<strong>主存</strong>，当有其他线程需要读取时，它会去内存中读取新值。关闭缓存，<strong>（从Load到Store）是不安全的，中间如果其他的CPU修改了值将会丢失。下面的测试代码可以实际测试voaltile的自增没有原子性</strong>（原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。</p><p><strong>编译器层面 和CPU层面都提供了一套内存屏障来禁止重排序的指令</strong>，编码人员需要识别存在数据依赖的地方加上一个内存屏障指令，那么此时计算机将不会对其进行指令优化。</p><p>在多线程环境下，确保代码正确同步和避免重排序reording是至关重要的。Java 提供了各种机制来帮助程序员在多线程场景下明确表达数据依赖和避免指令重排序：</p><ol><li><strong>volatile 关键字：</strong> 使用 <strong><code>volatile</code></strong> 关键字可以确保变量的可见性，并防止编译器和处理器对被 <strong><code>volatile</code></strong> 修饰的变量进行重排序。它适用于简单的变量操作，但不能保证原子性。</li><li><strong>synchronized 关键字：</strong> 使用 <strong><code>synchronized</code></strong> 关键字可以确保代码块在同一时刻只能被一个线程执行，从而保证了线程安全性和避免了重排序。</li><li><strong>Lock 接口及其实现类：</strong> Java 提供了 <strong><code>Lock</code></strong> 接口及其实现类，如 <strong><code>ReentrantLock</code></strong>，允许更灵活地进行锁定和解锁，并提供了比 <strong><code>synchronized</code></strong> 更多的特性。</li><li><strong>Atomic 类：</strong> Java 提供了一系列原子操作类，如 <strong><code>AtomicInteger</code></strong>、<strong><code>AtomicBoolean</code></strong> 等，用于在不使用锁的情况下执行原子操作。</li></ol><ul><li><p><strong>Happens-Before 规则：</strong> Java 内存模型定义了 Happens-Before 规则，规定了一系列操作的顺序，以保证多线程环境下的一致性和可预测性。程序员可以利用这个规则来确保代码正确性。</p><p>Java 内存模型下一共有 8 条 happens-before 规则，如果线程间的操作无法从如下几个规则推导出来，那么它们的操作就没有顺序性保障，虚拟机或者操作系统就能随意地进行重排序，从而可能会发生并发安全问题。</p><ul><li>程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。</li><li>管程锁定规则（Monitor Lock Rule）：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里必须强调的是同一个锁，而 “后面” 是指时间上的先后顺序。</li><li>volatile 变量规则（Volatile Variable Rule）：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的 “后面” 同样是指时间上的先后顺序。</li><li>线程启动规则（Thread Start Rule）：Thread 对象的 start () 方法先行发生于此线程的每一个动作。</li><li>线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过 Thread.join () 方法结束、Thread.isAlive () 的返回值等手段检测到线程已经终止执行。</li><li>线程中断规则（Thread Interruption Rule）：对线程 interrupt () 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 Thread.interrupted () 方法检测到是否有中断发生。</li><li>对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize () 方法的开始。</li><li>传递性（Transitivity）：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那就可以得出操作 A 先行发生于操作 C 的结论。</li></ul></li></ul><ol><li><strong>线程安全的集合类：</strong> Java 提供了一些线程安全的集合类，如 <strong><code>ConcurrentHashMap</code></strong>、<strong><code>CopyOnWriteArrayList</code></strong> 等，可以在多线程环境下安全地进行操作。</li><li><strong>volatile 的双重检查锁定模式（Double-Checked Locking）：</strong> 在需要延迟初始化对象的情况下，使用双重检查锁定模式结合 <strong><code>volatile</code></strong> 关键字，可以确保线程安全性。</li></ol><p>ScheduledExecutorService的主要作用就是可以将定时任务与线程池功能结合使用</p><ul><li><p>Java中存在两种锁机制：synchronized和Lock，Lock接口及其实现类是JDK5增加的内容</p><p><strong>synchronized:</strong>  Java的关键字，在jvm层面上                 <strong>Lock:</strong> 是一个接口</p><p><strong>用法</strong></p><p><strong>synchronized:</strong> 在需要同步的对象中加入此控制，synchronized可以加在方法上，也可以加在特定代码块中，括号中表示需要锁的对象。</p><p><strong>Lock:</strong> 一般使用<strong>ReentrantLock</strong>类做为锁。在加锁和解锁处需要通过lock()和unlock()显示指出。所以一定要在finally块中写unlock()以防死锁。</p><p><strong>锁的释放</strong></p><p><strong>synchronized:</strong> 1、以获取锁的线程执行完同步代码，释放锁 2、线程执行发生异常，jvm会让线程释放锁。在发生异常时候会自动释放占有的锁，因此不会出现死锁</p><p><strong>Lock:</strong> 在finally中必须释放锁，不然容易造成线程死锁。必须手动unlock来释放锁，可能引起死锁的发生</p><p><strong>锁的获取</strong></p><p><strong>synchronized:</strong> 假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待</p><p><strong>Lock:</strong> 分情况而定，Lock有多个锁获取的方式，大致就是可以尝试获得锁，线程可以不用一直等待(可以通过tryLock判断有没有锁)</p><p><strong>锁的状态</strong>         <strong>synchronized:</strong> 无法判断                           <strong>Lock:</strong> 可以判断</p><ul><li>Lock可以提高多个线程进行读操作的效率。（可以通过readwritelock实现读写分离）</li><li><strong>在资源竞争不是很激烈的情况下，Synchronized的性能要优于ReetrantLock，但是在资源竞争很激烈的情况下，Synchronized的性能会下降几十倍，但是ReetrantLock的性能能维持常态；</strong></li><li>ReentrantLock提供了多样化的同步，比如有时间限制的同 步，可以被Interrupt的同步（synchronized的同步是不能Interrupt的）等。在资源竞争不激烈的情形下，性能稍微比synchronized差点点。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而ReentrantLock确还能维持常态。公平锁机制。什么叫公平锁呢？也就是在锁上等待时间最长的线程将获得锁的使用权。通俗的理解就是谁排队时间最长谁先执行获取锁。</li></ul><p>② 是否可手动释放<br>synchronized 不需要用户去手动释放锁，synchronized 代码执行完后系统会自动让线程释放对锁的占用； ReentrantLock则需要用户去手动释放锁，如果没有手动释放锁，就可能导致死锁现象。一般通过lock()和unlock()方法配合try/finally语句块来完成，使用释放更加灵活。</p><p>③ 是否可中断<br>synchronized是不可中断类型的锁，除非加锁的代码中出现异常或正常执行完成； ReentrantLock则可以中断，可通过trylock(long timeout,TimeUnit unit)设置超时方法或者将lockInterruptibly()放到代码块中，调用interrupt方法进行中断。</p><p>④ 是否公平锁</p><p>所以公平和非公平的区别就是：线程执行同步代码块时，是否会去尝试获取锁。</p><p>**如果会尝试获取锁，那就是非公平的。如果不会尝试获取锁，直接进队列，再等待唤醒，那就是公平的。**synchronized为非公平锁 ReentrantLock则即可以选公平锁也可以选非公平锁，通过构造方法new ReentrantLock时传入boolean值进行选择，为空默认false非公平锁，true为公平锁。</p><p>可重入锁是指同一个线程如果首次获得了这把锁，那么因为它是这把锁的拥有者，因此 有权利再次获取这把锁</p><p>公平锁是等待锁的线程<strong>不会饿死。缺点是整体吞吐效率相对非公平锁要低</strong>，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。</p><p>非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。</p><p><strong>调度</strong></p><p><strong>synchronized:</strong> 使用Object对象本身的wait 、notify、notifyAll调度机制</p><p><strong>Lock:</strong> 可以使用Condition进行线程之间的调度</p><p><strong>底层实现</strong></p><p><strong>synchronized:</strong> 底层使用指令码方式来控制锁的，映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。当线程执行遇到<a href="https://www.zhihu.com/search?q=monitorenter%E6%8C%87%E4%BB%A4&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22180469207%22%7D">monitorenter指令</a>时会尝试获取内置锁，如果获取锁则锁计数器+1，如果没有获取锁则阻塞；当遇到monitorexit指令时锁计数器-1，如果计数器为0则释放锁。</p><p><strong>Lock:</strong> 底层是CAS乐观锁，依赖AbstractQueuedSynchronizer类，把所有的<a href="https://www.zhihu.com/search?q=%E8%AF%B7%E6%B1%82%E7%BA%BF%E7%A8%8B&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22180469207%22%7D">请求线程</a>构成一个CLH队列。而对该队列的操作均通过Lock-Free（CAS）操作。</p><p>关于ReentrantLock和CAS的关系：ReentrantLock是一个基于CAS的悲观锁，而不是乐观锁。ReentrantLock使用CAS操作来实现锁的获取和释放，但它的行为是悲观的，因为它要求线程在访问共享资源之前获得锁。CAS本身是一种乐观锁的实现方式，但ReentrantLock使用CAS来保证互斥性，因此它被归类为悲观锁。总的来说，乐观锁和悲观锁是两种不同的并发控制策略，它们在多线程环境下解决了竞争问题，但它们的使用场景和实现方式有所不同。 CAS是一种用于实现乐观锁的原子操作，而ReentrantLock是一种基于CAS的悲观锁。</p><ol><li><strong>乐观锁</strong>：乐观锁是一种假设在大多数情况下不会发生冲突的锁。它不会在访问共享资源之前获取锁，而是在更新共享资源时进行检查。如果检测到其他线程已经更新了共享资源，那么当前线程可能需要重试或者采取其他措施来处理冲突。乐观锁通常用于多读的场景，可以提高吞吐量。</li><li><strong>悲观锁</strong>：悲观锁是一种假设在大多数情况下会发生冲突的锁。它在访问共享资源之前获取锁，并假定其他线程会干扰。悲观锁通常用于写入操作，以确保在写入共享资源时不会发生冲突。</li></ol><p>乐观锁的实现方式主要有两种：CAS机制和版本号机制。</p><p>对于ABA问题，比较有效的方案是引入版本号，内存中的值每发生一次变化，版本号都+1；在进行CAS操作时，不仅比较内存中的值，也会比较版本号，只有当二者都没有变化时，CAS才能执行成功。Java中的AtomicStampedReference类便是使用版本号来解决ABA问题的。</p><p>除了CAS，版本号机制也可以用来实现乐观锁。版本号机制的基本思路是在数据中增加一个字段version，表示该数据的版本号，每当数据被修改，版本号加1。当某个线程查询数据时，将该数据的版本号一起查出来；当该线程更新数据时，判断当前版本号与之前读取的版本号是否一致，如果一致才进行操作。</p></li></ul><p>最经典的分布式锁是可重入的公平锁，可重入锁（Reentrant Lock）是一种特殊类型的锁，允许同一个线程多次获取同一个锁而不会导致死锁。这种锁可以多次被同一线程获取，而不会因为同一线程的重复获取而阻塞自己。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;why you need to learn 并发与多线程?&lt;br&gt;
最直观的服务器处理多客户端访问的方式，就是为每个连接创建一个线程，或者更早期操作系统里甚至是一个进程。虽然线程比进程更轻量，切换成本也更低，但每连接一个线程在并发量大时仍会面临两个问题：&lt;/p&gt;
&lt;p&gt;线程</summary>
      
    
    
    
    <category term="计算机科学" scheme="https://stan370.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="计算机基础" scheme="https://stan370.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="多线程" scheme="https://stan370.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>How blockchain evolves to a new world order?</title>
    <link href="https://stan370.github.io/2025/06/08/blockchain-overview/"/>
    <id>https://stan370.github.io/2025/06/08/blockchain-overview/</id>
    <published>2025-06-08T14:25:07.000Z</published>
    <updated>2025-06-10T09:51:10.491Z</updated>
    
    <content type="html"><![CDATA[<h1>A new world order</h1><p>In the world of crypto, few figures have shaped its philosophical and technical trajectory as deeply as Vitalik Buterin, the co-founder of Ethereum. Beyond the whitepaper that birthed the world’s most programmable blockchain, Vitalik’s prolific blog output over the years has become a canon for developers, economists, and visionaries in the decentralized ecosystem.<br>For builders—especially those designing agent platforms, decentralized governance models, or crypto-powered coordination systems—these writings form a strategic blueprint. Build systems that are not only redundant in infrastructure but also politically and logically anti-fragile. Consider multisig governance, on-chain voting, and modular designs.</p><p>Total Value Locked (TVL) on Ethereum stands at <strong>$61.3 billion</strong>, dwarfing competitors—Ethereum holds ~45% of DeFi capital versus Solana’s ~5% (<a href="https://defillama.com/chain/Ethereum">source</a>).</p><p>Liquid staking (LST) on Ethereum locks <strong>13.7 million ETH (~$34.4B)</strong>.</p><p>ETH chain records <strong>~$676K/day in fees</strong> and nearly <strong>$1 billion in 24-hour DEX volume</strong> (<a href="https://defillama.com/chain/Ethereum">source</a>).</p><p>See Vitalik’s recent blogs:<br><a href="https://vitalik.eth.limo/general/2024/05/17/decentralization.html">The near and mid-term future of improving Ethereum</a><br><a href="https://vitalik.eth.limo/general/2024/10/17/futures2.html">Possible futures of Ethereum, Part 2</a></p><p><strong>This scope matters.</strong></p><h2 id="Defi-hatched">Defi hatched</h2><p>Enabling bold scaling ideas and ecosystem coordination requires such scale. It’s the bedrock on which Vitalik’s decentralization blueprint stands.</p><p>These numbers matter not as vanity metrics but as hard evidence: much of what Vitalik Buterin proposes in his blog writings—modular scaling, credible neutrality, permissionless governance—depends on Ethereum sustaining this role as the settlement and security layer for global crypto coordination. When Vitalik speaks about “The Meaning of Decentralization,” he doesn’t just refer to network architecture but to the political and epistemic dimensions of control: who defines protocol values, who updates client software, and who can contest outcomes. That meaning only gains traction when backed by thousands of actively verifying nodes, diverse client implementations, and real capital at stake.</p><p>Projects like Uniswap and other DEXs didn’t just emerge spontaneously—they were incubated in a unique intersection of open research, early crypto capital, and public infrastructure built on Ethereum. Understanding how they were hatched and funded reveals the mechanics of permissionless innovation, the catalytic role of public goods, and the quiet but powerful function of narrative leverage.</p><p>Uniswap began as a Reddit comment by Vitalik Buterin in 2016, suggesting the idea of an automated market maker (AMM) based on constant product formulas. Hayden Adams, an unemployed mechanical engineer at the time, decided to implement the idea in 2017, teaching himself Solidity and building the protocol’s early version. He received a $65,000 grant from the Ethereum Foundation in 2018, which helped him finish v1. Notably, Uniswap was one of the first examples of a successful public good funded entirely by EF grants before a token existed.</p><p>That original grant served a catalytic role, but the real growth came when Uniswap launched its protocol and began attracting liquidity. Paradigm, one of crypto’s leading VC firms, later invested in Uniswap Labs, helping it scale from a pure protocol to a company with developers, designers, and BD capacity. Paradigm reportedly led a $11M Series A round in 2020. Still, even as a venture-backed company, Uniswap the protocol has remained free and open—anyone can fork the contracts and build on top. This public nature was essential to its early network effects.</p><p>The larger ecosystem of DEXs followed similar but slightly varied paths. Curve Finance, another AMM optimized for stablecoin swaps, was started by Michael Egorov, a physicist and software engineer. Unlike Uniswap, Curve focused early on tokenomics, launching the CRV token with an intricate governance and staking model. It began with relatively low initial funding, but quickly grew via liquidity mining, incentivizing users to provide capital.<br>So, the DeFi ecosystem was not built with the permission of capital allocators—it emerged from a combination of ideas freely shared, public infrastructure like Ethereum and IPFS, and mechanisms like grants, liquidity mining, and retroactive public goods funding. What makes it novel is not just the technology, but how the capital formation and innovation pipeline itself was decentralized.</p><h2 id="Philosophy-and-vision">Philosophy and vision</h2><p>When I look at his posts, I think this is common for <strong>geniuses</strong> - it’s not so much about being brilliant and solving whatever is at hand as it is a ton of hard work reading, writing (to clarify ideas) and brainstorm with others any thing that pops up in your head that may be relevant or applicable. There’s always something useful that comes out of it and eventually those things accumulate to what you, and others, iterate into working solutions.</p><p><img src="https://vitalik.eth.limo/images/end/cryptomap.drawio.png" alt="This map"> itself is an intentional 50/50 mix of idealism and “describing reality”. It’s intended to show four major constituencies of the ecosystem that can have a supportive and symbiotic relationship with each other. Many crypto institutions in practice are a mix of all four.</p><p>Each of the four parts has something key to offer to the machine as a whole:</p><p>Token holders and defi users contribute greatly to financing the whole thing, which has been key to getting technologies like consensus algorithms and zero-knowledge proofs to production quality.<br>Intellectuals provide the ideas to make sure that the space is actually doing something meaningful.<br>Builders bridge the gap and try to build applications that serve users and put the ideas into practice.<br>Pragmatic users are the people we are ultimately serving.</p><p>Remember that today’s blockchains are by definition developed by people with no prior blockchain experience. We all learned what we know from just digging into it.</p><p>So if you want to understand where blockchains are going, don’t start with whitepapers or Twitter threads. Look at Vitalik’s posts—but read them through the lens of what the data says. The writing is not a prediction. It’s a description of what’s already unfolding. If you’re building in Web3, the frontier is more than technical. It’s moral, economic, and social. Vitalik’s blog is not just a technical archive; it’s a guide to building a new kind of world. Read it not just as a reference—but as a call to action.</p><p>“The tools we build today encode the freedoms or limitations of tomorrow.” — V.B.</p><p>Further Reading: <a href="https://vitalik.eth.limo/">vitalik.ca</a></p><p>The following are <strong>Vitalik’s most influential and discussed blog posts</strong>, categorized by topic and with brief analysis, I highly recommend:</p><ol><li><strong><a href="https://vitalik.ca/general/2017/02/28/decentralization.html">The Meaning of Decentralization (2017)</a></strong><br><strong>Keywords: logical decentralization, political decentralization, architectural decentralization</strong></li></ol><ul><li><p>Explained that decentralization is not just about node distribution, but also includes “who controls what” and “distribution of failure points”.</p></li><li><p>It has been cited countless times and is the philosophical starting point of the decentralized narrative of Web3.</p></li></ul><ol start="2"><li><strong><a href="https://ethereum.org/en/whitepaper/">Ethereum: Platform for Smart Contracts (2014)</a></strong></li></ol><ul><li><p>Not a blog, but equally important. This is the Ethereum white paper he wrote, which proposes the vision of “world computer”.</p></li><li><p>If you haven’t read it, many core designs of Ethereum are difficult to understand.</p></li></ul><ol start="3"><li><strong><a href="https://vitalik.ca/general/2021/04/07/sharding.html">Why sharding is great: demystifying the technical properties</a></strong></li></ol><ul><li><p>A popular explanation of the design ideas of Ethereum sharding.</p></li><li><p>It is crucial to understand the evolution roadmap of Ethereum scalability.</p></li></ul><ol><li><strong><a href="https://vitalik.ca/general/2022/09/20/daos.html">DAOs are not corporations: where decentralization in autonomous organizations matters</a></strong></li></ol><ul><li><p>In-depth analysis of the differences between DAO governance models and traditional companies.</p></li><li><p>DAO is more suitable in scenarios of “market externalities”, “high collaboration” and “high divergence”.</p></li></ul><ol start="5"><li><strong><a href="https://vitalik.ca/general/2019/12/07/quadratic.html">Quadratic Funding and Quadratic Voting</a></strong></li></ol><ul><li><p>Promote the concept of the secondary mechanism of <strong>Radical Markets</strong> and conduct experiments in combination with Gitcoin.</p></li><li><p>Emphasize that the strong preferences of a minority can be expressed fairly to avoid violent voting by large households.</p></li></ul><ol start="6"><li><strong><a href="https://vitalik.ca/general/2020/08/10/credibleneutrality.html">Credible Neutrality as a Guiding Principle</a></strong></li></ol><ul><li>Proposed “credible neutrality” (Credible Neutrality), applicable to chains, oracles, and protocol rules.</li><li>One of the most recognized design philosophies in the crypto field.</li></ul><ol start="7"><li><strong><a href="https://vitalik.ca/general/2021/01/05/rollup.html">An Incomplete Guide to Rollups</a></strong></li></ol><ul><li>Systematically summarizes the pros and cons of optimistic rollups and zk rollups.</li><li>Promoted Ethereum’s “modular blockchain” paradigm shift.</li></ul><ol start="8"><li><strong><a href="https://vitalik.ca/general/2021/12/06/endgame.html">Endgame (2021)</a></strong></li></ol><ul><li>Propose the scalability, security, and endgame of centralized game of future blockchain architecture.</li><li>Assume that there is a super decentralized blockchain, but it must also rely on centralized building blocks (like sequencers).</li><li>Deeply reveal the future direction of L1-L2.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;A new world order&lt;/h1&gt;
&lt;p&gt;In the world of crypto, few figures have shaped its philosophical and technical trajectory as deeply as Vitali</summary>
      
    
    
    
    
    <category term="blockchain" scheme="https://stan370.github.io/tags/blockchain/"/>
    
  </entry>
  
  <entry>
    <title>The Curse of Meritocracy</title>
    <link href="https://stan370.github.io/2025/04/13/Curse/"/>
    <id>https://stan370.github.io/2025/04/13/Curse/</id>
    <published>2025-04-13T08:39:20.000Z</published>
    <updated>2025-07-29T09:51:27.947Z</updated>
    
    <content type="html"><![CDATA[<p>From a young age, many of us are told: “If you work hard and prove yourself, you will be rewarded.”</p><p>We are steeped in the gospel of <strong>meritocracy</strong> from childhood. Study diligently, excel academically, collect the accolades – the path to a successful future, we are assured, is paved with quantifiable effort and talent. As students aiming for demanding fields like Computer Engineering, this <strong>ethos</strong> becomes an intense reality. School morphs into an arena for performance, knowledge a means to an end measured in grades and rankings, and the ultimate prize: admission into prestigious institutions.</p><p>I bought into this promise wholeheartedly. I learned the rules, played the game, and poured years into mastering the metrics. And by the system’s own standards, I succeeded. Multiple Master’s offers in Computer Engineering from international universities felt like the culmination, the hard-earned validation.</p><p>**The Twist<br>**<br>However, life doesn’t always go as expected. That’s it.</p><p>I didn’t plan to take a <strong>gap year</strong>, but I saw it coming.</p><p>Somewhere in this journey, I started questioning something deeper — not just <em>why it’s hard to get a job in tech right now</em>, but <em>why it feels so personal</em>.</p><p>This reflection led me to confront a much bigger issue: the curse of meritocracy.<br>In a <em>true</em> meritocracy, these things should translate into opportunities, right?</p><ul><li>Get good grades</li><li>Win competitions</li><li>Find a job<br>So when job offers don’t come in — or only come in under unfair terms — we’re left confused, maybe even ashamed. “Did I not work hard enough?” becomes an internal voice of blame.</li></ul><p>Here lies the curse: when success is framed as purely based on merit, failure feels entirely like a personal defect.</p><p>But the truth is more complex. The job market is cyclical. Recruiters often filter by brand names, not by capability. Many good roles are never posted publicly. Policies, market recessions, and insider referrals all distort the game. This isn’t a complaint — it’s a reality check.</p><p>Merit is just one variable in a messy, nonlinear equation. The job market was still competitive, and societal expectations hadn’t vanished. But something fundamental had shifted within me. I used to think not getting into a FAANG company meant I was behind.</p><p>But Is it really matter that i solve the leetcode in time in a interview?</p><p>For a while, I thought the solution was simple: solve more Leetcode problems, and do it faster. I treated technical interviews as puzzles I just needed to crack.</p><p>But here’s what I learned: solving algorithms under a time limit is a skill, but it’s not the only one that matters.</p><p>What it doesn’t prove in a person:<br>That you’re a good software engineer.</p><p>That you can maintain and refactor complex codebases.</p><p>That you can build user-facing systems with long-term impact.</p><p>That you think creatively or critically beyond known patterns.</p><p>I think collaborating in hackathons gave me resilience, not just resume. Building tools and small games that someone actually use feels good.</p><p>Trying, failing, and reflecting on user feedback have taught me far more than traditional coursework ever did. I learned to build before I felt ready, to listen more than explain, and to treat failure not as a signal to stop, but as a prompt to iterate more fast.</p><p>To truly understand feedback, you have to step into the user’s shoes. They are the ultimate arbiters of value. What seems intuitive to you might be completely confusing to them. What you thought was a killer feature might be ignored, while a minor element becomes unexpectedly popular.</p><p>That kind of growth doesn’t show up on a transcript — but it shapes the kind of engineer, teammate, and thinker I’ve become.</p><p>Meritocracy told me to chase validation. Reality taught me to chase growth. It equates our human value with our output, fosters crippling anxiety, and can alienate us from our own genuine interests and sense of self. I didn’t magically have all the answers, nor was I suddenly immune to the pressures of the world.</p><p>**To Others on a Similar Path<br>**<br>If you’re always feel being left, or struggling to find your place — you’re not behind. You’re just not playing a zero-sum game anymore.</p><p>Gap Year was transformative for me because it existed outside the metrics of the standardize life I should live. I didn’t magically have all the answers, nor was I suddenly immune to the pressures of the world in the past 2 years. But something fundamental had shifted within me.</p><p>I’m still try to find the “right” job — but I’m no longer hunting approval. I think the most significant 成长 (growth) came from stepping outside the achievement framework altogether and find your own way of success.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;From a young age, many of us are told: “If you work hard and prove yourself, you will be rewarded.”&lt;/p&gt;
&lt;p&gt;We are steeped in the gospel o</summary>
      
    
    
    
    
    <category term="feelings" scheme="https://stan370.github.io/tags/feelings/"/>
    
    <category term="personal growth" scheme="https://stan370.github.io/tags/personal-growth/"/>
    
  </entry>
  
  <entry>
    <title>Learn Rust</title>
    <link href="https://stan370.github.io/2025/04/08/rust/"/>
    <id>https://stan370.github.io/2025/04/08/rust/</id>
    <published>2025-04-08T14:57:19.000Z</published>
    <updated>2025-05-21T07:20:29.055Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I applied for a project in Tor organization, which aims to reimplement the** <code>metrics-lib</code> **in Rust, maintaining the same functionality while leveraging Rust’s advantages in terms of performance, memory safety, and concurrency. This aligns with the Tor Project’s broader initiative to modernize the metrics pipeline.**The goal of this project is to rewrite the current Java-based Tor Metrics Library in Rust. This library is a crucial component for parsing and analyzing Tor network descriptors used by various services and researchers. By reimplementing the library in Rust, we aim to improve performance, take advantage of Rust’s modern language features, and provide a more ergonomic API. This rewrite will also allow the Network Health Team (and others) to migrate some of their services to Rust. In addition to replicating current features, the new library will include some features from the DescriptorParser for exporting parsed descriptor data into formats like CSV, Parquet, or PostgreSQL tables, thereby enabling more advanced integrations and analysis capabilities.<br>The rust rewrite should provide the <strong>same</strong> parsing and validation functionalities provided by metrics-lib and in addition allow <strong>exporting</strong> of the documents in some external storage, like parquet files to be saved into object storage or a table on a postgresql database.</p><p>To modernize and improve maintainability, performance, and safety, this proposal outlines a full re-implementation of the library in <strong>Rust</strong>, a systems programming language that offers <strong>memory safety</strong>, <strong>zero-cost abstractions</strong>, and <strong>better integration with modern data pipelines</strong>. Such as:</p><ul><li>Use Rust’s ownership system for safe memory management</li><li>Implement zero-copy parsing where possible</li></ul><table><thead><tr><th><strong>Layer</strong></th><th><strong>Tech Stack</strong></th></tr></thead><tbody><tr><td>Language</td><td>Rust</td></tr><tr><td>Network IO</td><td><code>reqwest</code>, <code>hyper</code>, <code>tokio</code></td></tr><tr><td>Parsing</td><td><code>nom</code>, <code>pest</code></td></tr><tr><td>Storage Output</td><td><code>parquet</code>, <code>serde</code>, <code>postgres</code></td></tr><tr><td>Testing &amp; CI/CD</td><td><code>cargo test</code>, GitLab CI/CD</td></tr><tr><td>Docs &amp; Linting</td><td><code>rustdoc</code>, <code>clippy</code>, <code>rustfmt</code></td></tr></tbody></table><h3 id="2-1-Original-structure">2.1 Original structure</h3><p>The library has evolved significantly from version 1.0.0 to 2.26.0, over the past 10 years.</p><p>Key features include:</p><ol><li><strong>Data Sources:</strong><ul><li>The library primarily targets data archived by <strong>CollecTor</strong> (<code>collector.torproject.org</code>).</li><li>This data is typically stored in compressed tar archives (<code>.tar.xz</code>, <code>.tar.gz</code>, <code>.tar</code>) containing numerous individual data files.</li><li>It can also process individual, unarchived data files.</li></ul></li><li><strong>Supported Data Types:</strong><code>metrics-lib</code> can parse several distinct types of Tor network measurement data:<ul><li><strong>Relay Descriptors:</strong><ul><li><code>server-descriptors</code>: Detailed information published by relays about themselves (IP, ports, keys, bandwidth, policies, etc.). Parsed into <code>RelayServerDescriptor</code>.</li><li><code>extra-info-descriptors</code>: Additional information published by relays (bandwidth history, geoip data, etc.). Parsed into <code>RelayExtraInfoDescriptor</code>.</li><li><code>microdescriptors</code>: Smaller, more frequently updated versions of relay information used for client bootstrapping. Parsed into <code>RelayMicrodescriptor</code>.</li></ul></li><li><strong>Network Status Consensus Documents:</strong><ul><li>These documents represent a snapshot of the Tor network state at a specific time, as agreed upon by the Directory Authorities.</li><li><code>microdesc-consensus</code>: Contains references to microdescriptors, relay flags, bandwidth weights, etc. Parsed into <code>RelayMicrodescriptorConsensus</code>. Contains <code>NetworkStatusEntry</code> objects for each relay listed.</li><li><code>relay-consensus</code>: (Less common now, but historically used) Similar but based on server descriptors. Parsed into <code>RelayServerDescriptorConsensus</code>.</li></ul></li><li><strong>Exit Lists:</strong><ul><li>Snapshots of relays identified as Exit nodes at a particular time, often generated by services like TorDNSEL. Parsed into <code>ExitList</code>. Contains <code>ExitNodeEntry</code> objects.</li></ul></li><li><strong>Bridge Data:</strong><ul><li>Similar data types but specifically for Tor Bridges (unlisted relays).</li><li><code>bridge-server-descriptors</code>: Parsed into <code>BridgeServerDescriptor</code>.</li><li><code>bridge-extra-info-descriptors</code>: Parsed into <code>BridgeExtraInfoDescriptor</code>.</li><li><code>bridge-statuses</code>: Analogous to consensus documents but for bridges, generated by the Bridge Authority. Parsed into <code>BridgeAuthoritativeStatus</code>.</li></ul></li></ul></li><li><strong>Core Design Pattern: Readers and Iterators:</strong><ul><li>The library uses a <strong>Reader</strong> pattern for each major data category (e.g., <code>DescriptorReader</code>, <code>ConsensusReader</code>, <code>ExitListReader</code>, <code>BridgeDescriptorReader</code>, <code>BridgeStatusReader</code>).</li><li>You instantiate a Reader, providing it the path to an archive file (e.g., <code>.tar.xz</code>) or a single data file.</li><li>The Reader acts as an <strong>iterator</strong>. You loop over the reader (e.g., <code>for desc in DescriptorReader(path):</code>), and it yields parsed data objects one by one.</li><li>This is efficient as it typically doesn’t load the entire archive or all data into memory at once (it likely streams through the archive).</li></ul></li><li><strong>Data Representation: Structured Objects:</strong><ul><li>When the Reader yields an item, it’s a object (like <code>RelayServerDescriptor</code>, <code>NetworkStatusEntry</code>, <code>ExitNodeEntry</code>).</li><li>These objects have <strong>attributes</strong> corresponding to the fields parsed from the raw data files (e.g., <code>desc.nickname</code>, <code>desc.fingerprint</code>, <code>consensus.valid_after_time</code>, <code>relay_status.flags</code>, <code>exit_node.exit_addresses</code>).</li></ul></li><li><strong>Key Features &amp; Benefits:</strong><ul><li><strong>Abstraction:</strong> Hides file format details (descriptor syntax, consensus structure, tarball handling).</li><li><strong>Automation:</strong> Easily process large numbers of files within archives.</li><li><strong>Structured Data:</strong> Provides convenient object-oriented access to data fields.</li><li><strong>Type Dispatching:</strong> The <code>DescriptorReader</code> automatically identifies the type of descriptor (<code>@type</code> annotation in the file) and returns the appropriate object type (<code>RelayServerDescriptor</code>, <code>RelayExtraInfoDescriptor</code>, etc.).</li><li><strong>Error Handling:</strong> Includes mechanisms (like <code>InvalidDescriptor</code> exceptions) to handle malformed or unparseable files gracefully.</li></ul></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Recently, I applied for a project in Tor organization, which aims to reimplement the** &lt;code&gt;metrics-lib&lt;/code&gt; **in Rust, maintaining th</summary>
      
    
    
    
    
    <category term="编程" scheme="https://stan370.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>进步的幻象：生产力的发展带来了什么</title>
    <link href="https://stan370.github.io/2025/04/07/capitalism/"/>
    <id>https://stan370.github.io/2025/04/07/capitalism/</id>
    <published>2025-04-07T05:31:55.000Z</published>
    <updated>2025-04-07T08:08:18.710Z</updated>
    
    <content type="html"><![CDATA[<h1>进步的幻象</h1><p>生产力的进步，通常被视为人类社会发展的核心动力。它意味着用更少的资源和时间创造更多的价值，理应带来更高效的生产、更富裕的生活和更多的闲暇。然而，现实却常常呈现出一种令人困惑甚至绝望的景象：随着技术的飞速发展和生产效率的指数级提高，许多人非但没有因此获得解放，反而感到更加劳碌、压力更大。<strong>如果生产力的进步只是让人更加疲惫不堪，那么这种进步的意义究竟何在？我们是否陷入了一种“进步的幻象”</strong>，重复着历史的错误，却始终不愿吸取教训？</p><p>这种令人沮丧的悖论并非新鲜事。回顾历史，我们不难发现，生产力进步与劳动者处境之间的关系远非简单的线性正相关。以20世纪30年代的<strong>大萧条</strong>为例。当时，美国的工厂已经拥有了惊人的生产能力，可以大量制造汽车、收音机等商品。从生产力角度看，这是一个巨大的飞跃。然而，这种进步却伴随着史无前例的经济崩溃。生产过剩与有效需求不足并存，工厂倒闭，数百万人失业，社会陷入贫困和混乱。生产力的高度发达并没有转化为普遍的繁荣和闲暇，反而导致了大规模的苦难。这深刻地揭示了：生产力进步本身并非目的，其价值取决于其成果如何被分配和管理。如果进步的果实主要被少数人攫取，而多数人却因技术进步带来的结构性失业或市场波动而陷入困境，那么这种“进步”对大多数人而言就毫无意义，甚至是一种灾难。</p><h2 id="1-How-to-turn-labor-into-Relentless-Machine">1. How to turn labor into Relentless Machine?</h2><p>随着机器化大工业蓬勃发展，资本主义价值运动的一个必然趋势就是，“对象化劳动在劳动过程本身中与活劳动相对立而成为支配活劳动的力量”；与此同时，活劳动则转变为机器系统中“单纯的活的附件”。如此一来，从价值形成的生产过程看，资本在追逐自我增殖过程中，不可避免地引致价值实体的“空壳化”。形象地讲，这好比资本主义价值运动存在“黑洞”，只吞噬旧价值，却无法吐出新价值。正如美国学者大卫·哈维所指出的，“如果活劳动是价值和利润的源泉，那么用死劳动或机械劳动代替活劳动在政治上和经济上都毫无意义。在马克思看来，这是资本主义的一个核心矛盾”。<br>　　回顾资本主义生产史，在福特制下，科学技术的资本主义应用不断推进生产标准化和自动化，实现人机关系的根本翻转，“在工场手工业和手工业中，是工人利用工具，在工厂中，是工人服侍机器”，但劳动作为“有意识的机件”依然不可或缺。随着资本主义的发展，非物质劳动展演于人们的日常沟通、社会合作和情感交流之中，资本一时难以实现对其规训与吸纳，遑论利用“能动的机器体系”来取而代之。进入数字资本主义阶段，资本主义智能化生产步入快车道，极大地拓展了“机器换人”的操作边界，生产过程中直接劳动加速缩减。但数字经济实践表明，在分析式人工智能技术驱动下，智能增强的数字机器不仅囿于特定作业领域，而且日渐曝光的“幽灵工作”时刻昭示：所谓的“无人化”“零劳动”“后工作”依然只是技术乐观派的一种数字乌托邦想象。<br>　　其实，在马克思语境下，即使资本获得最完善、最适应的机器体系，即自动的机器体系，也不意味着劳动的彻底退出，而是作为一个环节“分布在机械体系的许多点上”。并且，在马克思看来，“一个在本生产部门内完全不使用可变资本，因而完全不使用工人的资本家”只是一个极端的假定。如上文所述，伴随资本主义生产从机械化到自动化再到智能化，劳动形式也从物质劳动到非物质劳动再到数字劳动，创造价值的活劳动从来就没有真正离场。“蒸汽机、纺织机、电气化和电子化从未持续减少劳动量，相反更加大了劳动量。”但万事因时而变。大模型生产落地后，在通用人工智能的技术加持下，数字机器的决策自主和能力泛化正在以超乎常人想象的节奏飞速提升。撇开“超级智能”“机器意识”等极具争议性话题，从资本主义生产过程看，当今数字机器展现持续迭代的“高阶自动化”能力，正在使越来越多的认知劳动被超高效的智能算法所替代。可以说，“以往的工业自动化系统或智能机械解放的主要是人的体力，取代的是体力劳动者，但ChatGPT之类通用人工智能正在颠覆人的脑力劳动，取代‘脑力劳动者’承担的各种工作”。<br>　　面对工业时代机器系统的巨大力量，马克思曾惊呼：“如果机器消灭了整个雇佣工人阶级，那么这对资本来说将是一件十分可怕的事情，因为资本没有雇佣劳动就不成其为资本了！”毋庸置疑，大模型时代数字机器所展示的生产威力，使迄今为止所有的工业机器都相形见绌。随着通用人工智能的技术精进和场景应用，“现在资本正把‘活劳动’的基本能力——认知和感知——重塑为适合资本的机器形式，它致力于加紧对这些基础能力的捕获并加快转化于‘分布式’的智能体系中”。照此趋势发展下去，一个不容回避的理论追问是，就连“站在生产过程的旁边”照料机器的机会，留给普通劳动者的还会有多少？</p><h2 id="2-大模型生产放大价值运动的“市场悖反”">2.　大模型生产放大价值运动的“市场悖反”</h2><p>在政治经济学语境下，价值反映了商品经济条件下人们相互交换劳动的社会关系。它滥觞于社会分工下私人劳动和社会劳动的对立，成形于商品生产和商品流通的统一。换言之，作为一种社会确证，价值以交换价值为中介实现了具体劳动向抽象劳动、私人劳动向社会劳动的双重转换。进而，“劳动作为一般劳动的对象化和作为满足一般需要的[手段的]性质”通过交换被肯定，自然成为维系资本主义价值体系的生死攸关之事了。<br>　　从价值实现看，随着资本主义生产力快速发展，商品供给日趋丰富，市场开拓和需求扩张就变得愈发迫切。但数百年资本主义经济发展表明，虽然资本不择手段来开拓国内外市场，但生产相对过剩始终与资本主义社会化大生产如影随形。究其根源，资本自身的运动一直存在无法克服的“市场悖反”：一方面，为了获取价值，资本竭力制造日益丰富的商品供给；另一方面，为了加速自我增殖，资本又极尽贬低劳动力价值之能事。其结果，资本主义的生产扩张和需求萎缩相向而行，造成价值运动中断，引发周期性危机。<br>　　这集中体现在：福特制下生产标准化、流水线化，持续推动劳动“去技能化”，“工人变成了机器的单纯的附属品，要求他做的只是极其简单、极其单调和极容易学会的操作”。于是，“由于这种转移，工人自己的劳动能力就贬值了”。后福特制兴起后，资本力推新自由主义的制度革新，持续推动就业不稳定化，越来越多的普通劳动者只能靠消费信贷勉强度日。进入数字资本主义阶段，数字劳动的兴起给劳动者带来新的就业方式和工作机会，但数字劳动的平台化组织和算法化管理，进一步加剧就业不稳定。<br>　　随着通用人工智能技术开始普及，数字资本主义千行百业的生产流程都在经历重组和重塑。麦肯锡估计，在63个应用案例中，生成式AI应用每年能给全球经济带来2.6万亿美元至4.4万亿美元的潜在价值。目前来看，数字科技巨头通过数据、算力和算法的全方位垄断，牢牢掌控通用人工智能的技术经济生态，企图独享大模型生产释放的新一轮数字红利。可以肯定的是，数字资本主义现行平台体制如不改弦更张，必然会有越来越多的劳动者在数字化转型中落入“数字穷人”的生存窘境。<br>　　这是因为，首先，在大模型生产下，“机器换人”现象持续向资本主义知识生产领域蔓延，拥有知识专长的“创意阶层”将会步蓝领工人的后尘，被无情的却擅于叙事的数字资本抛弃。其次，通用人工智能技术进一步激活数字泰勒主义，数字资本加速拆解人类认知劳动过程，不断将可计算的工作内容标准化、模块化和自动化，从而将资本主义高阶劳动也“去技能化”。可以料想的是，数字资本主义复杂劳动简单化加速，国民收入分配格局中劳动占比持续走低将是必然趋势。<br>　　如此一来，一方面，大模型生产实现知识商品的工业化生产，加上通用人工智能技术赋能传统制造提质增效，数字资本主义商品和服务产能将会呈现指数级增长；另一方面，大模型生产将数量惊人的知识型工作者从资本主义直接生产过程排挤出去，致使长期以来支撑发达资本主义国家大众消费的“中产阶级”加速塌陷。其结果，大模型生产进一步放大资本主义生产扩张与需求收缩的“市场悖反”，数字化的资本生产和流通注定要遭遇更加频繁的生产过剩和更加剧烈的市场动荡。</p><h2 id="3-Global-Perspective">3. Global Perspective</h2><p>从全球供应链的角度来看，美国与中国之间建立了极为复杂的经济联系。美国对中国长期存在巨额贸易逆差，进口远超出口，许多美企依赖中国进行低成本制造，从而保持消费价格的低廉并提升自身利润。虽然近年来部分企业宣布将生产转移回美国本土，但真正实现回流的比例仍然有限。在美国重新设厂和招募熟练劳动力的成本高昂，成为现实操作中的巨大阻力。</p><p>在此背景下，特朗普政府于2018至2020年间推行了关税战略，对数十亿美元的中国产品加征关税，初期聚焦钢铁和铝，后扩展至各类消费品。其既定目标包括减少贸易逆差、提升美国制造业竞争力，推动制造业回流。然而，成效与预期之间存在不小差距。</p><p>与此同时，中国的全球角色也在发生转变。从曾经的“世界工厂”逐渐向价值链上游移动，中国正将发展重点从基础制造转向更复杂的高附加值产业与技术创新，并在全球经济与地缘政治领域展现出更强的自信心。值得注意的是，美国当前所采取的“去风险”（de-risking）战略，区别于全面“脱钩”（decoupling）。这是一种更为审慎的做法，即在关键产业链减少对中国的依赖，但并不完全切断两国之间的经济联系。<br>正是在这种全球结构的变化之中，中国国内的劳工现状更深刻地展现出这一增长逻辑的矛盾和非人道。</p><p>中国改革开放以来，依托廉价劳动力和强大的组织动员能力，其生产力取得爆炸式增长，一跃成为全球制造中心，甚至在高科技产业上亦迅速崛起。然而，与之伴随的，却是令人堪忧的劳工现实：普遍盛行的“996”工作制、激烈的内卷文化、制造业与服务业劳动者超长工时与高强度劳动成为常态。大量年轻人乃至中年人身心俱疲，缺乏自主生活的空间与时间，个体生活的质量并未因国家的经济增长而同步提升。 在改革开放后的几十年里，中国的生产力实现了爆炸式增长，成为“世界工厂”，高科技产业也迅速崛起。然而，与此相伴的却是普遍的“996”工作制、激烈的内卷竞争、以及许多制造业和服务业劳动者面临的超长工时和高强度劳动。许多年轻人和中年人感到身心俱疲，缺乏生活的自主权和闲暇时间。尽管整体社会财富大幅增加，但许多劳动者并没有因此获得应有的回报，反而感到被卷入了无休止的竞争和加班之中。生产力的进步似乎只是让资本和技术所有者获得了更多利润，而广大劳动者却依然处于“更加劳碌”的困境。</p><p><strong>更深层的隐忧在于，这种现象实际上加剧了贫富差距的扩大。技术与生产力的进步确实释放了巨大的经济潜能，但这些红利的分配极为不均。掌握资本、技术与信息资源的少数群体能够轻松积累财富，而普通劳动者则在面对自动化、AI等新技术的冲击下议价能力不断下降，工资增长滞缓。最终，一部分人享受着自由与财富，而更多人却在加班与焦虑中苦苦挣扎。</strong></p><p>“<strong>History happens over and over again, people dont learn any things!</strong>” 这句看似宿命论的感叹，却揭示了一个令人沮丧的现实。从大萧条的教训，到当下中国以及全球范围内的劳工困境和贫富差距，历史似乎在不断重演。人们似乎总是容易被“效率”和“增长”的口号所迷惑，而忽略了进步的最终目的应该是为了人类的福祉。我们拥有了前所未有的生产力，但却没有建立起一套能够公平分配这种生产力的社会机制和伦理准则。我们仍然在以一种原始的、弱肉强食的方式争夺生产力进步带来的利益，而没有认识到真正的进步应该意味着更少的劳动、更多的自由、更平等的社会。</p><p>因此，如果生产力的进步只是导致更严重的剥削、更剧烈的竞争、更巨大的贫富差距，并最终让多数人感到更加劳碌，那么这种进步就失去了其应有的意义。它只是一种技术上的成功，而不是人类文明的进步。衡量进步的标准不应仅仅是GDP的增长或生产效率的提高，更应该是社会整体福祉的提升、劳动者的解放、以及人与人之间更公平的关系。</p><p>生产力的进步本身是中性的，其价值取决于人类如何运用它。我们是否能从大萧条、从当下的劳工困境中吸取教训，不再仅仅追求“多”和“快”，而是追求“好”和“公平”？这需要我们重新审视进步的定义，需要更健全的社会保障体系、更合理的财富分配机制、更以人为本的政策制定。否则，我们可能永远无法走出“进步的幻象”，在无休止的劳碌中，徒劳地追逐着一个看似光鲜却毫无意义的未来。真正的进步，应该让每一个人都能分享其成果，获得更多闲暇、更多尊严，而不是被它驱使着永不停歇。历史的重复是因为人类并没有从过去的错误中吸取教训。我们仍然在重复着同样的错误，仍然在追求利润而不是改善人类的生活。我们需要改变这种思维方式，需要将生产力的进步转化为人类生活的改善。我们需要建立一个更加公平和公正的社会，在这个社会中，工人的劳动成果被尊重和奖励，而不是被剥削。</p><p>如果生产力的进步只是让人更加劳碌，那么这种进步还有什么意义？我们需要反思我们的价值观和社会体系，需要将生产力的进步转化为人类生活的改善。只有这样，我们才能真正地享受生产力的进步带来的好处，而不是重复着历史上的错误。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;进步的幻象&lt;/h1&gt;
&lt;p&gt;生产力的进步，通常被视为人类社会发展的核心动力。它意味着用更少的资源和时间创造更多的价值，理应带来更高效的生产、更富裕的生活和更多的闲暇。然而，现实却常常呈现出一种令人困惑甚至绝望的景象：随着技术的飞速发展和生产效率的指数级提高，许多人非但没有</summary>
      
    
    
    
    
    <category term="marxism" scheme="https://stan370.github.io/tags/marxism/"/>
    
  </entry>
  
  <entry>
    <title>3000元部署开源隐私”大“模型 on Mac mini 16gB</title>
    <link href="https://stan370.github.io/2025/03/19/localLlama/"/>
    <id>https://stan370.github.io/2025/03/19/localLlama/</id>
    <published>2025-03-19T13:56:29.000Z</published>
    <updated>2025-08-04T02:58:49.784Z</updated>
    
    <content type="html"><![CDATA[<p><strong>为什么我选择 Mac Mini M4？——本地 LLM 部署 &amp; 个人知识库探索</strong></p><p>在大模型都想上云、绑API的时代，还有多少人愿意在家用小机器上，部署隐私友好、本地离线、完全控制的模型系统？如果你愿意折腾，一台**不到3000元的二手/教育优惠 Mac mini M4（16GB RAM）**就能跑起目前大多数开源 20B 以下的量化模型，甚至还能处理语音、图像、代码。</p><p>我在2024年中到2025年间密集试了各种框架，从 Transformers 到 llama.cpp，再到 Apple 的 MLX + LM Studio，下面是基于实际使用体验 + 社区 benchmark 对比 + 本地推理日志的一份部署总结，适合有硬件限制但又想最大化利用现有芯片能力的开发者。 这篇文章会分享我的<strong>选型思考</strong>、<strong>用途场景</strong>，以及在折腾过程中收获的一些经验。</p><hr><h2 id="1-为什么选择-Mac-Mini-M4？"><strong>1. 为什么选择 Mac Mini M4？</strong></h2><p>在挑选设备时，我主要考虑了以下几个因素：</p><h3 id="1-1-性能-vs-能耗：M4-的性价比惊喜">** 1.1 性能 vs. 能耗：M4 的性价比惊喜**</h3><p>相比 Intel/AMD 服务器或台式机，<strong>Apple Silicon 的能耗比确实很强</strong>。M4 拥有<strong>10 核 CPU + 10 核 GPU + 16 核 NPU</strong>，而且功耗低到离谱（官方标称 30W）。<br>在选择硬件时，我研究了多个选项，包括自建 PC、云服务器和其他品牌的小型机，最终锁定了 Mac Mini M4。以下是我的理由。<br>Mac Mini M4 的核心亮点是 Apple Silicon 的 M4 芯片，其统一架构和高能效比在 AI 工作负载中表现出色。以下是 M4 的一些关键参数，以及它们如何提升 RAG 工作流的效率：<br>CPU 核心：<br>M4 配备 8 性能核心 + 4 效率核心（或更高版本的 12P+4E），在处理检索任务（如搜索和索引）时，性能核心负责高负载计算，而效率核心处理轻量任务如后台数据整理。<br>GPU 核心：<br>M4 的集成 GPU 提供了 16 核或更高的图形处理能力，并支持 Apple 的 Metal API。对于运行轻量化 LLM（如量化后的 LLaMA 2）或实时生成嵌入，这种 GPU 性能足以媲美中端独立显卡。<br>统一内存架构（Unified Memory Architecture, UMA）：<br>16GB 或 24GB 的统一内存使得 CPU 和 GPU 共享同一块高速内存池，避免了传统架构中频繁的数据拷贝与延迟问题。这对运行大型模型和向量检索的实时计算非常重要。<br>Neural Engine（神经引擎）：<br>每秒 15.8 万亿次运算（TOPS） 的专用 AI 加速器可以用来提升模型推理速度，尤其是在运行量化后的 LLM 时。<br>存储速度：<br>内置 NVMe SSD 提供 高达 7GB/s 的读写速度，大幅缩短数据检索和模型加载的时间。<br>相比之下：</p><ul><li>如果选择 <strong>AMD 9600X + 192G 内存</strong>，不仅功耗高，后期还得考虑风扇噪音、散热问题。</li><li><strong>Epyc 服务器方案</strong>（768GB 内存那套）虽然可以跑更大的模型，但价格和功耗都太高，不适合个人玩家。</li><li><strong>Mac Mini M4</strong> 价格加上国补 <strong>最低 3000 RMB</strong>，省去了折腾电源、散热、机箱的麻烦，而且 macOS 的生态也适合开发者。<br>使用云服务器（如 AWS、GCP）运行 RAG 系统，每月成本可能高达数百美元，而本地运行的 Mac Mini 一次性投入后，几乎没有额外费用。<br>综合来看，M4 是一个 <strong>低功耗高性价比的选择</strong>，特别适合日常推理小型 LLM（&lt;14B 参数规模）。</li></ul><hr><p>好，这是一个面向技术读者、强调实际测试数据、部署体验和边际性价比的博客草稿。语气偏真实用户分享，内容结构松散但信息量高：</p><hr><h1>用不到3000元部署开源“类大模型”：Mac mini 16GB的极限挑战与实践总结（截至2025-08-04）</h1><p>在大模型都想上云、绑API的时代，还有多少人愿意在家用小机器上，部署<strong>隐私友好、本地离线、完全控制的模型系统</strong>？如果你愿意折腾，一台**不到3000元的二手/教育优惠 Mac mini M4（16GB RAM）**就能跑起目前大多数开源 20B 以下的量化模型，甚至还能处理语音、图像、代码。</p><p>我在2024年中到2025年间密集试了各种框架，从 Transformers 到 llama.cpp，再到 Apple 的 MLX + LM Studio，下面是基于<strong>实际使用体验 + 社区 benchmark 对比 + 本地推理日志</strong>的一份部署总结，适合有硬件限制但又想最大化利用现有芯片能力的开发者。</p><hr><h2 id="📦-系统与环境配置">📦 系统与环境配置</h2><ul><li><p><strong>设备</strong>：Mac mini M4，16GB 统一内存，256GB SSD</p></li><li><p><strong>系统</strong>：macOS 15，Terminal + zsh，iStat Menu 监控内存</p></li><li><p><strong>框架</strong>：</p><ul><li><code>LM Studio</code> v0.2.12 (MLX 后端，支持 MLX safetensors 4bit)</li><li><code>llama.cpp</code>（配合 llama-swap，自建模型 proxy）</li><li><code>Ollama+OpenWebUI</code>（用于快速集成 + 可视化测试）</li><li><code>Whisper.cpp</code>, <code>Bark</code>, <code>llava.cpp</code>，自编译支持本地音频和图文推理</li><li><code>huggingface-cli</code>, <code>gguf-convert.py</code>, <code>mlx-community-convert</code> 脚本</li></ul></li></ul><hr><h2 id="大模型部署能力：你能跑多“大”？">大模型部署能力：你能跑多“大”？</h2><h3 id="截止-2025-08，以下模型可稳定运行">截止 2025-08，以下模型<strong>可稳定运行</strong></h3><table><thead><tr><th>模型名</th><th>格式</th><th>大小</th><th>Tokens/s (生成)</th><th>备注</th></tr></thead><tbody><tr><td><code>gemma-3n-E4B-it</code></td><td>MLX 4bit</td><td>2.5GB</td><td>100+</td><td>实测最流畅</td></tr><tr><td><code>deepseek-coder-1.3b-instruct</code></td><td>GGUF Q4_K_M</td><td>~2.8GB</td><td>~80</td><td>llama.cpp 跑</td></tr><tr><td><code>qwen1.5-7b-chat</code></td><td>GGUF Q4_K_M</td><td>~5GB</td><td>~35</td><td>语义表现稳定</td></tr><tr><td><code>unsloth/Qwen3-Coder-30B-A3B-Instruct</code></td><td>GGUF Q2_K_XL</td><td>~11.8GB</td><td>~10–13</td><td>勉强可用，内存压线</td></tr><tr><td><code>mistral-7b-instruct-v0.3</code></td><td>GGUF Q4_K_M</td><td>~5.8GB</td><td>~30–40</td><td>LLM 基线</td></tr><tr><td><code>gemma3n</code> 8bit</td><td>MLX 8bit</td><td>~5GB</td><td>~65</td><td>稳定运行，CPU占比稍高</td></tr><tr><td><code>openai/whisper-large-v3</code></td><td>FP16</td><td>~5.2GB</td><td>~1×实时音频</td><td>whisper.cpp 编译，表现好</td></tr></tbody></table><h3 id="❌-无法稳定运行的模型">❌ 无法稳定运行的模型</h3><table><thead><tr><th>模型名</th><th>格式</th><th>原因</th></tr></thead><tbody><tr><td><code>llama3-70b-instruct</code></td><td>GGUF</td><td>模型文件 &gt;30GB，直接 OOM</td></tr><tr><td><code>deepseek-coder-33b</code></td><td>GGUF Q2_K</td><td>Q2_K 文件 &gt;14GB，模型加载后即 crash</td></tr><tr><td><code>Claude 3 系列</code>, <code>Mixtral 12x7B</code></td><td>Sharded/非 GGUF</td><td>无法加载或格式不兼容</td></tr></tbody></table><hr><h2 id="内存极限在哪里？">内存极限在哪里？</h2><p>在 Mac mini 16GB 上，操作系统本身约占 2.5GB，即便关闭 iCloud、Spotlight、Stage Manager 等服务，理论最大模型体积也就在 <strong>11.5~12GB 左右</strong>。实践中：</p><ul><li><strong>GGUF Q2_K_XL</strong> 是可用的最大 quant 格式（用于 30B 模型）</li><li>开启 <code>llama-swap</code> 可释放模型之间的 KV Cache，降低峰值内存（非常推荐）</li><li><code>MLX</code> 加载更快，但占用 GPU RAM 多，不适合同时跑多模型</li></ul><hr><h2 id="语音-图像能力评估">语音 + 图像能力评估</h2><h3 id="Whisper-Large-v3">Whisper Large v3</h3><ul><li>编译 <code>whisper.cpp</code> with <code>-O3 -DCOREML -DWHISPER_COREML_FULL</code></li><li>实测推理速度为 <strong>1x 实时音频速度</strong>，可本地转写播客/会议录音</li></ul><h3 id="Bark-AudioLM">Bark / AudioLM</h3><ul><li>推理时间长，不适合 16GB 内存场景，推荐 remote inference</li></ul><h3 id="LLaVA-MiniGPT">LLaVA + MiniGPT</h3><ul><li><code>llava-llama-2-7b-lightning.Q4_K_M</code> 可加载，但图像转文字约需 8–10s</li><li>CoreML GPU 没显著加速，图像处理瓶颈主要在预处理阶段（clip embedding）</li></ul><p>在考虑在Mac系统上使用LLM构建和管理个人知识基础的工具时，LM Studio MLX和Ollama都是不错的选择，但具有自己的优势。让我们分解如何在功能，用例和易用性方面进行比较。有限的定制：Ollama 的简单性是以灵活性为代价的。如果您想要更好地控制模型行为、定制或与其他系统的集成，Ollama 可能不如 LM Studio MLX 强大。<br>基本功能：虽然 Ollama 非常适合简单查询和管理小型知识库，但它没有 LM Studio MLX 那么多高级功能，例如复杂的数据结构、训练或多模型集成。</p><p>LM Studio用自己的UI带来了整个包装。在MacOS上，它也是运行MLX型号的最简单选择之一。与人们似乎想到的相反，它也可以在后台运行并成为其他应用程序的后端（OpenAi API +他们自己的API）。至于其缺陷，它是“Electron APP”，它更加臃肿（您可能不需要所有内容），并且显然是封闭的（部分是由开源技术支持）。</p><ol><li><p><strong>Ollama</strong> + GGUF 量化模型（Q4、Q6）</p><ul><li><code>ollama pull deepseek-coder:6b</code>（本地代码助手）</li><li><code>ollama pull phi3:4b</code>（轻量推理，快速响应）</li><li>Ollama 生态丰富，内置 <code>RAG</code> 功能，可以快速搭建个人知识库。</li></ul></li><li><p><strong>MLX（Apple 自研的 PyTorch 替代品）</strong></p><ul><li>Apple 提供的 <code>MLX</code> 框架，可以让 LLM 充分利用 <strong>Mac 的 NPU</strong>，进一步提升推理性能。</li><li>MLX 适合需要自己训练或者微调（fine-tune）小模型的用户，性能比 <code>torch-metal</code> 更稳定。</li></ul></li></ol><hr><h3 id="1-3-价格-vs-扩展性：最划算的-macOS-设备">** 1.3 价格 vs. 扩展性：最划算的 macOS 设备**</h3><p>买 Mac Mini M4 有几个隐藏的优点：</p><ol><li><p><strong>比 Mac Studio / MacBook Pro 便宜得多</strong></p><ul><li>Mac Studio（M2 Ultra）起步价 20,000+，完全不划算。</li><li>MacBook Pro 14/16 英寸价格高，但性能和 Mini 差不多。</li></ul></li><li><p><strong>内存和存储可以外接扩展</strong></p><ul><li>连接 <strong>Thunderbolt SSD</strong>，可以扩展大容量存储，不用买官方超贵的 SSD 版本。</li><li><strong>64GB 内存的版本确实更贵</strong>，但考虑到 macOS 的 <strong>Swap 机制</strong>，16GB 也能凑合。</li></ul></li><li><p><strong>macOS 生态对开发者友好</strong></p><ul><li>自带 Unix 环境，比 Windows 好用（M4 也支持 Asahi Linux）。</li><li><strong>Python + Homebrew + Rust + Ollama</strong> 一条龙支持，很适合 LLM 和 AI 开发。</li></ul></li></ol><p>综合来看，Mac Mini M4 <strong>在性能、价格、可扩展性之间找到了最优解</strong>，比 iMac、MacBook 更合适做 LLM 部署机。</p><hr><h2 id="2-Mac-Mini-M4-在我的-AI-工作流中的作用"><strong>2. Mac Mini M4 在我的 AI 工作流中的作用</strong></h2><p>买了 Mac Mini M4 之后，我主要用它来做 <strong>本地 AI 助手 + 个人知识库</strong>，具体用途包括：</p><h3 id="2-1-个人知识库（Local-RAG）">** 2.1 个人知识库（Local RAG）**</h3><ul><li>通过 <code>Ollama + LangChain</code> 搭建**本地 RAG（检索增强生成）**系统。</li><li>数据存储在 <strong>ChromaDB</strong> 或 <strong>Qdrant</strong> 里，配合 <code>Mistral 7B</code> 或 <code>Phi-3</code> 进行查询。</li><li>实现一个离线可用的 AI 助手，不依赖 OpenAI API。</li></ul><h3 id="2-2-本地代码助手">** 2.2 本地代码助手**</h3><ul><li>用 <code>Deepseek Coder</code> 作为 <strong>离线代码补全助手</strong>，在 VS Code 里运行 <code>ollama run deepseek-coder:6b</code>。</li><li>结合 <code>Copilot</code>，提高代码写作效率，适合离线环境或数据隐私要求高的项目。</li></ul><h3 id="2-3-轻量级-AI-训练">** 2.3 轻量级 AI 训练**</h3><ul><li>主要用 <code>MLX</code> 跑一些小模型的微调（Fine-tune）。</li><li><code>MLX</code> 可以充分利用 Mac 的 <strong>Neural Engine（NPU）</strong>，比 CPU-only 方案快很多。</li></ul><hr><h2 id="3-折腾的收获"><strong>3. 折腾的收获</strong></h2><p>以 DeepSeek-R1-0528-Qwen3-8B-GGUF为例， 这个模型的多个量化版本（比如 Q4_K_XL、Q5_K_M、Q6_K 等），该如何选择最合适的一个用于部署在 ollama 或其他本地推理环境上。下面从几个关键维度来帮你分析选型。<br>这些 Q4_K_M、Q5_K_S、Q6_K_XL 是 GGUF 格式模型的量化配置，代表不同精度和内存占用。数字代表位数（4bit、5bit、6bit…），K 表示使用 k-bit quantization 的算法变种（目前最佳实践），后缀 M/S/XL 表示精度差异与模型量化细节。</p><p>Q4_0, Q4_1: 最基础的 4bit 量化，速度快，占用小，但准确率下降明显。</p><p>Q4_K_M, Q4_K_XL: 属于 k-quant 家族中优化过的 4bit 版本，在精度和性能间折中较好。</p><p>Q5_K_<em>, Q6_K_</em>: 精度更高，占用更多资源，适合需要较高准确度的任务。</p><p>Q8_0, Q8_K_XL: 几乎是 FP16 级别的精度，占用大，推理慢但准确率接近原始模型。</p><p>硬件资源约束（Mac mini M4 16GB）<br>你在 Mac mini M4 上跑本地模型（假设无 GPU，只用 CPU + NE），实际能用的 RAM 不到 13GB（系统和应用会吃掉一部分）。所以这就限制了你最多只能加载到 Q6_K_XL 甚至 Q6_K，而 Q8_K_XL 体积 &gt;10GB，会非常吃内存和 swap，严重拖慢响应。</p><table><thead><tr><th>版本名</th><th>大小</th><th>是否推荐（Mac mini 16GB）</th></tr></thead><tbody><tr><td>Q4_0</td><td>4.79GB</td><td>✅ 快速测试/微交互型任务</td></tr><tr><td>Q4_K_M</td><td>5.03GB</td><td>✅ 推荐初始部署</td></tr><tr><td>Q4_K_XL</td><td>5.12GB</td><td>✅ 平衡好性能和准确率</td></tr><tr><td>Q5_K_S</td><td>5.72GB</td><td>✅ 若你追求更高准确率</td></tr><tr><td>Q6_K_XL</td><td>7.49GB</td><td>⚠️ 临界，容易爆内存</td></tr><tr><td>Q8_K_XL</td><td>10.8GB</td><td>❌ 可能无法加载或太慢</td></tr></tbody></table><p>这段时间折腾下来，我有几个感悟：</p><ol><li><p><strong>Mac 确实适合本地推理，但不适合训练大模型。</strong></p><ul><li>Mac Mini M4 在 <strong>7B LLM 及以下的推理</strong> 体验很好，但要跑更大的模型（&gt;14B），还是得上 <strong>PC + 高内存方案</strong>。</li><li>微调（Fine-tune）虽然可以用 MLX，但远不如 <strong>Linux + A100/3090 服务器</strong> 来得高效。</li></ul></li><li><p><strong>Ollama 的体验远超想象，但下载速度需要优化。</strong></p><ul><li><code>ollama pull</code> 速度后期骤降，<strong>可能是服务器/CDN 限流</strong>，需要手动优化下载策略（见我的 <code>pull -&gt; stop -&gt; sleep</code> 方案）。</li></ul></li></ol><h2 id="优化-Bash-版本（适用于-Linux-macOS）"><strong>优化 Bash 版本（适用于 Linux/macOS）</strong></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">MODEL_NAME=<span class="string">"deepseek-coder-v2:16b"</span></span><br><span class="line">MAX_ATTEMPTS=10  <span class="comment"># 最大尝试次数</span></span><br><span class="line">TIMEOUT=120      <span class="comment"># 每次下载时间（秒）</span></span><br><span class="line">SLEEP_TIME=3     <span class="comment"># 停止后等待时间</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">trap</span> <span class="string">"echo 'Stopping...'; exit 1"</span> SIGINT SIGTERM</span><br><span class="line"></span><br><span class="line">attempt=1</span><br><span class="line"><span class="keyword">while</span> [ <span class="variable">$attempt</span> -le <span class="variable">$MAX_ATTEMPTS</span> ]; <span class="keyword">do</span></span><br><span class="line">    <span class="comment"># 检查是否已下载</span></span><br><span class="line">    <span class="keyword">if</span> ollama list | awk <span class="string">'{print $1}'</span> | grep -q <span class="string">"^$MODEL_NAME$"</span>; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">" Model <span class="variable">$MODEL_NAME</span> is fully downloaded."</span></span><br><span class="line">        <span class="built_in">exit</span> 0</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"⏳ Attempt <span class="variable">$attempt</span>: Pulling model <span class="variable">$MODEL_NAME</span>..."</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 开始下载</span></span><br><span class="line">    ollama pull <span class="string">"<span class="variable">$MODEL_NAME</span>"</span> &amp;</span><br><span class="line">    PID=$!</span><br><span class="line">    <span class="built_in">sleep</span> <span class="variable">$TIMEOUT</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 停止进程</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"⏹️ Stopping download..."</span></span><br><span class="line">    <span class="built_in">kill</span> <span class="variable">$PID</span> 2&gt;/dev/null</span><br><span class="line">    <span class="built_in">sleep</span> <span class="variable">$SLEEP_TIME</span></span><br><span class="line"></span><br><span class="line">    attempt=$((attempt+<span class="number">1</span>))</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"⚠️ Model download incomplete after <span class="variable">$MAX_ATTEMPTS</span> attempts. Please check manually."</span></span><br><span class="line"><span class="built_in">exit</span> 1</span><br></pre></td></tr></table></figure><hr><h3 id="Windows-PowerShell-版本"><strong>Windows PowerShell 版本</strong></h3><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$MODEL_NAME</span> = <span class="string">"deepseek-coder-v2:16b"</span></span><br><span class="line"><span class="variable">$MAX_ATTEMPTS</span> = <span class="number">10</span></span><br><span class="line"><span class="variable">$TIMEOUT</span> = <span class="number">120</span></span><br><span class="line"><span class="variable">$SLEEP_TIME</span> = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$attempt</span> = <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> (<span class="variable">$attempt</span> <span class="operator">-le</span> <span class="variable">$MAX_ATTEMPTS</span>) {</span><br><span class="line">    <span class="comment"># 检查是否已下载</span></span><br><span class="line">    <span class="variable">$modelExists</span> = ollama list | <span class="built_in">Select-String</span> <span class="variable">$MODEL_NAME</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="variable">$modelExists</span>) {</span><br><span class="line">        <span class="built_in">Write-Host</span> <span class="string">" Model <span class="variable">$MODEL_NAME</span> is fully downloaded."</span></span><br><span class="line">        <span class="keyword">exit</span> <span class="number">0</span></span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="built_in">Write-Host</span> <span class="string">"⏳ Attempt <span class="variable">$attempt:</span> Pulling model <span class="variable">$MODEL_NAME</span>..."</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 启动下载</span></span><br><span class="line">    <span class="built_in">Start-Process</span> <span class="literal">-NoNewWindow</span> <span class="literal">-FilePath</span> <span class="string">"ollama.exe"</span> <span class="literal">-ArgumentList</span> <span class="string">"pull <span class="variable">$MODEL_NAME</span>"</span></span><br><span class="line">    <span class="built_in">Start-Sleep</span> <span class="literal">-Seconds</span> <span class="variable">$TIMEOUT</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 终止下载</span></span><br><span class="line">    <span class="built_in">Write-Host</span> <span class="string">"⏹️ Stopping download..."</span></span><br><span class="line">    <span class="built_in">Stop-Process</span> <span class="literal">-Name</span> <span class="string">"ollama"</span> <span class="literal">-Force</span> <span class="literal">-ErrorAction</span> SilentlyContinue</span><br><span class="line">    <span class="built_in">Start-Sleep</span> <span class="literal">-Seconds</span> <span class="variable">$SLEEP_TIME</span></span><br><span class="line"></span><br><span class="line">    <span class="variable">$attempt</span>++</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="built_in">Write-Host</span> <span class="string">"⚠️ Model download incomplete after <span class="variable">$MAX_ATTEMPTS</span> attempts. Please check manually."</span></span><br><span class="line"><span class="keyword">exit</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li><strong>本地 LLM 体验很棒</strong>，可以完全替代部分 ChatGPT 使用场景。</li></ul><ol start="3"><li><strong>Mac Mini M4 未来的价值很大。</strong><ul><li>Apple 的 <strong>Neural Engine（NPU）</strong> 越来越强，未来 M4 Pro、M5 可能会更适合 AI 部署。</li><li><strong>本地 AI+RAG 是趋势</strong>，个人设备上的 LLM 会变得越来越普及。</li></ul></li></ol><hr><hr><h2 id="🛠️-实用技巧-推荐社区">🛠️ 实用技巧 &amp; 推荐社区</h2><ul><li>善用 <a href="https://huggingface.co/TheBloke">HuggingFace</a>, <a href="https://huggingface.co/catalyst">catalyst</a>, <code>mlx-community</code> 模型仓库，第一时间能获取最新 GGUF 或 MLX 转换版本。</li><li>加入 <a href="https://www.reddit.com/r/LocalLLaMA/">r/LocalLLaMA</a> 和 Discord 群体，跟踪模型发布节奏与 benchmark，对实际能跑的模型一目了然。</li><li>多关注 <code>TheBloke</code>, <code>Undi95</code>, <code>unsloth</code>, <code>ggerganov</code>, <code>mlx-examples</code> 仓库，90% 的量化模型都从这些 repo 起源。</li><li>利用 <code>llama-cpp-server</code> + <code>llama-swap</code> 自建 API proxy，可复用模型并避免 LM Studio 多模型冲突。<br>💡 适合：你对 macOS/Linux 配置熟悉，只需要 1-2 个服务<br>如果你只想跑 Open WebUI 或 AnythingLLM，可以手动安装依赖，比如：</li></ul><p>sh<br>复制<br>编辑</p><h1>安装 Node.js</h1><p>brew install node</p><h1>安装 Open WebUI</h1><p>git clone <a href="https://github.com/open-webui/open-webui.git">https://github.com/open-webui/open-webui.git</a><br>cd open-webui<br>npm install<br>npm run dev<br>📌 优势：<br>不需要 Docker，减少资源占用<br>可以自己控制环境，避免 Docker 额外的磁盘消耗</p><h2 id="4-结论：Mac-Mini-M4，最具性价比的本地-AI-设备"><strong>4. 结论：Mac Mini M4，最具性价比的本地 AI 设备</strong></h2><p>如果你的需求是 <strong>跑本地 AI 助手、LLM 推理、个人知识库</strong>，<strong>Mac Mini M4 绝对是目前最具性价比的 Apple 设备</strong>。</p><p>📌 <strong>适合人群</strong>：<br>想折腾本地 AI，体验 Ollama / MLX<br>需要一个低功耗、高性价比的 macOS 设备<br>主要跑 7B 以内 LLM，或做小型 RAG / 本地 AI 应用</p><p>💡 <strong>不适合</strong>：<br>❌ 训练大模型（建议上 Linux + 3090/A100）<br>❌ 需要 64GB 以上内存（M4 Mini 最高只支持 36GB）</p><p>目前来看，Mac Mini M4 是 <strong>低成本个人 LLM 部署最划算的选择</strong>，比服务器或高端 Mac 方案都更适合折腾！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;为什么我选择 Mac Mini M4？——本地 LLM 部署 &amp;amp; 个人知识库探索&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在大模型都想上云、绑API的时代，还有多少人愿意在家用小机器上，部署隐私友好、本地离线、完全控制的模型系统？如果你愿意折腾，一台**不到</summary>
      
    
    
    
    
    <category term="LLM" scheme="https://stan370.github.io/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>我们是被怎么塑造的？</title>
    <link href="https://stan370.github.io/2025/03/11/Whoarewe/"/>
    <id>https://stan370.github.io/2025/03/11/Whoarewe/</id>
    <published>2025-03-11T13:11:46.000Z</published>
    <updated>2025-06-08T15:41:07.238Z</updated>
    
    <content type="html"><![CDATA[<p>Lately, I’ve been reflecting on how deeply our upbringing, culture, and self-perception influence our present. Many of our struggles—perfectionism, anxiety, or even feeling out of place—can often be traced back to these invisible forces shaping us from childhood.</p><p>我们登上的并非我们所选择的舞台，演出并非我们所选择的剧本.We don’t choose our starting point. Parents, school, and society hand us a blueprint for how to think, behave, and define success. Some people grow up with constant pressure to achieve, while others are raised in environments that encourage self-expression and risk-taking. These early experiences shape our core beliefs—ideas we hold about ourselves and the world, often without questioning them.</p><p>If you grew up in an environment where failure was unacceptable, you might internalize perfectionism.<br>If you were constantly compared to others, self-worth might feel conditional—only valid when you achieve something.<br>If your culture emphasized collectivism over individualism, personal desires might feel selfish, making decisions harder.</p><p>Asian cultures (and many others with strong traditional values) often emphasize duty, hierarchy, and stability over self-expression. This is a double-edged sword:<br>✅ It fosters discipline, responsibility, and strong family bonds.<br>❌ It can also create rigid expectations, where success is narrowly defined (grades, career, financial stability).</p><p>In contrast, Western cultures—especially in English-speaking and Protestant European countries—tend to prioritize self-expression, independence, and questioning authority. Neither is inherently better, but conflicts arise when someone raised in a more traditional setting starts questioning these values.</p><p>For example:</p><p>Wanting to change careers or take risks might feel like betraying expectations.<br>Prioritizing mental well-being over external success might seem selfish.<br>Expressing emotions openly might feel unnatural or weak.</p><p>The good news? Your beliefs are not fixed. Cognitive Behavioral Therapy (CBT) teaches that thoughts create emotions, and emotions shape behavior. By questioning negative core beliefs, you can reframe your self-perception and break free from limiting patterns.</p><p>For example:</p><p>Instead of “I must be perfect to be worthy,” try “I am valuable beyond my achievements.”<br>Instead of “I can’t fail, or I’ll disappoint everyone,” try “Failure is proof that I’m trying something worthwhile.”<br>Instead of “I must follow the safest path,” try “Exploring my own path is an act of self-respect.”<br>Defining Life Values: What Truly Matters? At some point, we have to decide: Whose values are we living by?</p><p>Are we chasing success defined by society, family, or our true selves?<br>Are we making choices based on fear or genuine desire?<br>Are we prioritizing what looks good externally or what feels right internally?<br>Finding inner peace comes not from external achievements but from aligning life with authentic values. Some people find it in creative work, relationships, impact, or even embracing uncertainty. There’s no single right answer—only the one that resonates with you.</p><p>Final Thoughts<br>Culture and upbringing shape us, but they don’t have to define us forever. Recognizing the patterns, questioning them, and rewriting our own narrative is part of growth. The goal isn’t to reject where we came from but to integrate it with who we choose to become.<br>If free will means being completely uncaused by prior events, it probably doesn’t exist. But if it means acting based on your own reasoning, emotions, and desires (even if those are influenced by prior causes), then we can still meaningfully say we have free will.</p><p>The real question is: Do you need “ultimate” free will to feel like your choices matter?<br>Would love to hear from others—have you ever questioned the values you were raised with? What helped you redefine them?</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Lately, I’ve been reflecting on how deeply our upbringing, culture, and self-perception influence our present. Many of our struggles—perf</summary>
      
    
    
    
    <category term="感想" scheme="https://stan370.github.io/categories/%E6%84%9F%E6%83%B3/"/>
    
    
  </entry>
  
  <entry>
    <title>The Roads I Couldn’t Take</title>
    <link href="https://stan370.github.io/2025/03/05/poem/index/"/>
    <id>https://stan370.github.io/2025/03/05/poem/index/</id>
    <published>2025-03-05T07:49:50.000Z</published>
    <updated>2025-03-19T13:49:45.577Z</updated>
    
    <content type="html"><![CDATA[<p>tossed no books, yet lost my pages,<br>Watched my past slip through the ages.<br>A younger me once held them tight,<br>But let them go into the night.</p><p>set my sights on distant lands,<br>With open heart and empty hands.<br>Locked in walls I couldn’t break,<br>Dreams delayed—what path to take?</p><p>The rules shift, the borders change,<br>Plans collapse, yet I remain.<br>Not a thread but woven streams,<br>Not one path but countless dreams.</p><p>If gates are closed, I’ll build my door,<br>If tides retreat, I’ll row the shore.<br>Not bound by place, nor time, nor fate,<br>I shape my world—it’s not too late.</p><p>Though the past is cast in stone,<br>The future’s mine to carve alone.<br>All those moments will be lost in time<br>like tears in rain. </p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;tossed no books, yet lost my pages,&lt;br&gt;Watched my past slip through the ages.&lt;br&gt;A younger me once held them tight,&lt;br&gt;But let them go in</summary>
      
    
    
    
    <category term="感想" scheme="https://stan370.github.io/categories/%E6%84%9F%E6%83%B3/"/>
    
    
  </entry>
  
  <entry>
    <title>访问localhost的时候你的电脑发生了什么？</title>
    <link href="https://stan370.github.io/2025/02/28/Network/network/"/>
    <id>https://stan370.github.io/2025/02/28/Network/network/</id>
    <published>2025-02-28T14:20:57.000Z</published>
    <updated>2025-03-19T12:12:05.248Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-环回地址（127-0-0-1）的请求流程"><strong>1. 环回地址（127.0.0.1）的请求流程</strong></h2><h4 id="1-协议栈的处理"><strong>(1) 协议栈的处理</strong></h4><ul><li><strong>数据包仍然会走完整的网络协议栈</strong>（应用层 → 传输层 → 网络层 → 链路层），但链路层和物理层的处理是虚拟的。</li><li><strong>关键点：</strong><ul><li><strong>网络层（IP层）：</strong> 数据包的目标地址是 <code>127.0.0.1</code>，操作系统识别为环回地址，不会将数据包发送到物理网卡。</li><li><strong>链路层和物理层：</strong> 操作系统通过虚拟的环回接口（<code>lo</code> 或 <code>Loopback Adapter</code>）处理数据包，不会触发真实的硬件操作（如网卡收发数据）。</li><li><strong>传输层（TCP/UDP）：</strong> 仍然需要完成端口绑定、连接管理等逻辑（例如 TCP 的三次握手）。</li></ul></li></ul><h4 id="2-示例：Ping-127-0-0-1"><strong>(2) 示例：Ping 127.0.0.1</strong></h4><ul><li>当执行 <code>ping 127.0.0.1</code> 时：<br>当你在浏览器、cURL 或任何应用程序（如 ping 127.0.0.1）中输入 127.0.0.1：</li></ul><p>应用程序会尝试解析该地址，但 127.0.0.1 是一个 IP 地址，不需要 DNS 解析。<br>它会选择协议（通常是 TCP 或 UDP），并调用系统 API（如 socket()、connect()）。<br>2. 传输层（Transport Layer）<br>如果使用 TCP（如 HTTP 请求），应用程序会创建一个 TCP 连接, 内核会生成 TCP 三次握手（SYN -&gt; SYN+ACK -&gt; ACK）。<br>如果使用 UDP，则不会有连接建立的过程，而是直接发送数据报。<br>3. 网络层（Network Layer）<br>传输层将数据交给 网络层，指定目标地址 127.0.0.1。<br>网络层检测到 127.0.0.1 属于 环回地址（Loopback Address）：<br>这一地址不会被路由到外部网络。<br>操作系统会将数据包 直接送回本机 处理，而不经过网卡。</p><p>a. ICMP 请求（网络层）生成并发送到环回接口。<br>b. 操作系统直接在内核中将请求转发给接收逻辑，不经过物理网卡。<br>c. 因此，能 <code>ping</code> 通，但数据包仅在内存中处理，不涉及硬件。</p><ul><li><p>127.0.0.1： 是一个 IPv4 地址,  网络层检测到 <code>127.0.0.1</code> 属于 <strong>环回地址（Loopback Address）</strong></p></li><li><p>在支持 IPv6 的系统中，<code>localhost</code> 可能同时映射到 <code>127.0.0.1</code>（IPv4）和 <code>::1</code>（IPv6）。</p><ul><li>如果服务只监听 IPv4，使用 <code>localhost</code> 可能会导致连接失败。</li></ul></li><li><p><strong>性能差异：</strong></p><ul><li>在大多数情况下，<code>localhost</code> 和 <code>127.0.0.1</code> 的性能差异可以忽略不计。</li><li>但在高并发或性能敏感的场景中，直接使用 <code>127.0.0.1</code> 可能更高效。</li></ul></li></ul><hr><h3 id="2-localhost-的请求流程"><strong>2. localhost 的请求流程</strong></h3><ul><li><strong><code>localhost</code> 是主机名</strong>，默认解析为 <code>127.0.0.1</code>，因此其行为与直接使用 <code>127.0.0.1</code> 完全相同。</li><li><strong>请求流程：</strong><ol><li>应用层发起请求（例如访问 <code>http://localhost:8080</code>）。</li><li>DNS 解析将 <code>localhost</code> 转换为 <code>127.0.0.1</code>。</li></ol></li></ul><p><code>localhost</code> 的请求处理方式仍然依赖于网络协议栈, 如果 <code>localhost</code> 完全绕过网络协议栈，直接让应用层处理请求，那它确实更像 <strong>进程间通信（IPC）</strong>，比如：</p><ul><li><strong>Unix Domain Socket（UDS）</strong></li><li><strong>共享内存、管道、消息队列</strong></li></ul><p>但实际情况是：</p><ul><li><code>localhost</code> 依然需要解析为 IP 地址并走 TCP/IP 协议栈。</li><li>只不过数据不会经过物理网卡，而是在 <strong>内核</strong> 中完成回环处理。</li><li>所以它比普通的网络请求快，但比 IPC 方式慢。</li></ul><hr><h3 id="3-localhost-请求-vs-本地进程间通信（IPC）"><strong>3. localhost 请求 vs. 本地进程间通信（IPC）</strong></h3><h4 id="1-相似之处"><strong>(1) 相似之处</strong></h4><ul><li><strong>不依赖物理网络：</strong> 两者都不需要物理网卡或外部网络设备。</li><li><strong>高性能：</strong> 由于数据在内存中处理，延迟极低。</li></ul><h4 id="2-关键区别"><strong>(2) 关键区别</strong></h4><table><thead><tr><th><strong>特性</strong></th><th><strong>localhost（环回接口）</strong></th><th><strong>本地进程间通信（IPC）</strong></th></tr></thead><tbody><tr><td><strong>协议栈</strong></td><td>走完整的网络协议栈（TCP/IP）</td><td>直接通过操作系统提供的 IPC 机制（如管道、共享内存）</td></tr><tr><td><strong>编程接口</strong></td><td>使用 Socket API（如 <code>bind()</code>, <code>listen()</code>）</td><td>使用 IPC 专用 API（如 <code>pipe()</code>, <code>shm_open()</code>）</td></tr><tr><td><strong>兼容性</strong></td><td>与网络通信代码完全兼容</td><td>需要专门设计 IPC 逻辑</td></tr><tr><td><strong>数据封装</strong></td><td>需要处理 TCP/UDP 包头、IP 包头等</td><td>直接传输原始数据</td></tr><tr><td><strong>适用场景</strong></td><td>模拟网络服务、测试客户端-服务端逻辑</td><td>高性能进程间数据交换</td></tr></tbody></table><h4 id="3-为什么环回接口仍要走协议栈？"><strong>(3) 为什么环回接口仍要走协议栈？</strong></h4><ul><li><strong>兼容性：</strong> 开发者可以使用相同的网络编程代码（如 Socket API）测试本地服务，无需修改逻辑。</li><li><strong>隔离性：</strong> 通过端口号隔离不同服务，与远程通信的行为一致。</li><li><strong>安全性：</strong> 防火墙规则可以统一管理环回接口和物理接口的流量。</li></ul><hr><h3 id="4-操作系统的实现优化"><strong>4. 操作系统的实现优化</strong></h3><ul><li><strong>内核优化：</strong> 操作系统会对环回接口的流量进行优化，例如：<ul><li>跳过物理网卡驱动和中断处理。</li><li>减少数据拷贝次数（如从应用层直接传递到接收缓冲区）。</li></ul></li><li><strong>性能对比：</strong><ul><li><strong>环回接口：</strong> 延迟通常在微秒级（μs），吞吐量可达数十 Gbps。</li><li><strong>IPC：</strong> 延迟可低至纳秒级（ns），吞吐量更高（取决于具体 IPC 机制）。</li></ul></li></ul><hr><h3 id="5-实验验证"><strong>5. 实验验证</strong></h3><h4 id="1-使用-Wireshark-抓包"><strong>(1) 使用 Wireshark 抓包</strong></h4><ul><li>抓取环回接口（如 <code>Loopback</code>）的流量，可以看到完整的 TCP/IP 数据包（包括以太网帧头），但这些帧头是虚拟生成的，不会发送到物理网卡。</li></ul><h2 id="Internet-protocol">Internet protocol</h2><p><strong>在当今互联互通的世界中，TCP/IP（Transmission Control Protocol/Internet Protocol，传输控制协议/互联网协议）协议栈构成了现代网络通信的核心。无论是访问网页、发送电子邮件，还是进行视频通话，所有数据的传输都依赖于这一分层协议体系。TCP/IP 协议栈采用分层架构，通常分为四个层次：应用层、传输层、网络层和数据链路层，每一层都承担特定的功能，共同实现可靠、高效的数据传输。网络层（IP）负责寻址和路由，确保数据包能够跨越全球网络到达目标地址；传输层（TCP/UDP）提供数据传输的可靠性和效率，而应用层则承载 HTTP、FTP、DNS 等实际服务，使用户能够便捷地访问互联网资源。</strong></p><p>作为现代网络的基石，TCP/IP 协议栈不仅推动了全球互联网的发展，也成为企业网络、云计算、物联网（IoT）等技术的通信标准。它的开放性和可扩展性使其能够不断适应新的技术需求，持续引领数字时代的网络演进。</p><p><img src="https://cdn.jsdelivr.net/gh/Stan370/stan370.github.io@main/source/_posts/Network/Untitled.png" alt="TCP/IP Protocol Stack"></p><p>Protocol defines format,order of messages was sent, received among network entities ,and  actions taken on transmission,receipt</p><h3 id="OSI">OSI</h3><p>MAC∈datalink LAN层</p><p>常见的网络编程中的问题主要是怎么定位网络上的一台主机或多台主机，另一个是定位后如何进行数据的传输。对于前者，在网络层中主要负责网络主机的定位，数据传输的路由，由IP地址可以唯一地确定Internet上的一台主机。对于后者，在传输层则提供面向应用的可靠（tcp）的或非可靠（UDP）的数据传输机制。</p><p>对于客户端/服务器（C/S）结构。 即通信双方一方作为服务器等待客户提出请求并予以响应。客户则在需要服务时向服务器提出申请。服务器一般作为守护进程始终运行，监听网络端口，一旦有客户请求，就会启动一个服务进程来响应该客户，同时自己继续监听服务端口，使后来的客户也能及时得到服务。</p><p>对于浏览器/服务器（B/S）结构。 客户则在需要服务时向服务器进行请求。服务器响应后及时返回，不需要实时监听端口。</p><p>二者的区别，取决于怎么看他们，<strong>如果使用浏览器，浏览器就是指“客户端”，</strong>“client/server” 和 “browser/server”两种体系结构没有真正的区别，没法比较</p><img src="C:\Users\Stan\AppData\Roaming\Typora\typora-user-images\image-20210920175427765.png" alt="image-20210920175427765" style="zoom:50%;"><h4 id="HTTP-TCP-IP">HTTP TCP IP</h4><p>HTTP规定了每段数据以什么形式表达才是能够被另外一台计算机理解。而TCP所要规定的是数据应该怎么传输才能稳定且高效的传递与计算机之间。</p><p><strong>HTTP</strong>:</p><p>200OK  请求成功  400 bad request</p><p>Idempotent幂等性概念：幂等通俗来说是指不管进行多少次重复操作，都是实现相同的结果。</p><p>2.REST请求中哪些是幂等操作<br>GET，PUT，DELETE都是幂等操作，而POST不是，以下进行分析：</p><p>首先GET请求很好理解，对资源做查询多次，此实现的结果都是一样的。    PUT请求的幂等性可以这样理解，将A修改为B</p><p>SSL</p><blockquote><p>SSL(Secure Sockets Layer 安全套接层)是为网络通信提供安全及数据完整性的一种安全协议。SSL 是 “Secure Sockets Layer” 的缩写，中文意思为“安全套接层”，而 TLS 则是标准化之后的 SSL。</p></blockquote><p>TLS</p><blockquote><p>安全传输层协议（TLS：Transport Layer Security）用于在两个通信应用程序之间提供保密性和数据完整性。该协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake），是更新、更安全的SSL版本。 HTTPS use TLS1.3</p></blockquote><h5 id="HTTP的核心概念"><strong>HTTP的核心概念</strong></h5><p>除了HTTP存在于应用层之外，该协议还有5个特点。</p><ol><li><p>HTTP的标准建立在将两台计算机视为不同的角色：客户端和服务器。客户端会向服务器传送不同的请求(request)，而服务器会对应每个请求给出回应(response)。<strong>无连接</strong></p></li><li><p>HTTP属于<strong>无状态协议(Stateless)</strong>。这表示每一个请求之间是没有相关性的。在该协议的规则中服务器是不会记录任何客户端操作，每一次请求都是独立的。（记录用户浏览行为会通过其他技术实现）</p></li><li><p>客户端的请求被定义在几个动词意义范围内。最长用到的是GET和POST，其他动词还包括DELETE, HEAD等等。</p><h3 id="GET和POST两种http请求方法的区别">[GET和POST两种http请求方法的区别]</h3><p>GET和POST是HTTP请求的两种基本方法, HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接。**GET请求没有body，只有url，请求数据放在url的querystring中；POST请求的数据在body中“。但这种情况仅限于浏览器发请求的场景。**GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。</p><p><strong>GET</strong></p><p>“读取“一个资源。<strong>比如Get到一个html文件。反复读取不应该对访问的数据有副作用。比如”GET一下，用户就下单了，返回订单已受理“，这是不可接受的。没有副作用被称为“幂等“（Idempotent)。</strong></p><p>因为GET因为是读取，就可以对GET请求的数据做缓存。这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），或者做到server端（用Etag，至少可以减少带宽消耗）</p><ul><li>千万不要用GET方法传送密码等敏感信息！（发出的数据会在浏览器地址栏中显示出来）</li></ul><p><strong>POST</strong></p><p>在页面里<form> 标签会定义一个表单。<strong>点击其中的submit元素会发出一个POST请求让服务器做一件事。这件事往往是有副作用的，不幂等的。</strong></form></p><p>不幂等也就意味着不能随意多次执行。因此也就不能缓存。比如通过POST下一个单，服务器创建了新的订单，然后返回订单成功的界面。这个页面不能被缓存。试想一下，如果POST请求被浏览器缓存了，那么下单请求就可以不向服务器发请求，而直接返回本地缓存的“下单成功界面”，却又没有真的在服务器下单。那是一件多么滑稽的事情。</p><p>因为POST可能有副作用，所以浏览器实现为不能把POST请求保存为书签。想想，如果点一下书签就下一个单，是不是很恐怖？。</p><p><strong>POST方法比GET方法更健壮、更安全，而且POST方法对数据大小没有限制。</strong></p></li><li><p>服务器的回应被定义在几个状态码之间：5开头表示服务器错误，4开头表示客户端错误，3开头表示需要做进一步处理，2开头表示成功，1开头表示在请求被接受处理的同时提供的额外信息。</p></li><li><p>不管是客户端的请求信息还是服务器的回应，双方都拥有一块头部信息(Header)。头部信息是自定义，其用途在于传递额外信息（浏览器信息、请求的内容类型、相应的语言）。</p></li></ol><h5 id="持久-or-pipeline-连接">持久 or pipeline 连接</h5><p>**持久连接：**使用同一个TCP连接发送和接受 <strong>多个</strong> http请求/应答；<br>　　**非持久连接：**一个TCP连接只能发送和接受 <strong>一个</strong> http请求/应答；</p><p>stateful contains stateless filter, which is the most flexible but cost more.</p><p><strong>HTTP2.0 多路复用 (Multiplexing)</strong></p><p><strong>多路复用允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息。</strong></p><p><strong>pipeline连接</strong></p><p>HTTP/1.1的新特性，允许在持久连接上可选地使用请求管道。在响应到达之前，可以将多条请求放入队列。当第一条请求通过网络流向服务器时，第二条和第三条请求也可以开始发送了。<strong>在髙时延网络条件下，这样做可以降低网络的环回时间，提高性能。</strong></p><p><strong>管道化连接有如下几条限制：</strong></p><ol><li>客户端必须确认是<strong>持久连接</strong>才能使用管道；</li></ol><p>TCP/IP 意味着 TCP 和 IP 在一起协同工作。TCP 负责应用软件（比如您的浏览器）和网络软件之间的通信。</p><p>Internet 的<strong>传输层</strong>有两个主要协议，互为补充。无连接的是 UDP，它除了给应用程序发送数据包功能并允许它们在所需的层次上架构自己的协议之外，几乎没有做什么特别的事情。面向连接的是 <a href="https://baike.baidu.com/item/TCP/33012">TCP</a>，该协议几乎做了所有的事情。</p><p><em><strong>使用无连接协议可以很方便地支持一对多和多对一通信，而面向连接协议通常都需要多个独立的连接才能做到。但更重要的是，无连接协议是构建面向连接协议的基础</strong>。TCP/IP 是基于一个４层的协议栈，如下图所示：</em></p><p>IP 负责计算机之间的通信。TCP 负责将数据分割并装入 IP 包，然后在它们到达的时候重新组合它们。IP 负责将包发送至接受者。</p><h2 id="Transport-layer"><strong>Transport layer</strong></h2><p>TCP/IP 意味着 TCP 和 IP 在一起协同工作。TCP 负责应用软件（比如您的浏览器）和网络软件之间的通信。</p><p>Internet 的<strong>传输层</strong>有两个主要协议，互为补充。无连接的是 UDP，它除了给应用程序发送数据包功能并允许它们在所需的层次上架构自己的协议之外，几乎没有做什么特别的事情。面向连接的是 <a href="https://baike.baidu.com/item/TCP/33012">TCP</a>，该协议几乎做了所有的事情。</p><ul><li><strong>使用无连接协议可以很方便地支持一对多和多对一通信，而面向连接协议通常都需要多个独立的连接才能做到。但更重要的是，无连接协议是构建面向连接协议的基础</strong>。</li></ul><p>IP 负责计算机之间的通信。TCP 负责将数据分割并装入 IP 包，然后在它们到达的时候重新组合它们。IP 负责将包发送至接受者。</p><p>Here are some key differences between TCP and UDP:</p><ol><li><strong>Reliability</strong>: TCP is a reliable protocol, while UDP is unreliable. TCP provides guaranteed delivery of data packets, ensuring that they arrive at the destination in the correct order and without errors. UDP, on the other hand, does not have built-in mechanisms for error checking, retransmission of lost packets, or ensuring packet ordering. It is up to the application layer to handle these aspects if required.</li><li>Connection-oriented vs. Connectionless: TCP is a connection-oriented protocol, which means it establishes a connection between the sender and receiver before data transmission. It performs a handshake process, establishes a reliable channel, and ensures a secure data transfer. UDP, on the other hand, is connectionless. It does not establish a dedicated connection before data transfer and simply sends packets to the destination without any handshake or setup.</li><li>Packet overhead:开销 TCP has a higher packet overhead compared to UDP. TCP adds additional information to each packet, such as sequence numbers, acknowledgments, and other control flags, which increases the overall size of the transmitted data. UDP has a smaller packet overhead, resulting in less network congestion and lower latency.</li><li>Ordering of packets: TCP guarantees the ordering of packets. If packets arrive out of order, TCP reorders them at the receiver’s end, ensuring that the application layer receives the data in the correct order. UDP does not provide any mechanisms for ordering packets, so the application layer must handle packet ordering if required.</li><li>Flow control and congestion control: TCP implements flow control and congestion control mechanisms to manage the rate of data transmission and avoid network congestion. It dynamically adjusts the transmission rate based on network conditions and ensures that the receiver can handle the incoming data. UDP does not have built-in flow control or congestion control mechanisms, and it’s up to the application layer to manage these aspects if necessary.</li><li>Application suitability: TCP is commonly used for applications that require reliable and ordered data delivery, such as web browsing, email, file transfer, and remote desktop. UDP is suitable for applications that prioritize speed and efficiency over reliability, such as real-time streaming, online gaming, DNS (Domain Name System), and VoIP (Voice over IP).</li></ol><ul><li><p>TCP实现细节</p><p><a href="https://blog.csdn.net/m0_46156900/article/details/113809699%E4%BC%A0%E8%BE%93%E5%B1%82%E6%A6%82%E8%BF%B0%E3%80%81%E4%BC%A0%E8%BE%93%E5%B1%82%E6%9C%8D%E5%8A%A1%E3%80%81%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%92%8C%E8%A7%A3%E5%A4%8D%E7%94%A8%E3%80%81%E6%97%A0%E8%BF%9E%E6%8E%A5%E4%BC%A0%E8%BE%93">https://blog.csdn.net/m0_46156900/article/details/113809699传输层概述、传输层服务、多路复用和解复用、无连接传输</a> UDP</p><h3 id="DEMUX"><strong>DEMUX</strong></h3><p><strong>connectionless</strong>: 主机接收到<strong>UDP</strong> segment (dest port dest IP)</p><p>connection <strong>oriented</strong>:</p><ul><li><strong>服务器能够在一个TCP端口上同时支持多个TCP套接字：</strong><br> 每个套接字由其四元组标识（有不同的源IP和源PORT）</li><li><strong> Web服务器对每个连接客户端有不同的套接字</strong><br> 非持久对每个请求有不同的套接字</li></ul><p>“服务器能够根据源IP地址和源端口号来区分来自不同客户机的报文段。<br>但是套接字与进程之间并非总是有着一一对应的关系。<br>事实上，Web服务器通常一个服务进程可以为每个新的客户机连接创建一个具有新连接套接字的线程。<br>显然，对于这样的服务器，在任意给定的时间内都可能有很多套接字(具有不同的标识)连接到同一个进程。”</p><h3 id="rdt3-0："><strong>rdt3.0：</strong></h3><p>具有比特差错和分组丢失的信道</p><p><strong>新的假设：****下层信道可能会丢失分组（数据或ACK）</strong>(好比之前说的路由器队列排满了，新来的就被drop掉)</p><ul><li><strong> 会死锁</strong></li><li><strong> 机制还不够处理这种状况：</strong><br>• <strong> rdt3.0可以工作，但链路容量比较大的情况下，性能很差 链路容量比较大，一次发一个PDU 的不能够充分利用链路的传输能力</strong></li><li><strong>pipelined protocol</strong></li></ul><p><strong>两种通用的流水线协议：回退N步(GBN)和选择重传(SR)</strong></p><p>go-back-n的一个缺点 *是单个分组端差错能够引起大量分组端重传，许多分组其实没必要重传。*为了解决这个缺点， selective repeat来了</p><p>滑动窗口          (slide window)协议</p><ul><li><strong> 发送缓冲区</strong><br> 形式：内存中的一个区域，落入缓冲区的分组可以发送<br> 功能：用于存放<strong>已发送</strong>，但是没有<strong>未经确认</strong>的分组<br> 必要性：需要重发时可用</li><li><strong>发送缓冲区中的分组</strong><br> 未发送的：落入发送缓冲区的分组，可以连续发送出去；<br> 已发送、等待确认的：发送缓冲区的分组只有得到确认才能删除</li></ul><p>selective repeat：</p><p>!<a href="https://img-blog.csdnimg.cn/20190524220207716.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyNzg5Nw==,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20190524220207716.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDAyNzg5Nw==,size_16,color_FFFFFF,t_70</a></p><p>**sender 端：**接收上层端数据，为 分组 assign 序号，如果 在 window 范围内，则发送，同时为每一个分组起一个逻辑定时器，哪个分组端定时器超时，重传哪个分组。上图中， pkt 2 timeout，只重传 pkt2，对其他 package没有影响。<br>pkt3 发送完会有一个wait的动作，因为现在窗口满了，在收到回复之前不会发送下一个分组。</p><p>TCP fast <strong>retransmit:</strong> if the receiver sends triple duplicate ACK for same  data,  sender resend unacked segment</p><p><strong>receiver 端：<strong>确认每一个正确接收的分组，而不管是否乱序，乱序端分组被缓存，直到丢失分组（即序号更小的分组）全部接收，将这一批分组按序交付给上层。上图中，收到 pkt1，交付，收到 pkt2，交付，收到pkt3，缓存。<br>需要注意的是，为什么sender 端在收到ack0 时会立即发送pk4，但是收到ack3时没有继续往外发送数据呢，原因是receiver端发送ACK3时，已经知道pkt2还未到到，所以在</strong>ACK3中带端 nextsequence 是pkt2，而此时发送端正在等待pkt2的超时（或者ACK2），所以在pkt2超时之前不会有新端package发出。</strong></p><h3 id="TCP-flow-control"><strong>TCP flow control</strong></h3><p>receiver controls the sender that sender will not overflow receiver by transmit too much</p><p>!<a href="https://img-blog.csdnimg.cn/20210217120510616.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20210217120510616.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70</a></p><p><strong>MTU</strong>：<br>Maximum Transmission Unit，最大数据传输单元，网络传输最大报文包；以太网MTU最大值是1500B<br><strong>MSS</strong>：<br>Maximum Segment Size ，TCP提交给IP层最大分段大小，不包含TCP Header和 TCP Option，只包含TCP Payload ，MSS是TCP用来限制application层最大的发送字节数。如果底层物理接口MTU= 1500 byte，则 MSS = 1500- 20(IP Header) -20 (TCP Header) = 1460 byte，如果application 有2000 byte发送，需要两个segment才可以完成发送，第一个TCP segment = 1460，第二个TCP segment = 540.要根据MSS的大小进行切分和加TCP头部信息，变成TCP报文段（segment）<br>·<br>所以，（Message 转换成字节流，再被划分成一个个的MSS）<br>MSS+TCP头部信息+IP头部信息 = MTU(比如以太网MTU1500B)，（“于是就存在一个分片的问题？”什么分片…）</p><p><strong>IP分片</strong></p><p>在TCP/IP分层中，数据链路层用MTU（Maximum Transmission Unit，最大传输单元）来限制所能传输的数据包大小，MTU是指一次传送的数据最大长度，不包括数据链路层数据帧的帧头。当发送的IP数据报的大小超过了MTU时，IP层就需要对数据进行分片，否则数据将无法发送成功。</p><p>一个IP数据报的每个分片都具有自己的IP头部信息，它们都具有相同的标识值，但是具有不同的位偏移，且除了最后一个分片fragflag=0外，其他分片都将设置fragflag=1标志。此外，每个分片的IP头部的总长度字段将被设置为该分片的长度。</p><p>例如，以太网帧的MTU是1500字节，因此它的数据部分最大为1480字节(IP头部占用20字节)。</p><h3 id="Nagle算法"><strong>Nagle算法</strong></h3><p>A problem can occur when an application generates data very slowly.<br> Consider, ssh or telnet that generate data only when a user types.<br> This means (for ssh/telnet) one packet sent every time user hits key          ——&gt; Nagle’s algorithm</p><p>\1. 发送 TCP 发送它接收到的第一条数据 - 无论大小</p><ol><li>发送 TCP 在缓冲区中累积数据并等待以下之一，然后再发送该段： • 接收 TCP 发送确认• 数据已累积以填充最大大小的段</li><li>重复步骤 2 注意：有时应关闭 Nagle 算法——例如当快速交互至关重要并且您希望发送小数据包时</li></ol><p>该算法的优越之处在于它是自适应的，确认到达的越快，数据也就发哦送的越快</p><h3 id="Congestion-control"><strong>Congestion control</strong></h3><ul><li><strong> 非正式的定义:“太多的数据需要网络传输，超过了网络的处理能力”</strong></li><li><strong> 拥塞的表现:</strong><ul><li> 分组<strong>丢失</strong> (路由器缓冲区溢出)</li><li> 分组经历比<strong>较长的延迟</strong>(在路由器的队列中排队)</li></ul></li></ul><p>速率控制方法</p><p>!<a href="https://img-blog.csdnimg.cn/20210218100930516.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20210218100930516.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70</a></p><p>如何控制发送端发送的速率？</p><p> (发送方)维持一个拥塞窗口的值：CongWin（CongestionWindow以字节为单位）<br>它对一个TCP发送方能向网络中发送流量的速率进行了限制。<br> 发送端限制已发送但是未确认的数据量（的上限）:<br>LastByteSent - LastByteAcked &lt;= CongWin<br> 从而粗略地控制发送方的往网络中注入的速率</p><p>TCP reno : loss  indicated by 3 ACKs                  ;</p><p>tcp Tahoe sets cwnd to 1</p><p>rate = cwnd/RTT                          avg TCP throughput = 3Window size /4 RTT</p></li></ul><p>!<a href="https://img-blog.csdnimg.cn/20210216113823842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20210216113823842.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70</a></p><p>在HTTP的规范内，两台计算机的交互被视为request和response的传递。<strong>而在实际的TCP操作中，信息传递会比单纯的传递request和response要复杂。通过TCP建立的通讯往往需要计算机之间多次的交换信息才能完成一次request或response。</strong></p><p>TCP的传输数据的核心是在于将数据分为若干段并将每段数据按顺序标记。标记后的顺序可以以不同的顺序被另一方接收并集成回完整的数据。计算机对每一段数据的成功接收都会做出相应，确保所有数据的完整性。</p><p>TCP在传递数据时依赖于实现定义好的几个标记（Flags）去向另一方表态传达数据和连接的状态：</p><ul><li>F : FIN - 结束; 结束会话</li><li>S : SYN - 同步; 表示开始会话请求</li><li>R : RST - 复位;中断一个连接 P : PUSH - 推送; 数据包立即发送</li><li>A : ACK - 应答 U : URG - 紧急 E : ECE - 显式拥塞提醒回应</li><li>W : CWR - 拥塞窗口减少</li></ul><p><strong>Connection建立&amp; close</strong></p><p>也是基于这些标志TCP可以实现<a href="https://blog.csdn.net/qzcsu/article/details/72861891">三次（three ways handshake）和四次握手 (four ways tear down)</a>。三次握手是初步建立连接的机制，而四次握手则是<strong>断开链接</strong>。两者之间大致操作是一样的，A发出建立链接(SYN)或者断开链接(FIN)的请求，B认可(A CK)其请求然后发出同样的请求给A并等待A的认可。在双方认可后，链接正式成立或者断开。</p><p>!<a href="https://img2020.cnblogs.com/blog/2098532/202105/2098532-20210520103027590-619536232.png">https://img2020.cnblogs.com/blog/2098532/202105/2098532-20210520103027590-619536232.png</a></p><p>!<a href="https://img2020.cnblogs.com/blog/2098532/202105/2098532-20210520103048249-324869987.png">https://img2020.cnblogs.com/blog/2098532/202105/2098532-20210520103048249-324869987.png</a></p><p>1、为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？</p><p>建立连接时，ACK和SYN可以放在一个报文里来发送。而关闭连接时，<strong>被动关闭方可能还需要发送一些数据后</strong>，再发送FIN报文表示同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。</p><p>2、为什么TIME_WAIT状态还需要等2MSL后才能返回到CLOSED状态？</p><p>两个存在的理由：1、无法保证最后发送的ACK报文会一定被对方收到，所以需要重发可能丢失的ACK报文。2、关闭链接一段时间后可能会在相同的IP地址和端口建立新的连接，为了防止旧连接的重复分组在新连接已经终止后再现。2MSL足以让分组最多存活msl秒被丢弃。</p><p>3、为什么必须是三次握手，不能用两次握手进行连接？</p><p>记住服务器的资源宝贵不能浪费! 如果在断开连接后，第一次握手请求连接的包才到会使服务器打开连接，占用资源而且容易被恶意攻击！防止攻击的方法，缩短服务器等待时间。两次握手容易死锁。如果服务器的应答分组在传输中丢失，将不知道S建立什么样的序列号，C认为连接还未建立成功，将忽略S发来的任何数据分组，只等待连接确认应答分组。而S在发出的分组超时后，重复发送同样的分组。这样就形成了<strong>死锁</strong>。</p><h3 id="QUIC">QUIC</h3><p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/83f96e4c-b464-4932-a980-04c73797197a/Untitled.png" alt="Untitled"></p><p>QUIC 的目标是几乎等同于 TCP 连接，但<a href="https://en.wikipedia.org/wiki/Network_delay">延迟</a>大大降低。<a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">它主要通过依赖于对HTTP</a>流量行为的理解的两项更改来实现这一点。<a href="https://en.wikipedia.org/wiki/QUIC#cite_note-ARSnext-20">[20]</a></p><p>第一个变化是大大减少连接建立期间的开销。由于大多数 HTTP 连接都需要<a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS</a>，QUIC 将设置密钥和支持的协议的交换作为初始<a href="https://en.wikipedia.org/wiki/Handshake_(computing)">握手过程</a>的一部分。当客户端打开连接时，响应数据包包含未来数据包使用加密所需的数据。这消除了建立 TCP 连接然后通过附加数据包协商安全协议的需要。其他协议可以以相同的方式提供服务，将多个步骤组合成一个请求-响应。然后，此数据可用于初始设置中的后续请求，以及将以其他方式协商为单独连接的未来请求。<a href="https://en.wikipedia.org/wiki/QUIC#cite_note-ARSnext-20">[20]</a></p><p>第二个变化是使用<a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol">UDP</a>而不是 TCP 作为其基础，其中不包括<a href="https://en.wikipedia.org/wiki/Packet_loss">丢失</a>恢复。相反，每个 QUIC 流都是单独进行流量控制的，丢失的数据在 QUIC 级别而不是 UDP 级别重新传输。这意味着如果一个流中发生错误，如上面的图标示例，<a href="https://en.wikipedia.org/wiki/Protocol_stack">协议栈</a>可以继续独立地为其他流提供服务。这对于提高容易出错的链接的性能非常有用，因为在大多数情况下，在 TCP 注意到数据包丢失或损坏之前可能会收到大量额外数据，并且在更正错误时所有这些数据都被阻止甚至刷新。在 QUIC 中，在修复单个多路复用流时，可以自由处理这些数据。<a href="https://en.wikipedia.org/wiki/QUIC#cite_note-27">[27]</a></p><p>QUIC 还包括许多其他更改，这些更改也可以改善整体延迟和吞吐量。例如，数据包被单独加密，因此它们不会导致加密数据等待部分数据包。这在 TCP 下通常是不可能的，其中加密记录在字节<a href="https://en.wikipedia.org/wiki/Bytestream">流</a>中，协议栈不知道该流中的高层边界。这些可以由运行在顶层的层协商，但 QUIC 的目标是在一次握手过程中完成所有这些。<a href="https://en.wikipedia.org/wiki/QUIC#cite_note-IETF_QUIC_Intro-8">[8]</a></p><p>QUIC 系统的另一个目标是提高网络切换事件期间的性能，例如当移动设备的用户从本地<a href="https://en.wikipedia.org/wiki/Hotspot_(Wi-Fi)">WiFi 热点</a>移动到<a href="https://en.wikipedia.org/wiki/Cellular_network">移动网络</a>时发生的情况。当这种情况发生在 TCP 上时，一个漫长的过程开始，每个现有的连接一个接一个地超时，然后根据需要重新建立。为了解决这个问题，QUIC 包含一个连接标识符，它可以唯一标识与服务器的连接，而不管来源如何。<a href="https://en.wikipedia.org/wiki/IP_address">这允许通过发送始终包含此 ID 的数据包简单地重新建立连接，因为即使用户的IP 地址</a>更改，原始连接 ID 仍然有效。<a href="https://en.wikipedia.org/wiki/QUIC#cite_note-QUICoverview-28">[28]</a></p><p>!<a href="https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/HTTP-1.1_vs._HTTP-2_vs._HTTP-3_Protocol_Stack.svg/336px-HTTP-1.1_vs._HTTP-2_vs._HTTP-3_Protocol_Stack.svg.png">https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/HTTP-1.1_vs._HTTP-2_vs._HTTP-3_Protocol_Stack.svg/336px-HTTP-1.1_vs._HTTP-2_vs._HTTP-3_Protocol_Stack.svg.png</a></p><p>!<a href="https://en.wikipedia.org/w/extensions/ImageMap/resources/desc-20.png?15600">https://en.wikipedia.org/w/extensions/ImageMap/resources/desc-20.png?15600</a></p><p>HTTP/3 与 HTTP/1.1 和 HTTP/2 对比的协议栈</p><p>QUIC 可以在应用程序空间中实现，而不是在<a href="https://en.wikipedia.org/wiki/Operating_system_kernel">操作系统内核</a>中。当数据在应用程序之间移动时，由于<a href="https://en.wikipedia.org/wiki/Context_switch">上下文切换，这通常会调用额外的开销。</a>然而，就 QUIC 而言，协议栈旨在供单个应用程序使用，每个使用 QUIC 的应用程序都有自己的连接托管在 UDP 上。最终差异可能非常小，因为整个 HTTP/2 堆栈的大部分已经在应用程序中（或更常见的是它们的库）。将其余部分放在这些库中，本质上是纠错，对 HTTP/2 堆栈的大小或整体复杂性几乎没有影响。<a href="https://en.wikipedia.org/wiki/QUIC#cite_note-IETF_QUIC_Intro-8">[8]</a></p><p>这种组织允许更容易地进行未来的更改，因为它不需要更改内核<a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)">来</a>进行更新。QUIC 的长期目标之一是添加用于<a href="https://en.wikipedia.org/wiki/Forward_error_correction">前向纠错</a>(FEC) 和改进拥塞控制的新系统</p><h2 id="Network-layer"><strong>Network layer</strong></h2><p>2functions: forwarding <strong>转发:</strong> (是一种局部的概念/功能…数据平面的…依赖于路由表…)将分组从路由器的<strong>输入接口转发到合适的输出接口</strong></p><p>routing: determine the</p><p>1.router examines header fields in all IP datagram</p><p>!<a href="https://img-blog.csdnimg.cn/20210218141705669.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20210218141705669.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70</a></p><p>!<a href="https://img-blog.csdnimg.cn/20210218174446962.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20210218174446962.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70</a></p><h3 id="路由器"><strong>路由器</strong></h3><p><strong>功能</strong></p><ul><li>运行路由算法/协议（RIP，OSPF，BGP）</li><li>将数据报从入口链路转发到出口链路</li></ul><p>router structure:</p><p>!<a href="https://img-blog.csdnimg.cn/2021021815334083.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/2021021815334083.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70</a></p><p>ipv6 IP addr 128bits 16bytes</p><ul><li>实际中的路由器的Router input ports和 output ports <strong>是同一个端口</strong>，</li><li>只是为了方便输入输出端口的讲解才<strong>分成两个“独立的输入输出端口”</strong></li></ul><h3 id="IP"><strong>IP</strong></h3><p>!<a href="https://img-blog.csdnimg.cn/20210218184213704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20210218184213704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70</a></p><p>局域网接入Internet的技术有三种<a href="https://blog.csdn.net/wenqiang1208/article/details/72403785%EF%BC%9A">https://blog.csdn.net/wenqiang1208/article/details/72403785：</a></p><ol><li>直接路由</li><li>代理服务器(proxy)代理服务器（Proxy Server）是一种重要的服务器安全功能，它的工作主要在(OSI)模型的会话层，从而起到防火墙的作用。代理服务器大多被用来连接INTERNET（国际互联网）和Local Area Network（局域网）。<br>代理分类：HTTP代理；socks代理；VPN代理；FTP代理</li><li>网络地址转换(NAT)NAT将自动修改IP报文的源IP地址和目的IP地址，Ip地址校验则在NAT处理过程中自动完成。有些应用程序将源IP地址嵌入到IP报文的数据部分中，所以还需要同时对报文的数据部分进行修改，以匹配IP头中已经修改过的源IP地址。否则，在报文数据部分嵌入IP地址的应用程序就不能正常工作。</li></ol><p><strong>NAT类型：</strong></p><ul><li><strong>NAT0（全锥形NAT）：</strong> 您的设备拥有一个真实的公网IP地址，可以直接与互联网上的其他设备通信，无需经过额外的转换。这是最理想的网络类型，适合需要高性能和公网访问的应用场景。</li><li><strong>NAT1（对称型NAT）：</strong> 您的设备可以通过端口映射与互联网上的其他设备通信，但需要手动配置端口映射规则。相对NAT0来说，性能稍差，但仍能满足大多数应用场景的需求。</li><li><strong>NAT2（端口限制型NAT或锥形NAT）：</strong> 您的设备只能与已建立连接的设备通信，无法主动发起连接。这会限制某些应用的使用，例如P2P下载、部分游戏等。</li><li><strong>NAT3（完全端口限制型NAT）：</strong> 您的设备只能与已建立连接的设备通信，且只能使用特定的端口。这是限制最严格的NAT类型，会对大部分应用造成影响。</li></ul><p>IP   <strong>(Fragmentation &amp; Reassembly)</strong></p><p> 网络链路有MTU(最大传输单元) – 链路层帧所携带的最大数据长度 不同的链路类型 不同的MTU</p><p>如果IP层有一个数据报要传，而且<strong>数据帧的长度比链路层的MTU还</strong>大，<br>那么IP层就需要进行分片( fragmentation)，即把数据报分成若干片，这样每一片就都小于MTU。<br> 最后一个分片标记为0 “重组”只在最终的目标主机进行 IP头部的信息被用于标识，排序相关分片</p><p><strong>IP（专用）地址 只在局部网络中有意义，区分不同的设备</strong><br> 路由器不对目标地址是专用地址的分组进行转发<br> 专用地址范围（A、B、C类都有）不用向isp申请</p><p>!<a href="https://img-blog.csdnimg.cn/20210218205701933.png">https://img-blog.csdnimg.cn/20210218205701933.png</a></p><p> Class A 10.0.0.0-10.255.255.255 MASK 255.0.0.0<br> Class B 172.16.0.0-172.31.255.255 MASK 255.255.0.0<br> Class C 192.168.0.0-192.168.255.255 MASK 255.255.255.0</p><p><strong>分类寻址</strong> (Classful Addressing)：将 IP 地址分为 ABCDE 五类，三个主要类为 ABC 三类，区别在于网络号和主机号的长度，网络号和主机号的划分线在八位字节边界，如 C 类地址前 24 bits 为网络号，后 8 bits 为主机号。<br>子网分类寻址 (Subnetted Classful Addressing)：在子网寻址系统中，通过从主机号中拿取前端部分 bits 作为子网号，用于识别子网，这将原本的两层划分系统（网络号/主机号）被改为三层划分系统（网络号/子网号/主机号）。<br>无类寻址 (Classless Addressing)：将原始的分类寻址抛开，网络号和主机号可以在任意点划分，不需要像分类寻之中那样划分在八位字节边界。这种方案更加灵活有弹性。</p><p><strong>CIDR: Classless InterDomain Routing</strong>（无类域间路由）</p><blockquote><p>网络前缀越短，<br>其地址块所包含的地址数就越多。<br>而在三级结构的IP地址中，划分子网是使网络前缀变长。</p></blockquote><p>VLSM(<a href="https://baike.baidu.com/item/%E5%8F%AF%E5%8F%98%E9%95%BF%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81/9163142">可变长子网掩码</a>) 是为了有效的使用<a href="https://baike.baidu.com/item/%E6%97%A0%E7%B1%BB%E5%88%AB%E5%9F%9F%E9%97%B4%E8%B7%AF%E7%94%B1/15758573">无类别域间路由</a>（CIDR）和路由汇聚(route summary)来控制<a href="https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1%E8%A1%A8/2707408">路由表</a>的大小，它是网络管理员常用的IP寻址技术</p><p>CIDR无类网络是一种相对于有类网络的网络，无类网络IP地址的掩码是变长的。<br>在有类网络的基础上，拿出一部分主机ID作为子网ID。<br>例如：<br>IP地址为192.168.250.44 子网掩码不能是小于24位。<br>因为这是一个C类地址（前3Bytes是网络号），子网掩码只能大于24位。<br>而掩码255.255.248.0（21位）是不符合规定的。<br>·<br>如果一个网络中的主机有100台，<br>那么，可以用子网掩码/25来划分这个C类网络（“192.168.250.0/24”）：<br>划分成192.168.250.0/25 和192.168.250.128/25两个子网。<br>—主机192.168.250.44/25 属于子网192.168.250.0/25。</p><p>Subnet</p><p><strong>子网掩码不能单独存在</strong>，它<strong>必须结合IP地址</strong>一起使用。<br>子网掩码<strong>只有一个作用</strong>，就是将某个IP地址<strong>划分</strong>成<strong>网络地址</strong>和<strong>主机地址</strong>两部分。</p><p>IP地址分配中的几个特定类别，以下是对它们的解释：</p><ol><li><strong>单播地址（Unicast）：</strong><ul><li>单播地址用于一对一通信，表示数据包从一个发送者传输到一个特定的接收者。它是最常见的IP地址类型。</li><li>A、B、C 类地址都是单播地址，分别用于大型网络、中等大小网络和小型网络。</li></ul></li><li><strong>组播地址（Multicast）：</strong><ul><li>组播地址用于一对多通信，表示数据包从一个发送者传输到一个特定的组中的多个接收者。</li><li>D 类地址是组播地址，用于指示数据流向一组设备。多个主机可以通过加入一个特定的组播组来接收这些数据。</li></ul></li><li><strong>广播地址（Broadcast）：</strong><ul><li>广播地址用于一对所有通信，在一个子网或局域网中向所有设备发送数据包。</li><li>在 IPv4 中，广播地址通常是特定的地址，例如全网广播地址为255.255.255.255，用于发送数据包给同一网络中的所有设备。</li></ul></li><li><strong>E 类地址（Reserved）：</strong><ul><li>E 类地址是保留地址，用于未来可能的用途。这个地址空间暂时没有分配给特定用途，被保留在IP地址分配方案中。</li></ul></li></ol><h3 id="路由器-2">路由器</h3><p><strong>功能</strong></p><ul><li>运行路由算法/协议（RIP，OSPF，BGP）</li><li>将数据报从入口链路转发到出口链路</li></ul><h4 id="结构">结构</h4><p><strong>输入端口(input port)：</strong></p><ul><li>物理层：接收物理信号，将其转换为bit</li><li>与数据链路层交互来执行数据链路层功能</li><li>网络层：查找、转发、排队</li><li>非集中式的交换：转发表的副本已发送给每个输入端口，因此，转发决策由输入端口在本地完成<ul><li>根据数据报的目的地址，在输入端口内存的转发表中寻找输出端口</li><li>目标：以线缆一级的速度完成输入端口处理</li><li>队列：如果数据报达到的速率大于处理速率则需要排队</li></ul></li></ul><p>Input queuing caused  by input buffer overflow.</p><p><strong>Output port:  datagram can be lost due to congestion,lack of buffers(arrive rate fabric &gt; transmission rate).</strong></p><p><strong>scheduling discipline: priority scheduling- network neutrality</strong></p><p><strong>交换结构fabric 3种：memory, bus,interconnection network</strong></p><p>交换结构将路由器的输入端口连接到它的输出端口。这种交换结构包含在路由之中，是一个路由器中的"网络"</p><p><strong>输出端口</strong></p><img src="https://img-blog.csdnimg.cn/20210218162449429.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:67%;"><p>输出端口存储从交换结构接收到的分组，并在输出链路上传输这些分组。当一条链路是双向的时，输出端口常与该链路输入端口成对出现在同一线路卡上。</p><ul><li>缓冲区：当交换结构速率较快时，就需要缓存，否则，在遇到拥塞时，会导致分组丢失</li><li>分组调度：先来先服务（FCFS）规则，加权公平排队规则（WFQ），遵循“网络中立”原则，为服务质量保障（QoS）起到关键作用</li></ul><p><strong>数据平面、控制平面</strong></p><p>control plane methods:</p><p>1 traditional router algorithm</p><p>2 software-defined networking (SDN): 在远程的服务器中实现<br>（Compare to the traditional routing algorithm，SDN is much more flexible.</p><p>router structure:</p><p><img src="https://img-blog.csdnimg.cn/2021021815334083.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom: 67%;"><img src="https://lh3.googleusercontent.com/proxy/UbaWC9LZvA2qcCc4sJOaCj1mlbaVV_QzDOfS1prFWQ9qpMrnAiL3i1DGa01YhwvxazVI9pjt1ww82_euDQxWf4n1TER0fHFYcT8KTkaIvpCdWKJ6bw6aGA_yUJfQx4pvTw" alt="TCP/IP Ports and Sockets Explained">ipv6 IP addr 128bits 16bytes</p><ul><li>实际中的路由器的Router input ports和 output ports <strong>是同一个端口</strong>，</li><li>只是为了方便输入输出端口的讲解才<strong>分成两个“独立的输入输出端口”</strong></li></ul><p>longest prefix matching</p><p>TCAM with high speed</p><h5 id="scheduling">scheduling</h5><p>Priority scheduling</p><ul><li><p><strong><a href="https://blog.csdn.net/pzw_0612/article/details/47357221">Round Robin (RR) scheduling（本意环形丝带，其实叫轮询调度</a>）:</strong></p><p><strong>Weighted Fair Queuing (WFQ，加权公平队列):</strong></p></li><li><p>FIFO scheduling</p></li></ul><h3 id="IP-2">IP</h3><img src="https://img-blog.csdnimg.cn/20210218184213704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:80%;"><p>局域网接入Internet的技术有三种<a href="https://blog.csdn.net/wenqiang1208/article/details/72403785%EF%BC%9A">https://blog.csdn.net/wenqiang1208/article/details/72403785：</a></p><ol><li><p>直接路由</p></li><li><p>代理服务器(proxy)代理服务器（Proxy Server）是一种重要的服务器安全功能，它的工作主要在(OSI)模型的会话层，从而起到防火墙的作用。代理服务器大多被用来连接INTERNET（国际互联网）和Local Area Network（局域网）。<br>代理分类：HTTP代理；socks代理；VPN代理；FTP代理</p></li><li><p>网络地址转换(NAT)NAT将自动修改IP报文的源IP地址和目的IP地址，Ip地址校验则在NAT处理过程中自动完成。有些应用程序将源IP地址嵌入到IP报文的数据部分中，所以还需要同时对报文的数据部分进行修改，以匹配IP头中已经修改过的源IP地址。否则，在报文数据部分嵌入IP地址的应用程序就不能正常工作。</p></li></ol><h4 id="IP-分片和重组"><strong>IP 分片和重组</strong></h4><p><strong>(Fragmentation &amp; Reassembly)</strong></p><p> 网络链路有MTU(最大传输单元) – 链路层帧所携带的最大数据长度 不同的链路类型 不同的MTU</p><p>如果IP层有一个数据报要传，而且<strong>数据帧的长度比链路层的MTU还</strong>大，<br>那么IP层就需要进行分片( fragmentation)，即把数据报分成若干片，这样每一片就都小于MTU。<br> 最后一个分片标记为0 “重组”只在最终的目标主机进行 IP头部的信息被用于标识，排序相关分片</p><p><strong>IP（专用）地址</strong> 只在局部网络中有意义，区分不同的设备<br> 路由器不对目标地址是专用地址的分组进行转发<br> 专用地址范围（A、B、C类都有）不用向isp申请</p><p><img src="https://img-blog.csdnimg.cn/20210218205701933.png" alt="在这里插入图片描述"></p><p> Class A 10.0.0.0-10.255.255.255 MASK 255.0.0.0<br> Class B 172.16.0.0-172.31.255.255 MASK 255.255.0.0<br> Class C 192.168.0.0-192.168.255.255 MASK 255.255.255.0</p><p><strong>分类寻址</strong> (Classful Addressing)：将 IP 地址分为 ABCDE 五类，三个主要类为 ABC 三类，区别在于网络号和主机号的长度，网络号和主机号的划分线在八位字节边界，如 C 类地址前 24 bits 为网络号，后 8 bits 为主机号。<br>子网分类寻址 (Subnetted Classful Addressing)：在子网寻址系统中，通过从主机号中拿取前端部分 bits 作为子网号，用于识别子网，这将原本的两层划分系统（网络号/主机号）被改为三层划分系统（网络号/子网号/主机号）。<br>无类寻址 (Classless Addressing)：将原始的分类寻址抛开，网络号和主机号可以在任意点划分，不需要像分类寻之中那样划分在八位字节边界。这种方案更加灵活有弹性。</p><h4 id="编码CIDR">编码CIDR</h4><p><strong>CIDR: Classless InterDomain Routing</strong>（无类域间路由）</p><blockquote><p><strong>网络前缀越短，</strong><br>其地址块所<strong>包含的地址数就越多</strong>。<br>而在三级结构的IP地址中，<strong>划分子网是使网络前缀变长。</strong></p></blockquote><p>VLSM(<a href="https://baike.baidu.com/item/%E5%8F%AF%E5%8F%98%E9%95%BF%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81/9163142">可变长子网掩码</a>) 是为了有效的使用<a href="https://baike.baidu.com/item/%E6%97%A0%E7%B1%BB%E5%88%AB%E5%9F%9F%E9%97%B4%E8%B7%AF%E7%94%B1/15758573">无类别域间路由</a>（CIDR）和路由汇聚(route summary)来控制<a href="https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1%E8%A1%A8/2707408">路由表</a>的大小，它是网络管理员常用的IP寻址技术</p><p>CIDR无类网络是一种相对于有类网络的网络，无类网络IP地址的掩码是变长的。<br>在有类网络的基础上，拿出一部分主机ID作为子网ID。<br>例如：<br>IP地址为192.168.250.44 子网掩码不能是小于24位。<br>因为这是一个C类地址（前3Bytes是网络号），子网掩码只能大于24位。<br>而掩码255.255.248.0（21位）是不符合规定的。<br>·<br>如果一个网络中的主机有100台，<br>那么，可以用子网掩码/25来划分这个C类网络（“192.168.250.0/24”）：<br>划分成192.168.250.0/25 和192.168.250.128/25两个子网。<br>—主机192.168.250.44/25 属于子网192.168.250.0/25。</p><h5 id="subnet">subnet</h5><p><strong>子网掩码不能单独存在</strong>，它<strong>必须结合IP地址</strong>一起使用。<br>子网掩码<strong>只有一个作用</strong>，就是将某个IP地址<strong>划分</strong>成<strong>网络地址</strong>和<strong>主机地址</strong>两部分。</p><p>A、B、C类的地址叫做单播地址（unicast）——“我到你”。而D 类地址叫组播地址（multicast）——“我到这个D类组的”…<br>还以一种叫广播地址（broadcast）——“我到所有”，一般在局域网内部<br>E 类地址预留的（Reserved for future use） （但存方寸地,留与子孙耕）<br>在<strong>路由信息的通告的过程当中</strong>，还不断地做<strong>路由聚集</strong>。<strong>减少表项，路由减负。</strong><br><strong>路由聚集的作用：</strong><br><img src="https://img-blog.csdnimg.cn/20210218212207583.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L20wXzQ2MTU2OTAw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:67%;"></p><h5 id="DHCP">DHCP</h5><p>第一步：Client通过广播（broadcast）发送DHCP Discover 报文，Look for服务器端</p><p>第二步：Server通过单播（unicast）发送DHCP Offer 报文向客户端提供IP地址等网络信息</p><p>第三步：Client通过广播<strong>DHCP Request 报文告知服务器端本地选择使用哪个IP地址</strong></p><p>第四步：Server通过DHCP Ack报文告知客户端IP地址是合法可用的<br>DHCP返回：<em>ip地址、网关（router、子网掩码、DNS</em></p><h5 id="NAT">NAT</h5><p>network address translation</p><p><strong>动机</strong>（使用NAT的原因）: 本地网络只有一个有效IP地址:<br>不需要从ISP分配一块地址，可用一个IP地址用于所有的（局域网）设备 –省钱<br><strong>可以在局域网改变设备的地址情况下而无须通知外界</strong><br>可以改变ISP（地址变化）而不需要改变内部的设备地址<br>局域网内部的设备没有明确的地址，对外是不可见的 –安全</p><ul><li><strong>如果流量从Inside端口进来，那么先执行路由，后执行NAT(本地 到 全局)。</strong></li><li><strong>如果流量从Outside端口进来，那么先执行NAT(全局 到 本地)，后执行路由。</strong></li></ul><h4 id="Data-plane">Data plane</h4><p>a set of match-action rules send by a controller.</p><p>traditional: longest prefix match forwarding <strong>vs</strong>. SDN allows more flexibility</p><p><strong>openFlow abstraction: match+action</strong></p><ul><li><p>Match，匹配数据包头部</p></li><li><p>Action，根据匹配的结果，做相应的操作，比如修改MAC地址，ACL之类</p></li><li><p>OpenFlow能够启动远程的控制器，经由<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E4%BA%A4%E6%8D%A2%E5%99%A8/8534019">网络交换器</a>，决定网络数据包要由何种路径通过<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E4%BA%A4%E6%8D%A2%E6%9C%BA/2105356">网络交换机</a>。这个协议的发明者，将它当成<a href="https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C">软件定义网络</a>（Software-defined networking）的启动器。 [1] OpenFlow允许从远程控制网络交换器的<a href="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E5%8C%85">数据包</a>转送表，透过新增、修改与移除数据包控制规则与行动，来改变数据包转送的路径。比起用<a href="https://baike.baidu.com/item/%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%E8%A1%A8">访问控制表</a>(ACLs) 和路由协议，允许更复杂的流量管理。同时，OpenFlow允许不同供应商用一个简单，开源的协议去远程管理交换机（通常提供专有的接口和描述语言）。</p><p>OpenFlow<a href="https://baike.baidu.com/item/%E5%8D%8F%E8%AE%AE">协议</a>用来描述控制器和交换机之间交互所用信息的标准，以及控制器和交换机的接口标准。协议的核心部分是用于OpenFlow协议信息结构的集合。OpenFlow<a href="https://baike.baidu.com/item/%E5%8D%8F%E8%AE%AE%E6%94%AF%E6%8C%81">协议支持</a>三种信息类型：Controller-to-Switch，Asynchronous和Symmetric，每一个类型都有多个子类型。Controller-to-Switch信息由控制器发起并且直接用于检测交换机的状态。Asynchronous信息由交换机发起并通常用于更新控制器的网络事件和改变交换机的状态。Symmetric信息可以在没有请求的情况下由控制器或交换机发起。</p></li></ul><h4 id="Control-plane">Control plane</h4><p>why logically centralized control plane?</p><p>控制平面在物理上与转发平面分离，控制软件使用开放接口（例如OpenFlow）对转发平面（例如，交换机和路由器）进行编程。</p><h3 id=""></h3><p><strong>data plane:  mainly forwarding . each router contains a flow table by a centralized routing controller</strong></p><ul><li></li></ul><h3 id="routing-protocol">routing protocol</h3><h4 id="link-state">link state</h4><ol><li>​                         <strong>贪心算法</strong>        <strong>global: all routers have complete topology</strong></li></ol><p>Dijkstra算法</p><p><strong>condition：any 路径&gt;0  &amp; 单源 已知出发点</strong></p><p>/临近，标记！<img src="C:\Users\Stan\AppData\Roaming\Typora\typora-user-images\image-20211222155611157.png" alt="image-20211222155611157" style="zoom:50%;"></p><p>直到全部点标记结束，回溯找出路径</p><h4 id="distance-vector">distance vector</h4><ol start="2"><li><p>距离矢量算法(distance vector routing)                 <strong>动态规划</strong>  decentralized<br>  每个路由器维护一张表（即一个矢量），表中列出了当前已知的到每个目标的最佳距离，以及所用的链路。这些表通过邻居之间交换信息而不断被更新，最终每个路由器都了解到达每个目的地的最佳链路。也叫分布式Bellman-Ford路由算法</p><p>可以参考：距离矢量算法简介 和 距离矢量算法示例</p><p>这个算法存在一个严重的缺陷：虽然它总是能够收敛到正确的答案，但<strong>速度可能非常慢</strong>。尤其是，它对于好消息的反应非常迅速，而对于坏消息的反应异常迟钝。这个算法存在无穷计数的问题。可扩展性很差，越大的网络收敛的越慢。而且，会占用比较大的网络带宽。</p></li></ol><p>相比于距离矢量算法，<strong>链路状态路由算法需要更多的内存和计算</strong>，在大型网络中运行这个算法依然是个问题。不过，在许多现实场合，链路状态路由算法工作得非常好，因为它没有慢收敛得问题。</p><p>OSPF和IS-IS的出现，许多人认为RIP（distance vector）已经过时了。但事实上RIP也有它自己的优点。对于小型网络，RIP就所占带宽而言开销小，易于配置、管理和实现，并且RIP还在大量使用中。链路状态路由算法被广泛应用于实际网络中。IS-IS，Intermediate System-Intermediate System，被很多的ISP使用。后来它被ISO采纳用于OSI协议；然后它被修改多次以便能够处理多种协议，比如IP协议。<strong>OSPF，Open Shortest Path First，是另一个主流的链路状态协议</strong>。</p><h3 id="AS">AS</h3><p><strong>Intra-AS routing:         aka IGP</strong></p><p><strong>OSPF</strong>(Open Shortest Path First<a href="https://baike.baidu.com/item/%E5%BC%80%E6%94%BE%E5%BC%8F%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E4%BC%98%E5%85%88/8966505">开放式最短路径优先</a>）是一个<a href="https://baike.baidu.com/item/%E5%86%85%E9%83%A8%E7%BD%91%E5%85%B3%E5%8D%8F%E8%AE%AE/167192">内部网关协议</a>(Interior Gateway Protocol，简称IGP），用于在单一<a href="https://baike.baidu.com/item/%E8%87%AA%E6%B2%BB%E7%B3%BB%E7%BB%9F">自治系统</a>（autonomous system,AS）内决策<a href="https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1">路由</a>。是对<a href="https://baike.baidu.com/item/%E9%93%BE%E8%B7%AF%E7%8A%B6%E6%80%81%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/1219386">链路状态路由协议</a>的一种实现，隶属内部网关协议（IGP），故运作于自治系统内部。著名的迪克斯彻（Dijkstra）算法被用来计算<a href="https://baike.baidu.com/item/%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E6%A0%91">最短路径树</a>。OSPF支持负载均衡和基于服务类型的选路，也支持多种路由形式，如特定主机路由和子网路由等</p><p>inter-AS routing:</p><p>job: learn which dests are reachable in other inter-AS system<strong>系统间传播(eBGP) ,</strong></p><p>and propagate the reachability info to all routers in AS1.<strong>内(iBGP)</strong></p><p>intra-AS: <strong>IGP</strong>             CONTAIN: RIP OSPF IGRP</p><p><strong>BGP</strong> inter domain routing protocol</p><p>网关就是路由器的IP</p><h3 id="SDN-control-plane">SDN control plane</h3><p>logically centralized : easy management:avoid router mis configurations</p><h3 id="ICMP">ICMP</h3><p>ICMP enables a router or destination host to communicate with a source host, for example,to report an error in datagram processing. (2 marks)Path MTU discovery uses the Type-3 Destination Unreachable ICMP messages as follows: TCP negotiates initial MTU size – usually TCP/IP sends datagram with Don’t Fragment flag set If datagram is too large an ICMP Destination Unreachable is received Reduce Maximum Transfer Unit.</p><p>Internet控制<a href="https://baike.baidu.com/item/%E6%8A%A5%E6%96%87/3164352">报文</a>协议。它是<a href="https://baike.baidu.com/item/TCP%2FIP%E5%8D%8F%E8%AE%AE%E7%B0%87">TCP/IP协议簇</a>的一个子协议，用于在IP<a href="https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA/455151">主机</a>、<a href="https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1">路由</a>器之间传递控制消息。控制消息是指<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E9%80%9A">网络通</a>不通、<a href="https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA/455151">主机</a>是否可达、<a href="https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1/363497">路由</a>是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。ICMP使用IP的基本支持，就像它是一个更高级别的协议，但是，ICMP in IP datagram.</p><p>above “IP” error reporting and echo request/reply</p><p><strong>traceroute</strong> (<a href="https://baike.baidu.com/item/Windows/165458">Windows</a> 系统下是<a href="https://baike.baidu.com/item/tracert/7578188">tracert</a>) 命令利用<a href="https://baike.baidu.com/item/ICMP/572452">ICMP</a> 协议定位您的计算机和目标计算机之间的所有<a href="https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1%E5%99%A8/108294">路由器</a>。TTL 值可以反映数据包经过的路由器或网关的数量，通过操纵独立ICMP 呼叫报文的TTL 值和观察该报文被抛弃的返回信息，traceroute命令能够遍历到数据包传输路径上的所有路由器。</p><h2 id="Datalink-layer">Datalink layer</h2><h3 id="Service">Service</h3><p><strong>组帧framing,链路接入 link access</strong></p><p>封装数据报构成数据帧，加首部和尾部帧同步</p><p>如果是共享介质，需要解决信道接入</p><p>帧首部的“MAC”地址，用于标识帧的源和目的</p><ul><li>不同于IP地址</li></ul><p><strong>相邻结点间可靠交付</strong></p><ul><li>在低误码率的有线链路很少采用</li></ul><p><strong>流量控制</strong></p><ul><li>协调相邻的发送结点和接收</li></ul><p><strong>差错纠正</strong></p><ul><li>接收端直接纠正比特差错</li></ul><p><strong>全双工和半双工通信控制</strong></p><ul><li>全双工：链路两端结点同时双向传输</li><li>半双工：链路两端结点交替双向传输</li></ul><p><strong>MAC地址</strong>（<strong>英语：Media Access Control Address）</strong>，直译为<strong>媒体存取控制位址</strong>，也称为<strong>局域网地址</strong>（LAN Address），<strong>MAC位址</strong>，<strong>以太网地址</strong>（Ethernet Address）或<strong>物理地址</strong>（Physical Address），它是一个用来确认网络设备位置的位址。在<a href="https://baike.baidu.com/item/OSI%E6%A8%A1%E5%9E%8B">OSI模型</a>中，第三层网络层负责<a href="https://baike.baidu.com/item/IP%E5%9C%B0%E5%9D%80">IP地址</a>，第二层数据链路层则负责MAC位址 [1] 。MAC地址用于在网络中唯一标示一个<a href="https://baike.baidu.com/item/%E7%BD%91%E5%8D%A1">网卡</a>，一台设备若有一或多个网卡，则每个网卡都需要并会有一个唯一的MAC地址</p><p>循环冗余检验CRC(Cyclic Redundancy Check)</p><h3 id="Multiple-access-protocol">Multiple access protocol</h3><p>多路访问控制协议</p><p>冲突(collision)：结点同时接收到两个或者多个信号→接收失败！</p><p>MAC协议采用分布式算法决定结点如何共享信道，即决策结点何时可以传输数据。</p><p>其必须基于信道本身，通信信道共享协调信息。无带外信道用于协调。</p><ul><li><strong>信道划分(channel partitioning)MAC协议</strong></li></ul><p><strong>TDMA: time division multiple access</strong></p><p>TDM 将时间划分为时间帧(timeframe),并进一步划分每个时间帧为N个时隙(slot)</p><p>每个站点在每个时间帧，占用固定长度的时隙(长度=分组传输时间)；未用时隙空闲(idle)</p><p>如图：6站点LAN，134传输分组，256空闲</p><p><a href="https://images2018.cnblogs.com/blog/1424868/201807/1424868-20180712103350498-1397118573.png"><img src="https://images2018.cnblogs.com/blog/1424868/201807/1424868-20180712103350498-1397118573.png" alt="img"></a></p><p><strong>FDMA: frequency division multiple access</strong></p><p>信道频谱划分为若干频带(frequency bands)</p><p>每个站点分配一个固定的频带，不会冲突但信道利用率可能不高；无传输频带空闲</p><p>如图：6站点LAN, 134频带传输数据，256频带空闲。</p><p><a href="https://images2018.cnblogs.com/blog/1424868/201807/1424868-20180712103357376-1532136065.png"><img src="https://images2018.cnblogs.com/blog/1424868/201807/1424868-20180712103357376-1532136065.png" alt="img" style="zoom:67%;"></a></p><h4 id="Random-access-protocol">Random access protocol</h4><p>包括 ALOHA,CSMA,CSMA/CA,CSMA/CD             (t<em>ransmit entire frame</em>)</p><p>Specify 如何检测collision 如何恢复</p><h5 id="slotted-ALOHA">slotted ALOHA</h5><p>结点只能在时隙开始时刻发送帧，当结点有新的帧时在下一个时隙(slot)发送如果2个或2个以上结点在同一时隙发送帧，结点即检测到冲突.如果无冲突：该结点可以在下一个时隙继续发送新的帧.  如果冲突：该结点在下一个时隙以概率p重传该帧，直至成功.Slotted aloha reduces the number of collisions to half and doubles the efficiency of pure aloha.</p><p>** pure ALOHA**</p><p>no synchronization(CLOCK) but only half as efficient as slooted</p><p><strong>载波侦听多路访问协议 CSMA(carrier sense multiple access)协议</strong></p><p>Listen before transmit</p><h5 id="CSMA-CD">CSMA/CD</h5><p>easy in wired LAN (ethernet)     <strong>reduce channel wastage, improve effiency</strong></p><p><strong>避免冲突的载波侦听多路访问协议  CSMA/CA(CSMA with Collision Avoidance)协议</strong></p><p><strong>802.11无线</strong>局域网中，不能像CSMA/CD那样，边发送、边检测冲突，原因为：</p><p>（1）检测碰撞的能力要求站点具有同时发送（站点自己的信号）和接收（检测其他站点是否也在发送）的能力。因为在802. 11适配器上，接收信号的强度通常远远小于发送信号的强度，制造具有检测碰撞能力的硬件代价较大。</p><p>802.11发送端：</p><p>（1）如果监听到信道空闲了分布式帧间间隔DIFS后，则在发送整个帧（发送的同时不检测冲突）</p><p>发送端首先利用CSMA向BS发送一个很短的请求发送（request-to-send，RTS）控制帧预约信道，而不是随机发送数据帧，利用小预约帧避免长数据帧的冲突。RTS帧仍然可能彼此冲突（但RTS帧很短）</p><p>AP广播一个很短的允许发送（clear-to-send，CTS）控制帧作为对RTS的响应，CTS帧可以被所有结点接收，以消除隐藏站影响</p><p>发送端可以发送数据帧，其他结点推迟发送</p><p>（2）如果监听到信道忙，则选取随机回退值</p><p>​       当信道空闲时，计时器倒计时;       当计时器超时时，发送帧</p><p>（3）如果没有收到ACK，则增加随机退避间隔时间，重复（2）</p><p>802.11接收端：</p><p>如果正确接收帧，则在延迟短帧间间隔SIFS后，向发送端发送ACK（由于存在隐藏站问题）</p><h3 id="ARP">ARP</h3><p><strong>MAC(LAN,or physical or ethernet) address and ARP</strong></p><p>48 MAC address in <strong>NIC</strong> ROM</p><p>MAC flat address <strong>portable</strong> (IP hierarchical not portable)</p><p>地址解析协议，即ARP（Address Resolution Protocol），是根据<a href="https://baike.baidu.com/item/IP%E5%9C%B0%E5%9D%80">IP地址</a>获取<a href="https://baike.baidu.com/item/%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80/2129">物理地址</a>的一个<a href="https://baike.baidu.com/item/TCP%2FIP%E5%8D%8F%E8%AE%AE">TCP/IP协议</a>。<a href="https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA/455151">主机</a>发送信息时将包含目标IP地址的ARP请求广播到<strong>局域网</strong>络上的所有主机，并接收返回消息，以此确定目标的物理地址.  <strong>PLUG and PLAY</strong></p><p>802.11 all use CSMA/CA</p><h3 id="LAN">LAN</h3><img src="C:\Users\Stan\AppData\Roaming\Typora\typora-user-images\image-20211222203321725.png" alt="image-20211222203321725" style="zoom:67%;"><h3 id="switch">switch</h3><h4 id="self-learning-plug-and-play">self learning plug and play</h4><p>frame forwarding, storing ; don’t need to be configured</p><h3 id="VLAN">VLAN</h3><p>建立<strong>逻辑</strong>上独立的虚拟网络：于是交换机可以很方便实现<strong>虚拟局域网</strong><br><strong>将连在Switch上的站点更具自己的喜好划分逻辑组</strong>：且与物理位置无关<br><strong>VLAN隔离广播域</strong> ：于是也可以对网络安全隔离、控制广播风暴</p><p>一般接终端设备使用access port 需要多VLAN透传的使用trunk port</p><h3 id="MPLS">MPLS</h3><p>是一种在开放的通信网上利用标签引导数据高速、高效传输的新技术。多协议的含义是指<em>MPLS</em>不但可以支持多种网络层层面上的协</p><p>goal to fast lookup and borrow ideas from VC</p><h3 id="security-management">security management</h3><p>FIrewall</p><p>stateless pkt filter, application gateways</p><p>stateful contains stateless filter, which is the most flexible but cost more.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;1-环回地址（127-0-0-1）的请求流程&quot;&gt;&lt;strong&gt;1. 环回地址（127.0.0.1）的请求流程&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&quot;1-协议栈的处理&quot;&gt;&lt;strong&gt;(1) 协议栈的处理&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;s</summary>
      
    
    
    
    
    <category term="计算机网络" scheme="https://stan370.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>美剧硅谷的middle-out algorithm 压缩算法</title>
    <link href="https://stan370.github.io/2025/02/06/shannon/"/>
    <id>https://stan370.github.io/2025/02/06/shannon/</id>
    <published>2025-02-06T08:23:06.000Z</published>
    <updated>2025-03-19T12:12:05.249Z</updated>
    
    <content type="html"><![CDATA[<p>在当今数据驱动与互联网高速发展的时代，概率论、数理统计以及信息论构成了理解和应对不确定性、优化数据传输以及实现高效压缩算法的数学基础。这三大领域不仅为金融风险管理、临床试验设计、机器学习等提供了理论支持，同时也奠定了现代通信与数据压缩技术的基石。</p><p>最近在观看美剧 Silicon Valley 时，我深有感触：剧中展示的技术——例如 Pied Piper 团队所研究的压缩算法，虽然戏剧化处理，但实际上反映了现实世界中信息理论的精髓，比如香农极限（Shannon Limit，也称为信息熵极限）。这使我联想到自己曾经研究过的信息论相关内容，尤其是自信息量、无损压缩以及带噪信道中的通信极限等问题。<br>So, 美剧硅谷中的The middle-out algorithm 压缩算法真能实现吗？我们或许需要一些背景知识</p><h3 id="概率论">概率论</h3><p>概率论是研究随机现象规律的数学分支，主要涉及<strong>概率</strong>、<strong>随机变量</strong>、<strong>概率分布</strong>等基本概念。它帮助我们量化随机事件发生的可能性。例如，正态分布、泊松分布和指数分布等模型被广泛用于描述现实世界中的不确定现象。最初源于17世纪的赌博问题，帕斯卡和费马等人的工作为这一学科奠定了基础。</p><h3 id="数理统计">数理统计</h3><p>数理统计则是应用概率论来收集、分析、解释数据，并进行推断和决策的学科。它包含了抽样理论、参数估计、假设检验、回归分析等方法，帮助我们从数据中提取信息，并对总体情况进行科学推断。高斯、费舍尔等人在19世纪末到20世纪初的工作，使得数理统计逐步形成了完整的理论体系。<br>统计方法（例如假设检验、回归分析、抽样技术）使我们能够从大量数据中提取有价值的信息，支撑科学决策与实验设计。</p><h3 id="信息论">信息论</h3><p>信息论是20世纪中叶由香农创立的学科，主要研究信息的量化、存储和传输。其核心概念包括<strong>熵</strong>（衡量不确定性）、<strong>自信息量</strong>（衡量单个事件所携带的信息大小）以及<strong>互信息</strong>（衡量两个变量之间的信息共享）。香农提出的香农极限（Shannon Limit）揭示了在带噪信道中实现无误差通信的理论上限，这一理论不仅对通信工程产生深远影响，也为数据压缩、密码学、机器学习等领域提供了理论依据。</p><h2 id="概率论、数理统计与信息论之间的联系">概率论、数理统计与信息论之间的联系</h2><ol><li><p><strong>理论基础</strong><br>概率论为数理统计提供了坚实的理论基础。统计学中的许多方法，例如假设检验、参数估计和回归分析，都依赖于概率模型。没有概率论的严谨定义和计算方法，统计推断就无从谈起。</p></li><li><p><strong>信息论的依托</strong><br>信息论中的熵、互信息等概念同样是建立在概率分布的基础上。例如，一个离散随机变量 (X) 的熵定义为<br><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.663ex;" xmlns="http://www.w3.org/2000/svg" width="27.873ex" height="2.36ex" role="img" focusable="false" viewBox="0 -750 12319.7 1043.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(888,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1277,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(2129,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2795.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(3851.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="munder" transform="translate(4796.2,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g><g data-mml-node="mi" transform="translate(6506.4,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(7257.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(7646.4,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(8218.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(8774,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(10052,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(10218.7,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(10969.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(11358.7,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(11930.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container><br>这不仅衡量了 (X) 的不确定性，也是无损压缩理论的理论下界。最大熵原理在统计建模和模型选择中也有广泛应用，它主张在满足已知条件下，选择熵最大的分布以避免引入不必要的假设。<br>带噪信道通信：香农极限揭示了在给定带宽和信噪比下，信道的最大信息传输速率。设计高效的信道编码（如 LDPC 码）可以帮助系统接近这一极限，从而在5G、卫星通信等领域实现无误差传输（Shannon, 1948）。</p></li><li><p><strong>实际应用中的融合</strong></p><ul><li><strong>数据压缩与通信</strong>：在数据压缩中，我们追求尽可能接近信息熵下界的编码效率。理想情况下，无损压缩的平均码长应接近源信息熵。而在带噪信道通信中，香农极限为设计信道编码提供了理论上限，指导我们在有限带宽和信噪比下实现尽可能高的传输速率。<br><strong>数据压缩</strong>能够实现是因为多数现实世界的数据都有<a href="https://zh.wikipedia.org/w/index.php?title=%E7%BB%9F%E8%AE%A1%E5%86%97%E4%BD%99&amp;action=edit&amp;redlink=1"><strong>统计冗余</strong></a>。例如，字母“e”在英语中比字母“z”更加常用，字母“q”后面是“z”的可能性非常小。<a href="https://zh.wikipedia.org/wiki/%E9%9D%9E%E7%A0%B4%E5%A3%9E%E6%80%A7%E8%B3%87%E6%96%99%E5%A3%93%E7%B8%AE"><strong>无损数据压缩</strong></a>通常利用了统计冗余，这样就能更加简练地、但仍然是完整地表示发送方的数据。<strong>真正随机的数据是不可能通过压缩来减小文件大小的。在这种情况下，数据没有可预测的模式或重复性,每个数据点都是独立的。</strong></li></ul></li></ol><h2 id="数据压缩">数据压缩</h2><p><strong>1. 有损压缩（Lossy Compression）:</strong></p><p>有损压缩是一种方法，其中一些数据被故意丢失，以减小文件的大小。这种方法通常用于图像、音频和视频数据，其中一些信息损失后人的感知不易察觉。</p><p><strong>原理：</strong></p><ul><li><strong>去除冗余信息：</strong> 有损压缩算法检测并删除不太重要的数据，如音频中的高频噪音或图像中的微小细节。</li><li><strong>量化：</strong> 在音频和视频压缩中，数值可以被量化为较低的精度，从而减小数据量。</li><li><strong>子采样和色度抽样：</strong> 在图像和视频压缩中，可以减小像素数量或颜色信息的精度。</li><li><strong>离散余弦变换（DCT）：</strong> 在图像和音频压缩中，DCT 可将数据转换为频域表示，以减少高频成分。</li></ul><p><strong>2. 无损压缩（Lossless Compression）:</strong></p><p>无损压缩是一种方法，其中压缩后的数据可以完全还原为原始数据，不会丢失任何信息。这种方法适用于需要维护数据完整性的情况，如文档、数据库和程序文件。</p><p><strong>原理：</strong></p><ul><li><strong>重复数据删除：</strong> 无损压缩算法通常检测和删除数据中的重复内容，例如相邻的相同字符或字符串。</li><li><strong>字典编码：</strong> 该方法使用字典或字典表，将常见的字符串存储为字典条目，然后用较短的引用替换原始数据。</li><li><strong>霍夫曼编码：</strong> 霍夫曼编码是一种变长编码技术，将常见字符映射到较短的编码，不常见字符映射到较长的编码。</li><li><strong>算术编码：</strong> 算术编码使用概率模型来将字符序列转换为一个大的数字，以减小数据的大小。<br>压缩算法的基本流程<br>目前成熟的无损压缩算法一般分为两大步骤：</li></ul><ol><li><strong>建模</strong>：利用统计模型（如概率分布、字典构建、上下文模型）对数据进行建模。</li><li><strong>编码</strong>：利用熵编码（如 Huffman 编码、算术编码或现代的上下文自适应二进制算术编码）实现数据压缩。</li></ol><p><strong>middle-out 的概念解析</strong><br>“Middle-out”这一命名暗示了算法在数据处理过程中可能采取了一种不同于传统自左至右或者自右至左的策略，而是从数据的“中间”开始处理，然后向两端扩展。可能的假设包括：</p><ul><li><strong>数据分割与局部统计</strong>：如果数据在中间部分具有更明显的冗余或统计规律，先对中间部分进行压缩再向外扩展，可能在某些特定数据结构中取得更好的局部压缩效果。</li><li><strong>并行处理</strong>：从数据中心向两端分割可能利于并行处理，在多核系统上提高压缩速度，但这主要针对速度优化而非压缩比的根本提升。</li><li><strong>动态字典更新</strong>：一种设想是算法在“中间”构建核心字典或模型，然后将该字典扩展到整个数据中，利用全局与局部信息的结合来提升压缩效率。但这种方法本质上仍受限于数据的统计特性和信息熵。<br>但是</li><li><strong>数据依赖性</strong>：大多数数据文件的冗余分布并非在中间部分集中，而是与数据结构、文件格式密切相关。针对某一类数据进行“中间优先”的处理可能适用于某些特定场景，但难以普适。</li><li><strong>算法复杂度</strong>：若需要在中间先构建全局统计模型，再向两侧扩展，算法设计和实现上的复杂性会大幅增加，而且实际收益可能不明显。<br>无损数据压缩的压缩率不足以处理庞大体积的音视频数据，但如果允许一定程度的<a href="https://zh.wikipedia.org/w/index.php?title=%E4%BF%9D%E7%9C%9F%E5%BA%A6&amp;action=edit&amp;redlink=1">保真度</a>损失，那么还可以实现进一步的压缩。<br>在无损压缩中，我们希望将数据编码为尽可能短的比特串。根据香农的第一定理，一个符号序列的最优编码长度下界正是其信息熵  <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.663ex;" xmlns="http://www.w3.org/2000/svg" width="45.341ex" height="2.36ex" role="img" focusable="false" viewBox="0 -750 20040.8 1043.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(888,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1277,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(2129,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2795.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munder" transform="translate(3851.6,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g><g data-mml-node="mi" transform="translate(5561.7,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(6312.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6701.7,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(7273.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7884.9,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(8385.1,0)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g><g data-mml-node="mo" transform="translate(8889.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(9278.1,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(9850.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(10516.9,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(11572.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="munder" transform="translate(12517.4,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g><g data-mml-node="mi" transform="translate(14227.5,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(14978.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(15367.5,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(15939.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(16495.2,0)"><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(278,0)"></path><path data-c="67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(17773.2,0)"><path data-c="2061" d=""></path></g><g data-mml-node="mi" transform="translate(17939.8,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(18690.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(19079.8,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(19651.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container><br>然而，经常有一些文件不能被有损数据压缩压缩，实际上对于不含可以辨别样式的数据任何压缩算法都不能压缩。另外，试图压缩已经经过压缩的数据通常得到的结果实际上是增加数据。</li></ul><p>实际上，有损数据压缩也会最终达到不能工作的地步。例如一个极端的例子：压缩算法每次去掉文件最后一个字节，那么经过这个算法不断的压缩直至文件变空，压缩算法将不能继续工作。</p><p>由于可以帮助减少如<a href="https://zh.wikipedia.org/wiki/%E7%A1%AC%E7%9B%98">硬盘</a>空间与连接<a href="https://zh.wikipedia.org/wiki/%E5%B8%A6%E5%AE%BD">带宽</a>这样的昂贵资源的消耗，所以压缩非常重要，然而压缩需要消耗信息处理资源，这也可能是费用昂贵的。所以数据压缩机制的设计需要在压缩能力、失真度、所需计算资源以及其它需要考虑的不同因素之间进行折衷。</p><p><strong>对于任何形式的通信来说，只有当<a href="https://zh.wikipedia.org/wiki/%E4%BF%A1%E6%81%AF">信息</a>的<a href="https://zh.wikipedia.org/w/index.php?title=%E5%8F%91%E9%80%81%E6%96%B9&amp;action=edit&amp;redlink=1">发送方</a>和接受方都能够理解编码机制的时候压缩数据通信才能够工作</strong>。例如，只有当接受方知道这篇文章需要用汉语字符解释的时候这篇文章才有意义。同样，只有当接受方知道编码方法的时候他才能够理解压缩数据。</p><p>计算表示“hello world”这个字符串所需的信息熵，我们需要分析字符串中每个字符的概率分布,  将英文字母及符号看作信息的基本单位, 那么这个字符串中出现了’h’,’e’,’l’,’o’,’ ‘,’w’,’r’,’d’,8个字符其出现频率</p><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="87.093ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 38494.9 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(888,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1277,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(2129,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2795.8,0)"><path data-c="2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></g><g data-mml-node="mo" transform="translate(3851.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(4629.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(5018.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(5796.6,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(778,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(1278,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1778,0)"></path></g><g data-mml-node="mo" transform="translate(8296.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(9297,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></g><g data-mml-node="mo" transform="translate(10019.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(11019.4,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(778,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(1278,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(1778,0)"></path></g><g data-mml-node="mo" transform="translate(13519.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(14519.9,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(778,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1278,0)"></path><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z" transform="translate(1778,0)"></path></g><g data-mml-node="mo" transform="translate(16797.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(17464.7,0)"><path data-c="2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></g><g data-mml-node="mo" transform="translate(18520.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(19298.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(19687.4,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(20465.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(778,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(1278,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1778,0)"></path></g><g data-mml-node="mo" transform="translate(22965.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(23965.9,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(778,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(1278,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(1778,0)"></path></g><g data-mml-node="mo" transform="translate(26466.1,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(27466.3,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(778,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1278,0)"></path><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z" transform="translate(1778,0)"></path></g><g data-mml-node="mo" transform="translate(29744.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(30411.1,0)"><path data-c="2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></g><g data-mml-node="mn" transform="translate(31466.9,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(778,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1278,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1778,0)"></path></g><g data-mml-node="mtext" transform="translate(33744.9,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mtext" transform="translate(33994.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">比</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">特</text><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z" transform="translate(2000,0)"></path><text data-variant="normal" transform="translate(2500,0) scale(1,-1)" font-size="884px" font-family="serif">字</text><text data-variant="normal" transform="translate(3500,0) scale(1,-1)" font-size="884px" font-family="serif">符</text></g></g></g></svg></mjx-container></p><p>字符串长度为 11 个字符，因此总信息熵为：</p><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="45.985ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 20325.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mtext"><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path data-c="6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z" transform="translate(389,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(889,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(1278,0)"></path><path data-c="6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z" transform="translate(1778,0)"></path></g></g><g data-mml-node="mo" transform="translate(2333.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3389.6,0)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(4277.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4666.6,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(5518.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(6129.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(7130,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(8407.8,0)"><path data-c="2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></g><g data-mml-node="mn" transform="translate(9463.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(778,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1278,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1778,0)"></path></g><g data-mml-node="mo" transform="translate(11963.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(12964,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(14241.8,0)"><path data-c="2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></g><g data-mml-node="mn" transform="translate(15297.6,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(1000,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(1278,0)"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(1778,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(2278,0)"></path></g><g data-mml-node="mtext" transform="translate(18075.6,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mtext" transform="translate(18325.6,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">比</text><text data-variant="normal" transform="translate(1000,0) scale(1,-1)" font-size="884px" font-family="serif">特</text></g></g></g></svg></mjx-container></p><h3 id="通信双方达成共识"><strong>通信双方达成共识</strong></h3><p>为了表示“hello world”这个字符串，通信双方需要：</p><ol><li><p><strong>字符集共识</strong>：双方需约定使用的字符集（如 ASCII 或 Unicode）。</p></li><li><p><strong>编码方式共识</strong>：双方需约定编码方式（如 UTF-8、霍夫曼编码）。</p></li><li><p><strong>信息熵共识</strong>：双方需理解字符串的熵值（约 2.842 比特/字符），以确定最小传输资源需求。</p><ul><li><strong>统计推断与机器学习</strong>：现代机器学习模型（例如贝叶斯网络、朴素贝叶斯分类器）都深受概率论和统计学的启发，而交叉验证、A/B 测试等统计方法则保证了这些模型在实际应用中的鲁棒性和准确性。</li></ul></li></ol><h2 id="发展历程">发展历程</h2><ul><li><strong>概率论</strong>：最早起源于17世纪的赌博问题，由帕斯卡、费马等人提出初步理论，随后随着数学的发展不断完善。</li><li><strong>数理统计</strong>：在19世纪末到20世纪初，高斯、费舍尔等人的工作使统计学逐步形成体系，应用范围也从农业试验扩展到医学、工程等多个领域。</li><li><strong>信息论</strong>：由香农在1948年提出，其原始目标是解决通信领域中信息传输的效率问题。随着时间的推移，信息论的应用范围不断扩大，如今已深入到数据压缩、密码学、机器学习、神经科学等众多领域。</li></ul><p>另外，<strong>随机过程与时间序列分析</strong>中的马尔可夫链、布朗运动等理论在金融统计中的应用也日益广泛，它们帮助我们建模和预测股市波动、汇率变化等动态系统的行为。</p><h2 id="应用案例：从理论到实践">应用案例：从理论到实践</h2><h3 id="金融与风险管理">金融与风险管理</h3><p>现实世界充满了随机现象，例如股市波动、气候变化和疾病传播。概率论为我们提供了一套系统的方法去量化和描述这些不确定性，使我们能够对未来进行预测并做出决策。通过概率模型和统计方法，我们可以评估潜在风险。例如，在金融领域，金融机构利用VaR（风险价值）模型对资产组合进行风险管理，从而制定更为稳健的投资策略。<br>金融市场充满随机波动。利用概率分布（如正态分布、t分布）和 Monte Carlo 模拟，金融工程师可以对资产收益进行建模，评估投资组合的风险。例如，2008年金融危机期间，尾部风险的低估促使研究者重新审视和改进风险模型（Embrechts et al., 2001）。</p><h3 id="医学与生物统计">医学与生物统计</h3><p>在新药研发过程中，临床试验必须设计得科学严谨。统计方法如 t 检验、卡方检验以及抽样方法确保了试验结果的可靠性，并帮助研究者在有限样本中提取信息。FDA 审查报告中明确指出，统计效能（power）常被设置为至少80%以确保试验的有效性（Friedman et al., 2010）。</p><h3 id="机器学习与人工智能">机器学习与人工智能</h3><p>现代机器学习算法广泛应用于图像识别、自然语言处理等领域。基于概率图模型、朴素贝叶斯分类器的理论支持，结合交叉验证和 A/B 测试等统计方法，深度学习模型在 ImageNet 挑战赛中取得了95%以上的识别准确率（Goodfellow et al., 2016）。</p><h3 id="信息论在数据压缩与通信中的应用">信息论在数据压缩与通信中的应用</h3><ul><li><strong>无损压缩</strong>：无损压缩算法（如 Huffman 编码、算术编码）利用自信息量和熵的理论设计，力图将数据压缩到接近其理论下界。剧中 Pied Piper 的压缩算法虽然经过戏剧化处理，但实际上反映了真实世界中对压缩算法效率追求的热情和技术挑战。</li><li><strong>带噪信道通信</strong>：香农极限揭示了在给定带宽和信噪比下，信道的最大信息传输速率。设计高效的信道编码（如 LDPC 码）可以帮助系统接近这一极限，从而在5G、卫星通信等领域实现无误差传输（Shannon, 1948）。</li></ul><p>概率论、数理统计与信息论不仅为我们提供了描述随机现象和信息传输的理论基础，更在金融、医学、机器学习以及通信等多个领域中得到了广泛应用。通过对自信息量、熵以及香农极限等核心概念的学习，我们不仅能够理解数据的内在结构，还能设计出高效的数据压缩算法和抗噪通信系统。正如美剧 <em>Silicon Valley</em> 中对技术的戏剧化演绎所展示的那样，作为年轻的 SDE 和创业者，深入掌握这些学科的原理，将为未来的创新与技术发展提供无限可能。<br>So, 美剧硅谷中的The middle-out algorithm 压缩算法真能实现吗？<br>文件能压缩的程度受信息量的限制，基本上不太可能出现一个无损压缩算法超过香农极限，而且middleout之后相当于使用分治法他们可能会继续将两半分成一半</p><p>事实上Dropbox正在研究一种实际且相当革命性的中间压缩算法。 <a href="https://blogs.dropbox.com/tech/2016/07/lepton-image-compression-saving-22-losslessly-from-images-images-at-15mbs/">https://blogs.dropbox.com/tech/2016/07/lepton-image-compression-saving-22-losslessly-from-images-images-at-15mbs/</a></p><h2 id="参考文献">参考文献</h2><ul><li>Embrechts, P., Klüppelberg, C., &amp; Mikosch, T. (2001). <em>Modelling Extremal Events for Insurance and Finance</em>. Springer.</li><li>Friedman, L. M., Furberg, C., DeMets, D. L., Reboussin, D. M., &amp; Granger, C. B. (2010). <em>Fundamentals of Clinical Trials</em>. Springer.</li><li>Goodfellow, I., Bengio, Y., &amp; Courville, A. (2016). <em>Deep Learning</em>. MIT Press.</li><li>Shannon, C. E. (1948). <em>A Mathematical Theory of Communication</em>. Bell System Technical Journal, 27(3), 379–423.</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在当今数据驱动与互联网高速发展的时代，概率论、数理统计以及信息论构成了理解和应对不确定性、优化数据传输以及实现高效压缩算法的数学基础。这三大领域不仅为金融风险管理、临床试验设计、机器学习等提供了理论支持，同时也奠定了现代通信与数据压缩技术的基石。&lt;/p&gt;
&lt;p&gt;最近在观看美</summary>
      
    
    
    
    <category term="随谈" scheme="https://stan370.github.io/categories/%E9%9A%8F%E8%B0%88/"/>
    
    
    <category term="概率论" scheme="https://stan370.github.io/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"/>
    
    <category term="信息论" scheme="https://stan370.github.io/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/"/>
    
    <category term="算法" scheme="https://stan370.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>WebAPP怎么保存状态？ Token设计与选型</title>
    <link href="https://stan370.github.io/2025/01/07/Token/"/>
    <id>https://stan370.github.io/2025/01/07/Token/</id>
    <published>2025-01-07T11:43:33.000Z</published>
    <updated>2025-03-19T12:12:05.248Z</updated>
    
    <content type="html"><![CDATA[<h3 id="认证系统的设计与选型：JWT到长短生命周期的Token管理">认证系统的设计与选型：JWT到长短生命周期的Token管理</h3><p>大约在 2010 年，大多数Web服务器都使用session来存储状态信息，用户将执行用户/密码登录，后端将为该session ID创建SessionID。 人们开始琢磨一个新点子：用 令牌 (token) 进行身份认证。JWT (JSON Web Token) 一战成名，成为这个时代的宠儿！在此之前，每次用户访问系统，服务器都得去数据库查一查：“嘿，这哥们儿还算是登录状态吗？” 这不仅拖慢了系统，还让分布式身份认证变得异常麻烦。</p><p>而 JWT 的出现，彻底改变了游戏规则。<br>👉 服务器不需要查询数据库，只需验证 JWT 的签名 就能知道用户是否登录。<br>这不仅提升了性能，还让那些酷炫的分布式认证系统成为可能。而分布式认证系统之所以变得重要，是因为那时候全世界都陷入了微服务（Microservice）**的热潮。</p><p>不过，令牌也有个问题：唯一重要的是令牌本身。没有数据库来确认会话的有效性，这意味着如果有人偷了你的令牌，他们就可以在令牌有效期内假装成你。因此，令牌的生命周期应该很短。以前会话可以持续几个小时，而令牌的生命周期可能只有几分钟。</p><p>短命令牌的烦恼：用户得反复登录<br>但如果令牌的生命周期太短，用户就会觉得很烦，因为他们需要一次又一次地登录。更糟糕的是，令牌可能在他们正用着应用的时候突然“死掉”。于是，**刷新令牌（Refresh Token）**应运而生。<br>有了刷新令牌，你可以在令牌快要过期的时候，偷偷发个请求去续命。每个刷新令牌只能用一次，而且当你用它的时候，你还会得到一个新的刷新令牌。这样一来，如果有人试图重复使用同一个刷新令牌，我们就知道出事了，然后可以把所有跟这个被盗令牌相关的刷新令牌都废掉。最终，所有使用该账号的用户都会被强制登出。</p><p>工程师的永恒饭碗：自己制造问题，再解决问题！<br>现在你明白为什么工程师的工作永远干不完了吧？因为我们总是先发明一些新问题，然后再发明一些解决方案，而这些解决方案又会带来更多的问题！😄</p><p>在现代的认证与授权机制中，<strong>Token</strong>扮演着关键角色，用于标识和验证用户的身份。</p><p>Token是一个令牌，客户端访问服务器时，验证通过后服务端会为其签发一张令牌，之后客户端就可以携带令牌访问服务器，服务端只需要验证令牌的有效性即可。一句话概括；<strong>访问资源接口（API）时所需要的资源凭证</strong><br>JWT（JSON Web Token）常常是一个热门选择。下面我将从设计原则、优势与劣势、以及实际应用场景等角度详细说明 JWT 的设计与选型问题。JWT 的标准结构由三部分组成：</p><p>Header（头部）：通常包含令牌的类型（通常为 JWT）以及所使用的签名算法（如 HMAC SHA256 或 RSA）。<br>Payload（载荷）：包含声明（Claims），如注册声明（如 iss、sub、aud、exp、nbf、iat 和 jti）以及自定义数据。<br>Signature（签名）：通过对 Header 和 Payload 进行编码后，使用指定的算法和密钥（或私钥）进行签名，确保数据未被篡改。</p><p>然而，如何设计Token，尤其是在选择使用<strong>Access Token</strong>和<strong>Refresh Token</strong>的组合（简称AT&amp;RT方案）还是单Token方案时，往往需要根据业务需求和安全性做权衡。本文将从原理、场景和安全性三个角度入手，深入探讨Token设计中的抉择。</p><hr><h4 id="Access-Token-与-Refresh-Token-的角色分工"><strong>Access Token 与 Refresh Token 的角色分工</strong></h4><p>Access Token 和 Refresh Token 的设计理念源于 OAuth 2.0 协议，而 OAuth 2.0 是由 Internet Engineering Task Force (IETF) 在 2012年 正式发布的（RFC 6749）。虽然 OAuth 2.0 是这一设计的主要推动者，但它的灵感可以追溯到早期的身份验证和授权机制。Access Token（简称AT）和 Refresh Token（简称RT）的设计，背后的核心思想是将<strong>授权</strong>与<strong>资源访问</strong>的行为分离。</p><ol><li><p><strong>Access Token</strong>：用于快速访问受保护的资源。它通常有较短的有效期，直接携带用户授权信息（如权限、身份等），在API请求中传递给服务器进行验证。</p><ul><li><strong>特点</strong>：短时有效、高频使用。</li><li><strong>风险</strong>：一旦被窃取，可能导致短期内资源被恶意访问。</li></ul></li><li><p><strong>Refresh Token</strong>：用于刷新Access Token的有效期。它通常只在认证服务器（Authorization Server）和客户端之间交互，不会直接参与资源访问。</p><ul><li><strong>特点</strong>：长时有效、低频使用。</li><li><strong>风险</strong>：被窃取后可能允许恶意用户长期续签Access Token。</li></ul></li></ol><p>通过将两者分工，AT&amp;RT方案将<strong>获取授权</strong>这一高危、低频的操作与<strong>获取资源</strong>这一低危、高频的操作分离开，从而降低安全风险。</p><hr><h4 id="AT-RT-与单Token方案的核心区别"><strong>AT&amp;RT 与单Token方案的核心区别</strong></h4><p>AT&amp;RT方案与单Token方案的区别，可以总结为一个核心理念：<strong>控制风险的暴露面</strong>。</p><ol><li><p><strong>单Token方案</strong>：</p><ul><li>单Token同时承担授权和资源访问功能。</li><li>一旦泄漏，恶意用户可以直接访问资源，且可能长时间有效。</li><li>适用场景：小型应用、内网服务、对安全性要求较低的系统。</li></ul></li><li><p><strong>AT&amp;RT方案</strong>：</p><ul><li>将授权功能剥离到Refresh Token，Access Token则专注于资源访问。</li><li><strong>好处</strong>：<ul><li>如果Access Token泄漏，由于其短时效性，攻击者只能在有限时间内使用。</li><li>即使Refresh Token泄漏，也可以通过令牌轮换机制（Token Rotation）降低风险。</li></ul></li><li>适用场景：安全敏感、用户访问频繁的场景，如银行、社交媒体、云服务等。</li></ul></li></ol><hr><h4 id="设计Token时需要考虑的关键问题"><strong>设计Token时需要考虑的关键问题</strong></h4><p>在实际系统中，选择单Token还是AT&amp;RT方案，取决于以下几个因素：</p><ol><li><p><strong>安全性需求</strong>：</p><ul><li>如果系统中涉及敏感数据或存在较高的Token泄露风险（如公网环境、多终端接入），推荐使用AT&amp;RT方案。</li><li>单Token方案适用于风险较低的场景，如开发测试环境或不涉及关键数据的内部服务。</li></ul></li><li><p><strong>使用频率</strong>：</p><ul><li>高频访问的API更倾向于AT&amp;RT方案，因为Access Token的短时效性可以有效减少潜在攻击窗口。</li><li>如果访问频率较低，单Token方案可能更简洁高效。</li></ul></li><li><p><strong>复杂度与成本</strong>：</p><ul><li>AT&amp;RT方案需要维护多种令牌状态（如失效、刷新、轮换），实现复杂度较高。</li><li>单Token方案实现简单，适合中小型团队或初创项目。</li></ul></li><li><p><strong>Token有效期</strong>：</p><ul><li>Access Token通常设置为几分钟到几小时的有效期，降低泄漏风险。</li><li>Refresh Token的有效期则更长，通常为数天到数月。</li></ul></li></ol><hr><h4 id="AT-RT方案的安全机制"><strong>AT&amp;RT方案的安全机制</strong></h4><p>为了进一步提高安全性，AT&amp;RT方案通常配合以下技术：</p><ol><li><p><strong>令牌轮换（Token Rotation）</strong>：</p><ul><li>每次使用Refresh Token时，返回新的Refresh Token并使旧的失效。</li><li>即使Refresh Token被窃取，也只能使用一次，降低攻击风险。</li></ul></li><li><p><strong>短期有效Access Token</strong>：</p><ul><li>将Access Token有效期控制在较短时间内（如5分钟）。</li><li>即便被窃取，攻击窗口也极为有限。</li></ul></li><li><p><strong>设备绑定与IP限制</strong>：</p><ul><li>将Refresh Token绑定到特定设备或IP，防止跨设备滥用。</li></ul></li><li><p><strong>安全存储</strong>：</p><ul><li>客户端应妥善存储Refresh Token（如使用Secure Storage或HttpOnly Cookie）。</li></ul></li></ol><hr><h4 id="实践中的选型建议"><strong>实践中的选型建议</strong></h4><table><thead><tr><th><strong>场景</strong></th><th><strong>推荐方案</strong></th><th><strong>原因</strong></th></tr></thead><tbody><tr><td>内网微服务通信</td><td>单Token方案</td><td>安全风险较低，实现简单，且内部环境对Token泄漏容忍度高。</td></tr><tr><td>移动端应用（电商、社交媒体等）</td><td>AT&amp;RT方案</td><td>需要支持多终端、频繁访问资源且对安全性要求较高。</td></tr><tr><td>低频后台管理系统</td><td>单Token方案</td><td>后台系统操作频率低，可通过严格控制用户行为降低风险。</td></tr><tr><td>高敏感性业务（银行、金融等）</td><td>AT&amp;RT方案+Token轮换</td><td>涉及敏感数据，需最大限度减少Token泄漏后的攻击可能性。</td></tr></tbody></table><hr><h2 id="总结"><strong>总结</strong></h2><p>AT&amp;RT方案的核心在于用双Token机制分隔高频和高危操作，从而降低风险的暴露面。而单Token方案则以简洁性取胜，适合对安全性要求较低的场景。在实际应用中，开发者需要根据业务特点、用户行为模式以及系统复杂度，选择最合适的方案。</p><p><strong>Token设计没有“银弹”，但对风险的正确理解，才是高效与安全并行的基石。</strong></p><h2 id="背景知识">背景知识</h2><p>在身份验证和授权领域，“有状态”（stateful）和"无状态"（stateless）通常用来描述系统处理用户认证信息的方式。</p><p>有状态（Stateful）：</p><p>有状态的认证系统在服务器端会维护用户的会话状态信息。这意味着服务器端会存储关于用户认证状态的信息，比如用户的登录状态、会话信息、权限等。<br>在有状态的认证系统中，服务器端在处理用户请求时，会根据存储的会话状态来验证用户的身份和权限，通常会使用会话标识（如 Session ID）来识别用户的会话状态。<br>典型的例子包括传统的基于会话的认证方式，用户在登录后会获得一个会话标识（Session ID），服务器端会在会话管理中保持用户的登录状态，并在后续请求中使用该会话标识来验证用户的身份。</p><p>使用有状态令牌（Stateful Token）在特定场景中具有显著优势，特别是在需要服务器端管理会话状态和即时控制会话生命周期的情况下。以下是一些适合使用有状态令牌的场景：</p><h3 id="1-高度安全性要求的应用">1. <strong>高度安全性要求的应用</strong></h3><ul><li><strong>即时会话撤销</strong>：在高安全性应用中，例如金融服务、在线支付和医疗系统，可能需要立即撤销某些会话。服务器端存储会话状态，可以在需要时立即无效化令牌。</li><li><strong>敏感操作</strong>：对于涉及敏感数据和操作的系统，服务器端管理可以提供额外的控制和审计能力。</li></ul><h3 id="2-单一服务器或共享存储的系统">2. <strong>单一服务器或共享存储的系统</strong></h3><ul><li><strong>集中式会话管理</strong>：在单服务器应用或使用集中式共享存储的环境中，服务器端存储和管理会话状态较为简单和高效。</li><li><strong>小规模系统</strong>：对于小规模系统或负载较低的系统，管理会话状态的开销相对较低。</li></ul><h3 id="3-需要复杂的会话控制-需长时间会话管理的应用">3. <strong>需要复杂的会话控制,需长时间会话管理的应用</strong></h3><ul><li><strong>细粒度权限控制</strong>：服务器端可以根据用户会话状态进行细粒度的权限控制，例如临时提升权限、基于活动时间段的权限控制等。</li><li><strong>动态会话属性</strong>：在会话期间可能需要动态调整用户的会话属性（如角色、权限等），服务器端管理更加灵活。</li><li><strong>长期会话</strong>：在需要长时间保持用户会话的应用中，例如企业内部应用或需要频繁交互的应用，服务器端可以更好地管理和维护会话状态。</li><li><strong>会话恢复</strong>：支持会话恢复，用户可以在不同设备和会话中无缝切换。</li></ul><h3 id="4-严格的会话一致性需求-不需要跨域">4. <strong>严格的会话一致性需求,不需要跨域</strong></h3><ul><li><strong>强一致性</strong>：需要确保会话状态的一致性，如电商购物车、多人协作工具等，服务器端可以更好地保证一致性和数据同步。</li><li><strong>内部系统</strong>：主要用于内部系统，不需要跨域、跨平台访问，这类系统更适合使用有状态令牌。</li></ul><p>无状态（Stateless）：</p><p>无状态的认证系统不会在服务器端维护用户的会话状态信息。每个请求都是独立的，服务器不会存储任何关于用户的会话状态。<br>在无状态的认证系统中，服务器端不需要存储任何会话状态，所有的认证信息都被包含在每个请求中，通常是在请求的头部（Header）或参数中。<br>典型的例子包括基于令牌（Token）的认证方式，比如 JSON Web Token（JWT）。在这种方式下，用户在登录后会获得一个令牌（Token），服务器端会使用令牌中的信息来验证用户的身份和权限，而不需要存储任何会话状态。</p><p>即使使用 JWT 进行用户认证，后端数据库仍然需要存储用户的账户和密码信息。这是因为：</p><ul><li><strong>用户注册和登录</strong>：在用户注册时，需要存储他们的账户信息（如用户名、邮箱）和密码（通常是经过哈希处理的密码）。</li><li><strong>身份验证</strong>：在用户登录时，后端需要验证用户输入的密码是否正确，这需要与数据库中存储的密码进行比对。</li></ul><p>JWT 是在用户成功登录后生成的令牌，通常包含用户的身份信息和权限信息。其生成和使用过程如下：</p><ul><li><strong>用户登录</strong>：用户提交用户名和密码。</li><li><strong>身份验证</strong>：服务器验证用户名和密码。如果验证成功，服务器生成一个 JWT，包含用户的身份信息（如用户ID）和其他必要的声明（claims）。</li><li><strong>返回 JWT</strong>：服务器将生成的 JWT 返回给客户端。</li><li><strong>后续请求</strong>：客户端在后续请求中携带 JWT，服务器通过验证 JWT 的签名和有效期来确认用户身份。</li></ul><p>JWT 在用户认证和授权方面具有以下优势：</p><ul><li><p><strong>无状态性</strong>：服务器不需要存储用户的会话信息，每次请求都可以通过验证 JWT 来确认用户身份。</p></li><li><p><strong>扩展性</strong>：适用于分布式系统和微服务架构，因为令牌是自包含的，不需要共享会话状态。</p></li><li><p><strong>安全性</strong>：通过加密和签名，确保令牌的完整性和可信度。<br><strong>Cookie-Based Session</strong>：</p></li><li><p><strong>优点</strong>：简单、安全性高（服务器端存储）。</p></li><li><p><strong>缺点</strong>：扩展性差，服务器压力大。</p></li></ul><p><strong>Token-Based Authentication</strong>：</p><ul><li><strong>优点</strong>：无状态、扩展性好。</li><li><strong>缺点</strong>：客户端存储安全性较差。</li></ul><p><strong>JWT</strong>：</p><ul><li><strong>优点</strong>：无状态、自包含、适合分布式系统。</li><li><strong>缺点</strong>：安全性依赖于客户端存储和令牌签名。</li></ul><p><strong>Cookie-Based Session</strong>：适用于简单的 Web 应用，特别是单服务器或小规模应用。</p><p><strong>Token-Based Authentication</strong>：适用于需要跨多个客户端（如移动端、单页应用）的应用。</p><p><strong>JWT</strong>：适用于分布式系统和微服务架构，提供更高的扩展性和灵活性。</p><p>如果是在一个只有帐号跟密码的世界上，我就必须要把我的 Google 帐号和密码告诉给这第三方服务行事历服务，它才有办法取得这些资讯。但如果我把帐号密码告诉了第三方，它可能就可以在暗地里窃取行事历以外的资讯，像是在 Gmail 里的机密资讯。这时候就出现了使用 <strong>Access Token 来解决这个问题的协议，OAuth 2.0。</strong></p><p>在 OAuth 2.0 中，使用短期的 Access Token 有几个主要的优势和原因：</p><ol><li><strong>安全性：</strong> 短期的 Access Token 有效期较短，如果被盗或泄露，攻击者可利用的时间窗口较小，减少了被滥用的风险。相比之下，长期有效的 Token 更容易成为攻击者的攻击目标。</li><li>可控制资源的访问权限（最小权限原则</li><li><strong>强制刷新：</strong> 通过设定较短的有效期，强制客户端定期刷新 Access Token。这有助于保持令牌的有效性和安全性，并且可以促使客户端与认证服务器交互，更新并重新授权访问权限。</li><li><strong>可撤销性:</strong> 您可以随时撤销第三方服务的访问权限。</li></ol><p>但同时也要权衡安全性和效率。 Access Token应该维持在较短有效期，<strong>过长不安全，过短也会影响用户体验</strong>，因为频繁去刷新带来没有必要的网络请求。可以参考我们常常在某些网站停止操作一段时间之后就会掉线，这个时间是Refresh Token的有效期，Access Token不应长过这个时间。</p><p>Refresh Token的有效期就是允许用户在多久时间内不用重新登录的时间，可以很长，视业务而定。我们在使用某些APP的时候，即使一个月没有开过也是登录状态的，这6y就是Refresh Token决定的。授权服务在接到Refresh Token的时候还要进一步做客户端的验证，尽可能排除盗用的情况。</p><p>A refresh token can help you balance security with usability. Since refresh tokens are typically longer-lived, you can use them <strong>to request new access tokens after the shorter-lived access tokens expire</strong>.</p><p><strong>It’s a common practice for some JWT frameworks or authentication systems to use a combination of JWT access tokens and opaque refresh tokens. This hybrid approach aims to leverage the advantages of both token types while mitigating their respective drawbacks.</strong></p><p><strong>通过引入 refresh token，系统设计者实现了一种混合模型：保持了大部分请求的无状态性（通过 JWT），同时通过 refresh token 实现必要的有状态管理（如 token 的更新和撤销）。这种方法有效地在用户体验、安全性和系统性能之间取得了平衡。<br>你的总结确实很好地解释了为什么在现代架构中，尽管追求无状态（stateless）</strong>，但还是需要一些有状态（stateful）元素来解决实际问题。这样的设计既保持了分布式系统的优势，又提供了必要的安全控制和用户体验优化。</p><p>所有token应该保管在private的地方，也就是只能客户端自己使用，所有token都应该在<a href="https://link.juejin.cn/?target=https%3A%2F%2Fzh.wikipedia.org%2Fwiki%2F%25E5%2582%25B3%25E8%25BC%25B8%25E5%25B1%25A4%25E5%25AE%2589%25E5%2585%25A8%25E6%2580%25A7%25E5%258D%2594%25E5%25AE%259A%23TLS_1.3">TLS</a>信道下发送（比如HTTPS）。</p><p>In an SSO/Auth system, the token you design should store information essential for secure and efficient authentication and authorization. Here’s a breakdown of the key information that should be included in your token:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">v.Set("scope", "iauth_token")</span><br><span class="line">  v.Set("response_type", "code")</span><br><span class="line">  v.Set("client_id", testService.ServiceID)</span><br><span class="line">  v.Set("state", uuid.NewString())</span><br><span class="line">  v.Set("redirect_uri", "https://test.hotstar.com:9999/callback")</span><br><span class="line">  tokenClaims := &amp;iauth.TokenClaims{}</span><br><span class="line">    parser := jwt.Parser{}</span><br><span class="line">    _, _, err = parser.ParseUnverified(result.AccessToken, tokenClaims)</span><br><span class="line">    assert.Nil(t, err)</span><br><span class="line">    assert.Equal(t, tokenClaims.SubjectID, testUserId)</span><br><span class="line">    assert.Equal(t, tokenClaims.ExpiresAt, int64(result.ExpiresAt))</span><br><span class="line">    assert.Equal(t, tokenClaims.ExpiresAt-12*3600-2, tokenClaims.IssuedAt) //we set 2 second offset in issueAt</span><br><span class="line">    assert.True(t, tokenClaims.IssuedAt == tokenClaims.NotBefore)</span><br><span class="line">    assert.NotNil(t, tokenClaims.Id)</span><br></pre></td></tr></table></figure><p><strong>Essential Information:</strong></p><ul><li><strong>User Identifier (UID):</strong> A unique identifier for the user, typically a numerical ID. This is crucial for identifying the user associated with the token.</li><li><strong>Issuer (iss):</strong> Identifies the system that issued the token. This helps verify the token’s origin and prevent forgery.</li><li><strong>Audience (aud):</strong> Specifies the intended recipient or service for the token. This ensures the token is used only by the intended service.</li><li><strong>Expiration Time (exp):</strong> A timestamp indicating when the token expires. This limits the token’s validity and reduces the risk of unauthorized access if compromised.</li><li><strong>Issued At Time (iat):</strong> A timestamp indicating when the token was issued. This helps track token age and detect potential issues.</li><li><strong>Token Type (typ):</strong> Specifies the type of token being used (e.g., JWT, opaque token). This helps the receiving service correctly handle the token.</li></ul><p><strong>Optional but Recommended Information:</strong></p><ul><li><strong>Scope (scp):</strong> Defines the permissions granted to the token holder. This allows for fine-grained control over what resources the user can access.</li><li><strong>Nonce (jti):</strong> A unique identifier for the token, preventing replay attacks where a stolen token is used multiple times.</li><li><strong>Session ID:</strong> A unique identifier for the user’s session. This allows for session management and revocation.</li><li><strong>User Roles/Groups:</strong> Information about the user’s roles or groups within the system. This can be used for authorization decisions.</li><li><strong>Refresh Token ID:</strong> If using a refresh token strategy, this identifies the associated refresh token for seamless token renewal.</li></ul><p><strong>Considerations:</strong></p><ul><li><strong>Security:</strong> Prioritize security by using strong encryption algorithms and proper key management for token generation and validation.</li><li><strong>Performance:</strong> Balance the amount of information stored in the token with performance considerations. Larger tokens can impact performance.</li><li><strong>Privacy:</strong> Only include necessary information to minimize the risk of exposing sensitive user data.</li><li><strong>Token Format:</strong> Choose a suitable token format like JWT (JSON Web Token) for its standardized structure and ease of parsing.</li></ul><p><strong>参考文献与数据来源</strong>：</p><ul><li><a href="https://tools.ietf.org/html/rfc7519">RFC 7519 - JSON Web Token (JWT)</a></li><li><a href="https://auth0.com/blog/jwt-best-practices/">JWT Best Practices</a></li><li><a href="https://cheatsheetseries.owasp.org/cheatsheets/JSON_Web_Token_for_Java.html">OWASP JWT Cheat Sheet</a></li><li><a href="https://pages.nist.gov/800-63-3/">NIST Guidelines on Authentication</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h3 id=&quot;认证系统的设计与选型：JWT到长短生命周期的Token管理&quot;&gt;认证系统的设计与选型：JWT到长短生命周期的Token管理&lt;/h3&gt;
&lt;p&gt;大约在 2010 年，大多数Web服务器都使用session来存储状态信息，用户将执行用户/密码登录，后端将为该session</summary>
      
    
    
    
    <category term="计算机工程" scheme="https://stan370.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%B7%A5%E7%A8%8B/"/>
    
    
    <category term="计算机基础" scheme="https://stan370.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="分布式系统" scheme="https://stan370.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    <category term="网络安全" scheme="https://stan370.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>网络安全实践</title>
    <link href="https://stan370.github.io/2025/01/06/security/"/>
    <id>https://stan370.github.io/2025/01/06/security/</id>
    <published>2025-01-06T14:43:32.000Z</published>
    <updated>2025-03-19T12:12:05.249Z</updated>
    
    <content type="html"><![CDATA[<h1>Web Security</h1><p>在广阔的互联网领域，信息源源不断，交易瞬息万变，一场无声的战斗正在上演。网络威胁潜伏在阴影中，试图利用漏洞并破坏我们建造的数字堡垒。这就是网络安全的领域，一个动态且不断发展的领域，它是用户与渗透到网络世界的无数风险之间的守护者。</p><p>Consider this: Beyond the visible web lies an untamed and uncharted area akin to the Wild West, where data bandits and cyber outlaws reign supreme. These ne’er-do-wells constantly innovate their nefarious methods to breach firewalls, hijack sessions, and steal sensitive data. Web security is the marshal that stands in their way, brandishing the latest cryptographic shields and a sharp strategy to enforce the law of the land.</p><p>**对称加密 (DES, 3DES, AES)：<strong>如果要加密一串消息，很自然的想法是，加密和解密用的同一个密码。如同现实生活中，一把钥匙既可以锁上一把锁，也可以打开一把锁，这就是密码学中的对称加密 (Symmetric Encryption)：加密和解密用的是同一串密钥 (Secret Key)。实际应用中的<a href="https://www.zhihu.com/search?q=%E6%95%B0%E6%8D%AE%E5%8A%A0%E5%AF%86&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22465894109%22%7D">数据加密</a>，通常都是使用的对称加密，因为<a href="https://www.zhihu.com/search?q=%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22465894109%22%7D">**对称加密算法</a>很多对硬件特别友好，所以在硬件加密模块上运行效率非常高</strong>。</p><p><strong>非对称加密 (RSA), 非对称加密是为了解决对称加密无法解决的问题。例如，怎么才能保证使用密钥的人是可信的呢？</strong></p><p>公钥加密私钥解，私钥签名公钥验。</p><ol><li><p><strong>公钥加密，私钥解密</strong>：</p><p>这是非对称加密的基本应用场景。当A想向B发送加密信息时，A使用B的公钥对信息进行加密。由于公钥可以公开，A无需担心公钥的安全性。B收到加密信息后，使用自己的私钥进行解密，因为只有B持有对应的私钥，所以只有B能够解密并读取信息内容。这一过程确保了信息的机密性。</p></li><li><p><strong>私钥签名，公钥验证</strong>：</p><p>数字签名技术用于验证信息的完整性和发送方的身份。当A发送信息给B时，A使用自己的私钥对信息的摘要进行加密，生成数字签名。B收到信息和签名后，使用A的公钥对签名进行解密，验证签名的正确性。如果验证通过，B可以确信信息没有被篡改，且确实来自持有对应私钥的A，增强了信息的完整性和不可抵赖性。</p></li></ol><p>消息认证码系统由三种算法组成：</p><ul><li><p>密钥生成算法从密钥空间中均匀随机地选择一个密钥。</p></li><li><p>签名算法根据密钥和消息有效地返回标签。</p></li><li><p>验证算法在给定相同密钥和标签的情况下，可以高效地验证消息的真实性。也就是说，当消息和标签未被篡改或伪造时，返回<em>接受，否则返回拒绝</em></p><p>。</p></li></ul><p>安全的消息认证代码必须能够抵御攻击者<a href="https://en.wikipedia.org/wiki/Digital_signature_forgery">伪造任意、选定或所有消息的标签的</a>企图，包括在<a href="https://en.wikipedia.org/wiki/Digital_signature_forgery">已知消息</a>或<a href="https://en.wikipedia.org/wiki/Digital_signature_forgery">选定消息</a>的情况下。在不知道密钥的情况下，计算给定消</p><h3 id="MITM">MITM</h3><p>以下是MITM攻击的一些常见形式：</p><ol><li><strong>窃听（Eavesdropping）：</strong><br>中间人通过监听网络通信，获取传输的敏感信息，如用户名、密码等。</li><li><strong>数据篡改（Data Modification）：</strong><br>中间人可以修改传输的数据，导致接收方收到被篡改过的信息，可能会对系统产生负面影响。</li><li><strong>欺骗（Spoofing）：</strong><br>攻击者可以伪装成合法的通信方，使得通信的两端都认为他们正在与合法的对方通信。</li><li><strong>中继攻击（Relay Attack）：</strong><br>攻击者在通信的两端之间传递信息，以模拟两者直接通信，同时记录或修改信息。</li><li><strong>SSL Stripping：</strong><br>中间人可能试图降级加密通信，将加密连接转换为非加密连接，以便更容易地窃听敏感信息。</li></ol><p>MITM攻击可以在各种通信协议中发生，包括HTTP、HTTPS、SMTP等。防范MITM攻击的方法包括使用加密通信（如HTTPS）、数字签名、使用安全的认证机制等。使用公共Wi-Fi网络时，特别需要注意MITM攻击，因为这样的网络更容易受到攻击者的窃听。</p><p>Hacker劫持user DNS解析到黑客的服务器之后，如果黑客服务器上没有合法签发的SSL证书，浏览器会提示这个DNS指向的服务器不可信任，然后弹出警告画面阻止你访问，所以要<strong>劫持DNS+合法证书</strong>两个问题同时解决才算完美的中间人攻击。用户电脑上的证书大部分由操作系统颁发，可以离线信任链</p><p><strong>单独说DH协商算法不能防止中间人没有意义。因为密钥协商算法要解决的是在不可靠链路上安全地协商密钥。而通信双方身份认证又是另外一个体系的东西。</strong></p><p>在 MITM 攻击中，攻击者拦截客户端和服务器之间的通信，冒充双方拦截或更改它们之间交换的数据。<br>虽然 HTTPS 对传输中的数据进行加密，但攻击者可能会插入客户端和服务器之间，拦截加密流量并使用各种技术对其进行解密，例如获取受损的 SSL/TLS 证书或利用 SSL/TLS 协议本身的漏洞。</p><p>MITM:</p><ol><li>服务器向客户端发送公钥。</li><li>攻击者截获公钥，保留在自己手上。</li><li>然后攻击者自己生成一个【伪造的】公钥，发给客户端。</li><li>客户端收到伪造的公钥后，生成加密hash值发给服务器。</li><li>攻击者获得加密hash值，用自己的私钥解密获得真秘钥。</li><li>同时生成假的加密hash值，发给服务器。</li><li>服务器用私钥解密获得假秘钥。</li><li>服务器用加秘钥加密传输信息</li></ol><p>可以看出我们这里数据是明文传输的，存在窃听风险。但是我们为了阐述数字签名机制是如何运转的，故意将保证信息机密性的机制省略了。</p><p>如果想要保证数据的机密性，我们常见的做法是，通信双方通过非对称加密安全交换对称加密的密钥，后续通信过程的数据都使用对称加密保证数据机密性。</p><p>并且「签名」的作用本身也不是用来保证数据的机密性，而是用于验证数据来源的防止数据被篡改的，也就是确认发送者的身份。接受者 Alice 收到后，取下数字签名，同时用 Bob 的公钥解密，得到「摘要1」，<strong>证明确实是 Bob 发的</strong>。</p><p>再对邮件内容使用相同的散列函数计算「摘要2」，与上面得到的「摘要1」进行对比，<strong>两者一致就说明信息未被篡改。</strong></p><h2 id="HTTPS">HTTPS</h2><p>主要三个作用：1. 加密通信 2.认证服务器的身份，防止mitm 窃听 3. 防止篡改，integrity</p><p>HTTPS（Hypertext Transfer Protocol Secure）使用了混合加密机制，包括非对称加密和对称加密，以确保安全的数据传输。ssl3.0 1998</p><p><strong>TLS（传输层加密协议） 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤，完成 TLS 握手只要 1 RTT，而且安全性更高。在 TLS 1.2 的握手中，一般是需要 4 次握手，先要通过 Client Hello （第 1 次握手）和 Server Hello（第 2 次握手） 消息</strong>协商<strong>出后续使用的加密算法，再互相交换公钥（第 3 和 第 4 次握手）</strong></p><ol><li><strong>客户端发起请求</strong>：<ul><li>客户端向服务器发起 HTTPS 请求。</li></ul></li><li><strong>服务器响应并发送证书</strong>：<ul><li>服务器响应请求并发送 SSL/TLS 证书。证书中包含服务器的公钥，该公钥由受信任的证书颁发机构（CA）签名。</li></ul></li><li><strong>客户端验证证书</strong>：<ul><li>客户端验证服务器的证书，确保证书由受信任的 CA 签发，证书未过期，且证书中的域名与请求的域名匹配。</li><li><strong>验证证书链</strong>：客户端通过验证证书链来确认证书是否由受信任的 CA 签发。证书链由服务器证书、中间证书（如果有）、根证书组成。</li><li><strong>检查证书有效期</strong>：客户端检查证书的有效期，确保当前日期在证书的有效期内。</li><li><strong>验证证书的域名</strong>：客户端验证证书中的域名是否与请求的域名匹配。</li><li><strong>检查证书吊销状态</strong>：客户端可以通过在线证书状态协议（OCSP）或证书吊销列表（CRL）来检查证书是否被吊销。</li></ul></li><li><strong>协商 SSL/TLS 版本和加密算法</strong>：<ul><li>客户端和服务器协商选择双方都支持的 SSL/TLS 版本和加密算法套件（cipher suite）。这些算法套件定义了具体使用的对称加密算法、非对称加密算法、哈希算法等。</li></ul></li><li><strong>密钥交换和会话密钥生成</strong>：<ul><li><strong>Ephemeral Diffie-Hellman（DHE）或 Ephemeral Elliptic Curve Diffie-Hellman（ECDHE）</strong>：客户端和服务器使用临时的 Diffie-Hellman 或椭圆曲线 Diffie-Hellman 参数生成一个共享的预主密钥（pre-master secret）。这涉及使用服务器的临时公钥（通常是服务器基于 ECC 生成的）和客户端生成的临时公钥。</li><li><strong>RSA</strong>：如果使用 RSA 密钥交换，客户端生成一个随机的预主密钥，并使用服务器证书中的公钥对其进行加密，然后发送给服务器。服务器使用其私钥解密预主密钥。</li></ul></li><li><strong>生成会话密钥</strong>：<ul><li>双方使用共享的预主密钥生成会话密钥。会话密钥用于对通信数据进行对称加密。</li></ul></li><li><strong>数据加密</strong>：<ul><li>使用协商好的对称加密算法（如 AES、ChaCha20 等），客户端和服务器使用会话密钥对传输的数据进行加密和解密。</li></ul></li><li><strong>完整性验证</strong>：<ul><li>使用消息认证码（MAC）或哈希函数（如 SHA-256）来验证数据的完整性，确保数据在传输过程中未被篡改。<br>证书验证的技术<br>浏览器验证证书: 浏览器验证证书的合法性，包括：<br>证书颁发机构: 浏览器检查证书是否由一个受信任的证书颁发机构（CA）颁发。<br>证书有效期: 浏览器检查证书是否在有效期内。<br>证书与域名匹配: 浏览器检查证书是否与网站的域名匹配。<br>证书签名: 浏览器检查证书的签名是否正确。<br>浏览器检查证书链: 浏览器检查证书链，确保证书是由一个受信任的 CA 颁发的。<br>浏览器验证证书的公钥: 浏览器验证证书的公钥，确保它与服务器的公钥匹配。</li></ul></li></ol><p>证书验证使用了以下技术：</p><p>X.509: X.509 是一种证书格式，用于存储证书信息。<br>SSL/TLS: SSL/TLS 是一种加密协议，用于建立安全连接。<br>公钥加密: 公钥加密是一种加密算法，用于加密数据。<br>数字签名: 数字签名是一种加密算法，用于验证证书的合法性。<br>证书验证的工具</p><p>证书验证可以使用以下工具：</p><p>浏览器: 浏览器内置了证书验证功能。<br>openssl: openssl 是一种命令行工具，用于验证证书。<br>certutil: certutil 是一种命令行工具，用于验证证书。<br><strong>安全外壳协议</strong>( SSH **)**是一种<a href="https://en.wikipedia.org/wiki/Cryptography">加密</a> <a href="https://en.wikipedia.org/wiki/Network_protocol">网络协议</a>，用于在不安全的网络上安全地运行<a href="https://en.wikipedia.org/wiki/Network_service">网络服务。</a><a href="https://en.wikipedia.org/wiki/Secure_Shell#cite_note-rfc4251-1">[1]</a>其最著名的应用是 remote <a href="https://en.wikipedia.org/wiki/Login">login</a> and <a href="https://en.wikipedia.org/wiki/Command-line_interface">command-line</a> execution.</p><p>SSH 应用程序基于<a href="https://en.wikipedia.org/wiki/Client%E2%80%93server_model">客户端-服务器</a>架构，将<a href="https://en.wikipedia.org/wiki/SSH_client">SSH 客户端</a>实例与<a href="https://en.wikipedia.org/wiki/SSH_server">SSH 服务器</a>连接。<a href="https://en.wikipedia.org/wiki/Secure_Shell#cite_note-rfc4252-2">[2]</a> SSH 作为分层协议套件运行，包含三个主要分层组件：<em>传输层</em>提供服务器身份验证、机密性和完整性；用户<em>认证协议</em>向服务器验证用户；连接<em>协议</em>将加密隧道复用为多个逻辑通信通道。<a href="https://en.wikipedia.org/wiki/Secure_Shell#cite_note-rfc4251-1">[1]</a></p><p><a href="https://en.wikipedia.org/wiki/Unix-like">SSH 是在类 Unix</a>操作系统上设计的，作为<a href="https://en.wikipedia.org/wiki/Telnet">Telnet</a>和<a href="https://en.wikipedia.org/wiki/Computer_security">不安全的</a>远程<a href="https://en.wikipedia.org/wiki/Unix_shell">Unix shell</a>协议的替代品</p><h3 id="Across-the-Wall">Across the Wall</h3><p>12.15问题：router设置为ipv6 解析时间长 infra建设没跟上，放弃。 想完全保证安全性和国内访问速率：刷openwrt，smartdns实现国内国外 dns 分流，需要另一台软路由。 折衷方案：全局代理？</p><p>代理模式： HTTP/socks系统代理 （开发者决定 大部分只使用browser）， TUN tap代理， 真VPN</p><p>TUN： 手机代理，软路由的模式</p><p>TUN虚拟网卡只能说非常接近 VPN还不是真正的VPN 因为我们用的ss vmess trojan等主流的翻墙协议 都无法<strong>封装网络层的数据包</strong> 最直观的感受就是ping命令这个网络层的工具 当我们使用clash的tun模式ping谷歌的话 会返回一个假的延迟 这个一毫秒的延迟是直接从虚拟网卡返回的 并且 如果使用下节要讲的fakeIP模式的话 还会直接返回一个假的IP 因为ss vmess等协议无法代理网络层的icmp协议 而ping就是icmp协议的工具 真正的VPN可以代理网络层 所以我使用真正的VPN wireguard是可以ping通谷歌的 可以看到延迟是真实的</p><p>目前来讲 tun模式是比较完美的客户端代理方式 既能实现在网络层接管系统所有流量 又能在此基础上实现分流 美中不足的地方就是使用ping命令 来测试网络延迟的时候就不太方便了 如果你平时只是用来浏览网页的话 第一种系统代理的方式也是一个不错的选择 至于真VPN的话 并不推荐用来科学上网 更适合有内网穿透需求的用户</p><p>VPN协议和NAT协议都是通过重新构建一个IP首部来实现的，但他们的实现又有<strong>区别</strong>，VPN是将内部IP数据报加密后打包成外部IP数据报的数据部分，它的主要目的是为了数据的保密性，而NAT是纯进行地址转换，它的目的是为了解决本地编址的内部网络与外网通信的问题。</p><p><strong>VPN的实现主要使用了两种基本技术：隧道传输 和 加密技术</strong></p><p><strong>VPN</strong> 通常处于网络层（第三层）或数据链路层（第二层）：</p><ul><li><strong>IP层的VPN</strong>，如IPsec或L2TP，通常工作在网络层，它们通过创建虚拟的私有网络来路由IP数据包。</li><li><strong>数据链路层的VPN</strong>，如PPTP，工作在数据链路层，通常用于点对点通信。</li></ul><p>Virtual Private Network 译为虚拟专用网络或者虚拟私有网络 什么网络是私有网络 你家里的局域网就是你的私有网络 我们无法直接和你没有公网ip的电脑进行通信 除非到你家里连上你家的路由器 那我们就能在同一个私有网络里 那什么是虚拟 顾名思义 虚拟的意思就是虚拟 就是物理不存在 虚拟私有网络的意思就是我不需要物理的跑到你家里去 物理的连接上你家的路由器 就可以实现与你没有公网IP的电脑进行通信 而要实现这个功能的话 就必须要能够封装网络层的数据包 只有能够封装网络层的数据包 才能实现异地组网 才能实现内网穿透 才能实现虚拟的和你在同一内网里 才能称之为VPN</p><p>VPN是一种技术 而不是某个具体的协议 VPN有很多技术实现 PPTP VPN IPSEC VPN OPENVPN WIREGUARD等等 具体实现细节都不太一样</p><p>但有一个是必须要支持的 就是<strong>封装网络层 如果ss协议也能够封装网络层 实现异地组网 那也能称之为VPN</strong></p><p>当然 我这里并不是说VPN就更高级 相反的 对于科学上网来讲 它可是一点都不高级 因为VPN并不是为翻墙而生的 只是因为它能对数据进行加密 顺便实现了翻墙功能 相较于<strong>ss这种专门为翻墙而生 将流量特征隐藏</strong>的协议 VPN的流量清晰明了的写着它就是VPN的流量 而且VPN分流很不方便 所以用来科学上网并不合适 这里就不再深入了 以后有机会出内网穿透的教程再来详细介绍</p><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/ea503cf6-9325-47ab-9fb3-3e33e40583ef/4ea5941a-a013-41e5-b7ef-33fae9328bc2/Untitled.png" alt="Untitled"></p><ol><li>Clash 的 DNS和代理两个模块是独立的. 日常终端PC使用 Clash for Windows 开启Systerm Proxy( HTTPS/SOCKS5代理) 并不需要 DNS enable: true, TUN 模式 是虚拟了网卡, 接管一切流量. OpenClash 实现虚拟网关用的是 TUN 模式, 而 Fake-IP /Redir-Host 的TUN模式、游戏模式 是(TAP 模式 很绕口 而 <a href="https://docs.cfw.lbyczf.com/contents/tap.html#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86">TAP 模式更推荐使用 Redir-Host 模式</a></li><li><a href="https://www.v2ex.com/t/939660">OpenClash 的绕过大陆IP 主要由两个模块组成</a> . 使用一份国内站点域名表 2w多条，添加至 Dnsmasq 中，在这个域名表中的 将会使用 默认114.114.114.114 来进行解析为真实的 IP ，在 iptables 中添加中国大陆 IP 段（ ipset ；直接绕过的规则并不使用 Clash 核心的 DNS 解析. <a href="https://songchenwen.com/tproxy-split-by-dns">由此解决了 <em>所有流量都经 Clash 核心转发，性能损耗过大</em> 的问题</a></li><li>插件设置-DNS设置中 *本地 DNS 劫持 使用防火墙转发 才能有黑白名单不走代理的局域网IP/MAC 选项. <em>我不清楚为何Redir-Host 模式 两种转发都能选黑白名单. Fake-IP 模式只在使用防火墙转发才能选择黑白名单</em>. issue区有两种方法 <a href="https://github.com/vernesong/OpenClash/issues/2506">[Feature] fakeIP模式下访问控制也有“不走代理的局域网设备 IP” #2506</a> <a href="https://github.com/vernesong/OpenClash/issues/3319">[Feature] Fake-IP模式下对于MAC/IP黑白名单、绕过大陆IP，可否提供更多选项？ #3319</a> 也有回复说 绕过中国大陆 IP 的实现是靠 Dnsmasq 先 DNS 分流判断实现的, 选择使用防火墙转发会使此功能失效</li><li>上游 Clash 官方已弃用 Redir-Host <a href="https://lancellc.gitbook.io/clash/clash-config-file/dns#enhanced-mode">(redir-host mode no longer available from Premium 2023.02.16)</a> Clash.Meta 还在使用两者; Clash for Windows 不换核情况下 遵循上游 Clash 默认TUN Mode 是Fake IP Mode ; 两者的区别只是 Fake-IP-filter: - ‘+.*’ 绕过所有域名 就变成 Redir-Host Mode</li><li>Fake-IP 模式 用假IP映射是为了使用 Rule 域名规则, 需要代理域名的解析均传递真实域名到代理服务器上 所以并无必要获得无污染DNS的解析 IP. Clash.Meta 的嗅探功能是为了把 Redir-Host 模式的 “真实IP” 变回域名. (实现CDN优化 解锁Netflix 等. 所以 Fake-IP 模式只需要配置 nameserver 并无必要配置 fallback 以及 fallback filter ; 配置nameserver 仅为了直连和fakeip filter 内的国内加速.</li></ol><h3 id="WARP原理">WARP原理</h3><p>WARP是CloudFlare提供的一项基于WireGuard的网络流量安全及加速服务，能够让你通过连接到CloudFlare的边缘节点实现隐私保护及链路优化。WireGuard 是由 Jason Donenfeld 等人用 C 语言编写的一个开源 VPN 协议，被视为下一代 VPN 协议，旨在解决许多困扰 IPSec/IKEv2、OpenVPN 或 L2TP 等其他WireGuard 就是采用 UDP 转发流量的 VPN 工具。他最大的优点也就是最大的缺点，采用 UDP 转发流量确实是能够有效的干扰墙的封锁，但是其稳定性实在是不敢恭维。</p><p>其连接入口为双栈（IPv4/IPv6均可），且连接后能够获取到由CF提供基于NAT的IPv4和IPv6地址，因此我们的单栈服务器可以尝试连接到WARP来获取额外的网络连通性支持。这样我们就可以让仅具有IPv6的服务器访问IPv4，也能让仅具有IPv4的服务器获得IPv6的访问能力。</p><ul><li>为仅IPv6服务器添加IPv4</li></ul><p>原理如图，IPv4的流量均被WARP网卡接管，实现了让IPv4的流量通过WARP访问外部网络。</p><ul><li>为仅IPv4服务器添加IPv6</li></ul><p>原理如图，IPv6的流量均被WARP网卡接管，实现了让IPv6的流量通过WARP访问外部网络。</p><ul><li>双栈服务器置换网络</li></ul><p>有时我们的服务器本身就是双栈的，但是由于种种原因我们可能并不想使用其中的某一种网络，这时也可以通过WARP接管其中的一部分网络连接隐藏自己的IP地址。至于这样做的目的，最大的意义是减少一些滥用严重机房出现验证码的概率；同时部分内容提供商将WARP的落地IP视为真实用户的原生IP对待，能够解除一些基于IP识别的封锁。</p><p>WARP是建立在Cloudflare 1.1.1.1的免费DNS服务器上。从技术上讲，Warp本质上就是一款VPN服务，Warp使用来自1.1.1.1的DNS服务器，并对它们之间的所有流量进行加密。</p><p>通常，当你访问<a href="http://baidu.com/">http://Baidu.com</a>时，URL会被翻译成网站所在服务器的IP地址，由ISP的DNS服务器托管。当你使用Warp时，Warp将手机上的DNS服务器固定为1.1.1.1。因此，所有请求都转到Cloudflare的安全服务器。</p><p>Warp在此基础上增加了一个额外的流程，使得设备和Cloudflare服务器之间的所有流量都是加密流量。<strong>但Warp是基于WireGuard隧道的UDP协议，中国大陆绝大部分运营商都会对这类流量进行惩罚式、限速式的限制策略，导致Warp在大陆使用上突发很高，但均速很低。(只能用于failover</strong> 😅 再加上Cloudflare的许多IP被国内Block，使得Warp在大陆接近一个不可用的状态。</p><p>Clash是一个开源的多协议代理工具，可以用于实现网络流量的代理和转发。它支持多种代理协议（如Shadowsocks、VMess、Trojan、Socks5等）和路由规则，能够实现灵活的网络流量控制和代理功能。</p><p>当使用 clash 作为系统代理或者直接将浏览器的代理设置为 clash 时, 请求会交给 clash 来处理, 包括 dns 解析, 当然 clash 拿到请求之后, 并不会先 dns 解析 ip, 它会先根据规则一条一条匹配, 如果有命中规则, 则根据相应的规则去处理.</p><p>这里要注意一下 <code>IP-CIDR</code>, 如果后面没有 <code>no-resolve</code>, 则需要 dns 解析 ip, 解析到 ip (可能被污染)后再根据此条进行对比, 如果没命中则进行下一条规则. 如果命中了, 走代理, 则不管它有没有被污染, 请求都会转发到节点服务器; 如果走直连, 则可能会被污染影响. 当然加上 <code>no-resolve</code> 之后, 就会让 clash 不进行 dns 解析, 所以此条 <code>IP-CIDR</code> 的直接 pass 掉, 可以这么说, 只有当浏览器直接对 ip 地址发起请求的时候, <code>IP-CIDR</code> 才会有效果.</p><p>接下来再讨论下手机上的 qx / surge 等工具, 或者 clash 开启了 enhanced mode 后, dns 解析这一块发生的变化.</p><p>由于请求并不是直接交给代理去处理, 所以浏览器需要先构建 dns 查询请求, 请求来到了 qx 或者软路由上面的 clash (透明代理)后, 被它劫持, 它有两种处理方式, redir-host 和 fake-ip, 前者已经被遗弃, 因为前者是要去获取 dns 解析的, dns 解析可能会解析到污染的 ip, 并且大多时候并不需要它进行 dns 解析. 所以 fake-ip 是主流, fake-ip 直接返回一条假的 ip, 并且对 ip 和域名进行了映射关系缓存, 这样浏览器拿到假的 ip 后进行 tcp 连接, 请求再次到达 qx / clash, 被截获后, 找到对应的域名, 接下来就是针对域名的规则匹配.</p><p><strong>trojan</strong>是近些年兴起的网络工具，项目官网 <a href="https://github.com/trojan-gfw%E3%80%82%E4%B8%8E**%E5%BC%BA%E8%B0%83%E5%8A%A0%E5%AF%86**%E5%92%8C%E6%B7%B7%E6%B7%86%E7%9A%84SS/SSR%E7%AD%89%E5%B7%A5%E5%85%B7%E4%B8%8D%E5%90%8C%EF%BC%8Ctrojan%E5%B0%86%E9%80%9A%E4%BF%A1%E6%B5%81%E9%87%8F%E4%BC%AA%E8%A3%85%E6%88%90%E4%BA%92%E8%81%94%E7%BD%91%E4%B8%8A%E6%9C%80%E5%B8%B8%E8%A7%81%E7%9A%84https%E6%B5%81%E9%87%8F%EF%BC%8C%E4%BB%8E%E8%80%8C%E6%9C%89%E6%95%88%E9%98%B2%E6%AD%A2%E6%B5%81%E9%87%8F%E8%A2%AB%E6%A3%80%E6%B5%8B%E5%92%8C%E5%B9%B2%E6%89%B0%E3%80%82%E5%9C%A8%E6%95%8F%E6%84%9F%E6%97%B6%E6%9C%9F%EF%BC%8C%E5%9F%BA%E6%9C%AC%E4%B8%8A%E5%8F%AA%E6%9C%89**trojan%E5%92%8C">https://github.com/trojan-gfw。与**强调加密**和混淆的SS/SSR等工具不同，trojan将通信流量伪装成互联网上最常见的https流量，从而有效防止流量被检测和干扰。在敏感时期，基本上只有**trojan和</a> <a href="https://itlanyan.com/v2ray-traffic-mask/">v2ray伪装</a> 能提供稳如狗的体验**。</p><p>想要长期稳定高效的科学上网，socks5 类型的代理基本是必须要掌握的。Clash 支持的代理类型有 <code>ss</code>、<code>vmess</code>、<code>socks5</code>、<code>http</code> 和 <code>snell</code></p><p><strong>SOCKS</strong>是一种<a href="https://en.wikipedia.org/wiki/Internet">Internet</a> <a href="https://en.wikipedia.org/wiki/Protocol_(computing)">协议</a>，它通过<a href="https://en.wikipedia.org/wiki/Proxy_server">代理服务器在</a><a href="https://en.wikipedia.org/wiki/Client_(computing)">客户端</a>和<a href="https://en.wikipedia.org/wiki/Server_(computing)">服务器</a>之间交换<a href="https://en.wikipedia.org/wiki/Packet_(information_technology)">网络数据包</a>。<strong>SOCKS5</strong>可选择提供<a href="https://en.wikipedia.org/wiki/Authentication">身份验证</a>，因此只有授权用户才能访问服务器。实际上，SOCKS 服务器将 TCP 连接代理到任意 IP 地址，并提供一种转发 UDP 数据包的方法。</p><p>SOCKS 执行在<a href="https://en.wikipedia.org/wiki/OSI_model">OSI 模型</a>的第 5 层（<a href="https://en.wikipedia.org/wiki/Session_layer">会话层，</a><a href="https://en.wikipedia.org/wiki/Presentation_layer">表示层</a>和<a href="https://en.wikipedia.org/wiki/Transport_layer">传输层</a>之间的中间层）。SOCKS 服务器接受 TCP 端口 1080 上的传入客户端连接，如<a href="https://en.wikipedia.org/wiki/RFC_(identifier)">RFC</a>  <a href="https://datatracker.ietf.org/doc/html/rfc1928">1928</a>中所定义。</p><p>SOCKS使用<a href="https://zh.wikipedia.org/w/index.php?title=%E6%8F%A1%E6%89%8B%E5%8D%8F%E8%AE%AE&amp;action=edit&amp;redlink=1">握手协议</a>来通知代理软件其客户端试图进行的SOCKS连接，然后尽可能透明地进行操作，而常规代理可能会解释和重写报头（例如，使用另一种底层协议，例如<a href="https://zh.wikipedia.org/wiki/%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">FTP</a>；然而，HTTP代理只是将HTTP请求转发到所需的HTTP服务器）。虽然HTTP代理有不同的使用模式，<a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">HTTP CONNECT</a>方法允许转发TCP连接；然而，SOCKS代理还可以转发<a href="https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE">UDP</a>流量（仅SOCKS5），而HTTP代理不能。HTTP代理通常更了解HTTP协议，执行更高层次的过滤（虽然通常只用于GET和POST方法，而不用于CONNECT方法）。</p><p><strong>socks5</strong> 类型的代理服务器在网络层级上是工作于应用层的<strong>会话层</strong>，很多流量都无法代理，因从即便是开了所谓的全局，也不能给游戏加速，毕竟游戏的网络传输一般都是跑在传输层的。<strong>像 Ping 和 Trace 这些 ICMP 命令自然也是无法通过代理的</strong>。（当然也有方法可以用软件强制接管虚拟网卡达到真全局的目的，比如 SSTAP，tun2socks 等等）</p><p>如果客户端和服务器都可以独立发包，但是偶尔发生延迟可以容忍（比如：在线的纸牌游戏，许多MMO类的游戏），那么可考虑使用TCP长连接如果客户端和服务器都可以独立发包，而且无法忍受延迟（比如：大多数的多人动作类游戏，一些MMO类游戏），那么考虑使用UDP加速器原理 加速器的原理很简单，就是UDP代理</p><p><strong>主要难在两点，其一是怎么处理游戏客户端到加速器服务器之间的UDP连接，其二是怎么让游戏客户端去连接这个加速器（一般游戏客户端是没有设置代理服务器的功能的）</strong></p><p>处理UDP有两种思路，一种是协议套娃，将游戏的UDP包外面套一层TCP（UDP over TCP ），到了目的地再把TCP解包成UDP，最后在发送到游戏服务器，返回的数据包也做同样处理；另外一种是伪造TCP（FakeTCP），对UDP数据包加上伪造的TCP包头，让其看起来像是TCP协议，欺骗运营商。</p><p>主动检测<br>HTTP所有没有正确结构和密码的连接都将被重定向到预设端点,因此,如果可疑探针连接(或者只是您的粉丝连接到您的博客XD),木马服务器的行为与该端点完全相同(默认情况下)。<br>被动检测<br>因为流量受到保护TLS(用户有责任使用有效的证书),所以如果你正在访问一个HTTP站点,流量看起来<br>是一样的(握手后HTTPS只有一个);如果您没有访问某个站点,那么流量看起来与“保持活动状态”或“保持活动状态“相同。因此,木马还可以绕过ISP限制。RTT TLS HTTP HTTPS WebSocket QoS</p><p><strong>常见端口扫描技术</strong></p><p><strong>3.3.2.1. 全扫描</strong></p><p>扫描主机尝试使用三次握手与目标主机的某个端口建立正规的连接，若成功建立连接，则端口处于开放状态，反之处于关闭状态。</p><p>全扫描实现简单，且以较低的权限就可以进行该操作。但是在流量日志中会有大量明显的记录。</p><p><strong>3.3.2.2. 半扫描</strong></p><p>半扫描也称SYN扫描，在半扫描中，仅发送SYN数据段，如果应答为RST，则端口处于关闭状态，若应答为SYN/ACK，则端口处于监听状态。不过这种方式需要较高的权限，而且现在的大部分防火墙已经开始对这种扫描方式做处理。</p><p><strong>3.3.2.3. FIN扫描</strong></p><p>FIN扫描是向目标发送一个FIN数据包，如果是开放的端口，会返回RST数据包，关闭的端口则不会返回数据包，可以通过这种方式来判断端口是否打开。</p><p>这种方式并不在TCP三次握手的状态中，所以不会被记录，相对SYN扫描要更隐蔽一些。</p><h3 id="HTTPS加密">HTTPS加密</h3><p>是的，HTTPS（Hypertext Transfer Protocol Secure）使用了混合加密机制，包括非对称加密和对称加密，以确保安全的数据传输。</p><p><strong>TLS 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤，完成 TLS 握手只要 1 RTT，而且安全性更高。在 TLS 1.2 的握手中，一般是需要 4 次握手，先要通过 Client Hello （第 1 次握手）和 Server Hello（第 2 次握手） 消息</strong>协商<strong>出后续使用的加密算法，再互相交换公钥（第 3 和 第 4 次握手）</strong></p><p>SSL握手的步骤如下：</p><ol><li>SSL或TLS客户端先向服务端发送一个加密通信请求，叫做ClientHello请求。该请求包含以下信息：<ul><li>客户端支持的SSL或者TLS版本</li><li>客户端生成的随机数，用于生成后续通信的随机字符串（“对话密钥”）</li><li>客户端支持的加密算法</li></ul></li><li>SSL或TLS服务端收到客户端请求后，向客户端发出响应，叫做ServerHello。该响应包含以下信息：<ul><li>服务端从客户端提供的SSL或TLS列表中选择的版本</li><li>Sesstion ID 和 另外生成的随机数</li><li>服务端的数字证书（如果服务端需要用于客户端身份验证的数字证书，则服务端发送一个客户端证书请求，其中包含受支持的证书类型列表和可接受的认证机构(CAs)的专有名称。）</li><li>确认使用的加密算法</li></ul></li><li>客户端收到服务端响应后，首先校验服务端发来的数字证书决定是否继续通信。</li><li><strong>TLS 第三次握手</strong>    客户端验证完证书后，认为可信则继续往下走。 接着，客户端就会生成一个新的<strong>随机数 (<em>pre-master</em>)</strong>，用服务器的 RSA 公钥加密该随机数，通过「<strong>Client Key Exchange</strong>」消息传给服务端。 服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。 至此，<strong>客户端和服务端双方都共享了三个随机数，分别是 Client Random、Server Random、pre-master</strong>。 于是，双方根据已经得到的三个随机数，生成<strong>会话密钥（Master Secret）</strong>，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。 生成完「会话密钥」后，然后客户端发一个「<strong>Change Cipher Spec</strong>」，告诉服务端开始使用加密方式发送消息。</li><li>如果服务端发送了一个客户端证书请求，客户端将会发送一个用客户端私钥加密的随机字符串和客户端的数字证书，或者没有数字证书的警告。在某些强制客户端证书的实现中，如果客户端没有数字证书，则握手会失败.</li><li>服务端接受并验证客户端证书</li><li>客户端向服务端发送一条完成的消息，该消息使用密钥加密，表示握手的客户端部分已经完成。</li><li>服务端向客户端发送一条完成的消息，该消息使用密钥加密，表示握手的服务端部分已经完成</li><li>在SSL或TLS会话期间，服务端和客户端现在可以交换使用共享密钥对称加密的消息</li></ol><p><img src="https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e8136f52-d35d-46c6-964e-ab05e6590e71/Untitled.png" alt="Untitled"></p><p>A rainbow table is a precomputed table of passwords and their hashes,</p><p><a href="https://en.wikipedia.org/wiki/Salt_(cryptography)">彩虹表对包含大量盐</a>的单向哈希无效。例如，考虑使用以下函数生成的密码哈希（其中“ + ”是<a href="https://en.wikipedia.org/wiki/Concatenation">串联</a>运算符）：</p><p><code>saltedhash(password) = hash(password + salt)</code></p><p>要么</p><p><code>saltedhash(password) = hash(hash(password) + salt)</code></p><p>salt 值不是秘密的，可以随机生成并与密码哈希一起存储。大盐值通过确保每个用户的密码被唯一地散列来防止预计算攻击，包括彩虹表。这意味着具有相同密码的两个用户将具有不同的密码哈希值（假设使用不同的盐）。为了成功，攻击者需要为每个可能的盐值预先计算表。salt 必须足够大，否则攻击者可以为每个 salt 值制作一个表。对于使用 12 位盐的旧<a href="https://en.wikipedia.org/wiki/Crypt_(C)">Unix 密码，这将需要 4096 个表，这会显着增加攻击者的成本，但对于 TB 硬盘驱动器来说并非不切实际。</a><a href="https://en.wikipedia.org/wiki/Crypt_(C)#SHA2-based_scheme">SHA2-crypt</a>和<a href="https://en.wikipedia.org/wiki/Crypt_(C)#Blowfish-based_scheme">bcrypt</a>方法——用于<a href="https://en.wikipedia.org/wiki/Linux">Linux</a>、<a href="https://en.wikipedia.org/wiki/BSD">BSD</a> Unixes 和<a href="https://en.wikipedia.org/wiki/Solaris_(operating_system)">Solaris</a> — 有 128 位的盐。<a href="https://en.wikipedia.org/wiki/Rainbow_table#cite_note-alexander-4">[4]</a>这些较大的盐值使得针对这些系统的预计算攻击对于几乎任何长度的密码都不可行。即使攻击者可以每秒生成一百万张表，他们仍然需要数十亿年才能为所有可能的盐生成表。 Or by key  strengthening</p><p>Injection—     Could try to “sanitise” (clean/make safe) data input, but there is a better solution. • Do not create SQL (or similar statements) by adding together strings. • Can use special routines designed to produce these statements. • Languages designed for the web contain functions to help with this. • In Java, PreparedStatement is a class to do this.</p><h3 id="Socket">Socket</h3><p>HTTP是构建在TCP协议之上的，而TCP可以使用Socket来实现网络通信。基于这一点，可以使用Socket编程来创建HTTP客户端或服务器。<strong>Socket API提供了对底层网络通信的访问，可以使用不同的编程语言（如Python、Java、C++等）的Socket库来实现HTTP客户端和服务器</strong>。Socket APi 也可以实现UDP通信</p><p>对于HTTP客户端：</p><ul><li>客户端可以使用Socket建立与服务器的TCP连接。</li><li>客户端通过Socket发送HTTP请求（如GET、POST等）给服务器。</li><li>服务器接收到请求后，通过Socket发送HTTP响应给客户端。</li><li>客户端通过Socket接收服务器的响应数据。</li></ul><p>对于HTTP服务器：</p><ul><li>服务器可以使用Socket监听指定端口，接收客户端的连接请求。</li><li>服务器接收到连接后，创建Socket连接到客户端。</li><li>服务器通过Socket接收来自客户端的HTTP请求。</li><li>服务器处理请求，并通过Socket发送HTTP响应给客户端。</li></ul><p>分层模型中的精华思想之一是封装（Encapsulation）。在网络协议的分层设计中，封装指的是<strong>每一层向上一层提供服务</strong>时，将上一层的数据进行封装，隐藏了底层协议的实现细节，形成一个黑盒子，<strong>上层协议不需要了解下层协议的任何细节</strong>。封装使得分层模型中的每一层都像一个黑盒，只暴露出相应的接口和功能，而隐藏了内部实现的细节，这样有利于提高系统的可靠性、可维护性和可扩展性，同时促进了协议的标准化和互操作性。</p><p>一个是 fread/fwrite 读写，一个是 recv 和 send 读写（在 Linux 下你用 read 和 write 的话，文件和 socket 两者都能读写，只是无法直接设置一些特殊的 flag）</p><p>一般的文件以及 socket 客户端读写的都是数据，而 socket 服务端 accept 读出来的是可以读写的客户端文件。</p><ol><li><strong>监听套接字 (Listening Socket)</strong>：这是服务器端的套接字，通过调用**<code>bind</code><strong>、</strong><code>listen</code><strong>和</strong><code>accept</code><strong>函数来建立。监听套接字用于等待客户端的连接请求，当客户端请求连接时，</strong><code>accept</code>**函数会返回一个新的已完成连接套接字。</li><li><strong>已完成连接套接字 (Connected Socket)</strong>：这是服务器端的套接字，也是客户端的套接字。它们通过**<code>connect</code><strong>函数（客户端）或</strong><code>accept</code><strong>函数（服务器端）建立连接后，用于实际的数据传输。这些套接字可以通过</strong><code>read</code><strong>和</strong><code>write</code>**函数来进行数据的读取和写入。</li></ol><p>成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p><p>严格来讲，“网关”是一个逻辑概念，【不要】把它当成具体的网络设备。充当“网关”的东东，可能是：路由器 or XX层交换机 or XX层防火墙 or 代理服务器 …</p><p>“网关”也分不同的层次。如果不加定语，通常指的是“3层网关”（网络层网关）。列几种比较常见的，供参考：</p><p>路由器充当网关——3层（网络层）</p><p>3层交换机充当网关——3层（网络层）</p><p>4层交换机充当网关——4层（传输层）</p><p>应用层防火墙充当网关——7层（应用层）</p><p>代理服务器充当网关——（取决于代理的层次，参见前一个小节）</p><p>“隧道协议”可以做到更灵活的包裹——既可以对层次相隔很远的协议进行包裹，也可以对同一层的协议进行包裹，甚至可以“倒挂”——所谓的“倒挂”就是让【上】层反过来包裹【下】层。</p><p>举例：</p><p>俺曾经写过一篇《<a href="https://program-think.blogspot.com/2019/04/Proxy-Tricks.html">如何让【不支持】代理的网络软件，通过代理进行联网（不同平台的 N 种方法）</a>》，其中介绍了“HTTP 代理”的两种模式：“转发模式 ＆ 隧道模式”。对于“HTTP 代理”的隧道模式，可以实现【TCP over HTTP】（把 TCP 协议打包到 HTTP 协议内部）</p><p>##<strong>Network层</strong></p><p>网络层的两种交换技术：电路交换（有连接） VS 分组交换（无连接）。</p><p>IP/ARP 是根据IP地址获取MAC地址的一种协议。/ICMP</p><ol><li><strong>IP地址：</strong> IP协议使用IP地址来唯一标识网络上的每个设备。IPv4和IPv6是两个常见的IP地址版本。IPv4使用32位地址，而IPv6使用128位地址，提供了更广泛的地址空间以应对互联网的增长需求。</li><li><strong>面向无连接：</strong> IP是一种面向无连接的协议，这意味着每个数据包（或数据报）都是独立的，不需要在通信之前建立连接。每个数据包独立传输，因此不会维护通信状态。</li><li><strong>不可靠传输：</strong> IP提供了不可靠的传输，这意味着它不保证数据包的传输顺序、可靠性或交付。数据包可能会在传输过程中丢失、重复、延迟或乱序，因此上层协议（如TCP）负责处理可靠性和顺序问题。</li></ol><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/ea503cf6-9325-47ab-9fb3-3e33e40583ef/b91e7cce-3503-4dad-b95e-3b5a338d858a/Untitled.png" alt="Untitled"></p><p>根据RFC 791，IP地址是一个32位的二进制数字，通常表示为四个八位字节的点分十进制表示法，<a href="http://xn--xxx-eo8e.xxx.xxx.xxx">如xxx.xxx.xxx.xxx</a>。</p><ol><li><strong>A类地址：</strong><ul><li>A类地址的第一个字节的最高位始终为0，这表示A类地址的范围是1.0.0.0到126.0.0.0。</li><li>这类地址通常用于大型网络，因为其范围允许约1670万个主机地址。</li></ul></li><li><strong>B类地址：</strong><ul><li>B类地址的前两个字节的最高两位始终为10，这表示B类地址的范围是128.0.0.0到191.255.0.0。</li><li>B类地址通常用于中等规模的网络，可容纳约6.5万个主机地址。</li></ul></li><li><strong>C类地址：</strong><ul><li>C类地址的前三个字节的最高三位始终为110，这表示C类地址的范围是192.0.0.0到223.255.255.0。</li><li>C类地址通常用于小型网络，每个C类网络可以容纳约254个主机地址。</li></ul></li></ol><p>在实际网络中，已经有许多其他IP地址分配方案和规则，包括子网掩码、无类域间路由（CIDR）等，这些使得IP地址的分配更加灵活和高效。所以，不再严格使用A、B、C类地址来划分网络规模。</p><p>VLSM(<a href="https://baike.baidu.com/item/%E5%8F%AF%E5%8F%98%E9%95%BF%E5%AD%90%E7%BD%91%E6%8E%A9%E7%A0%81/9163142">可变长子网掩码</a>) 是为了有效的使用<a href="https://baike.baidu.com/item/%E6%97%A0%E7%B1%BB%E5%88%AB%E5%9F%9F%E9%97%B4%E8%B7%AF%E7%94%B1/15758573">无类别域间路由</a>（CIDR）和路由汇聚(route summary)来控制<a href="https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1%E8%A1%A8/2707408">路由表</a>的大小，它是网络管理员常用的IP寻址技术</p><p>CIDR无类网络是一种相对于有类网络的网络，无类网络IP地址的掩码是变长的。<br>在有类网络的基础上，拿出一部分主机ID作为子网ID。<br>例如：<br>IP地址为192.168.250.44 子网掩码不能是小于24位。<br>因为这是一个C类地址（前3Bytes是网络号），子网掩码只能大于24位。<br>而掩码255.255.248.0（21位）是不符合规定的。<br>·<br>如果一个网络中的主机有100台，<br>那么，可以用子网掩码/25来划分这个C类网络（“192.168.250.0/24”）：<br>划分成192.168.250.0/25 和192.168.250.128/25两个子网。<br>—主机192.168.250.44/25 属于子网192.168.250.0/25。</p><p>**路由器用于不同网络之间的通信，进行跨网络的路由决策，而交换机用于内部网络的局域网络通信，将数据帧从一个接口转发到另一个接口。**在许多网络中，路由器和交换机通常是一起使用的，以实现内部通信和与外部网络的连接。</p><p><strong>路由器（Router）</strong>：</p><ol><li><strong>网络层设备：</strong> 路由器位于OSI模型的网络层，负责在不同网络之间进行数据包的转发和路由选择。</li><li><strong>跨网络通信：</strong> 路由器用于将数据包从一个网络传送到另一个网络，通常在不同IP子网之间执行路由操作。</li><li><strong>决策基于IP地址：</strong> 路由器的路由决策是基于目标IP地址进行的，它查找路由表以确定数据包应该被转发到哪个接口或下一个路由器。</li><li><strong>网络分割和隔离：</strong> 路由器可以分隔不同的网络，提供网络隔离和安全性。</li><li><strong>网络地址转换（NAT）：</strong> 一些路由器支持NAT，允许多个设备共享一个公共IP地址。</li></ol><p><strong>交换机（Switch）</strong>：</p><ol><li><strong>数据链路层设备：</strong> 交换机位于OSI模型的数据链路层，主要用于在局域网络（LAN）内的设备之间进行数据帧的交换。</li><li><strong>内部局域网络通信：</strong> 交换机用于在同一网络内的设备之间传输数据，通常在相同IP子网内工作。</li><li><strong>决策基于MAC地址：</strong> 交换机的决策是基于目标设备的MAC地址进行的，它使用MAC地址表来确定数据帧应该被发送到哪个接口。</li><li><strong>高性能：</strong> 交换机通常提供高性能的数据交换，因为它们在硬件级别进行操作，不需要进行复杂的路由选择。</li><li><strong>无状态：</strong> 交换机通常是无状态设备，不存储关于通信的历史信息，而路由器可能会维护路由表和状态信息。</li></ol><h3 id="爬">爬</h3><p><a href="https://websec.readthedocs.io/zh/latest/info/site.html">https://websec.readthedocs.io/zh/latest/info/site.html</a></p><p>robots.txt 也不是强制的规范，而是一种内容网站和搜索引擎之间博弈的产物。对于一个搜索引擎来说，遵守或者不遵守只关乎你作为一个搜索引擎的声誉，大多数时候还是遵守的，比如说百度上至今不能搜索淘宝宝贝，因为淘宝主动屏蔽了百度。内容站点也不是啥<a href="https://www.zhihu.com/search?q=%E7%99%BD%E6%9C%88%E5%85%89&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A2081752804%7D">白月光</a>，无非也是想要<strong>搜索引擎带来的流量，但是又不想爬虫占用服务器资源</strong>。</p><p><a href="http://zhihu.com">zhihu.com</a>/robots.txt</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">User-agent: Googlebot</span><br><span class="line">Disallow: /appview/</span><br><span class="line">Disallow: /login</span><br><span class="line">Disallow: /logout</span><br><span class="line">Disallow: /resetpassword</span><br><span class="line">Disallow: /terms</span><br><span class="line">Disallow: /search</span><br><span class="line">Allow: /search-special</span><br><span class="line">Disallow: /notifications</span><br><span class="line">Disallow: /settings</span><br><span class="line">Disallow: /inbox</span><br><span class="line">Disallow: /admin_inbox</span><br><span class="line">Disallow: /*?guide*</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>数据提取：</p><ol><li><strong>请求发送与响应获取</strong>：爬虫程序通过发送 HTTP/HTTPS 请求获取网页内容，通常使用库或框架（如Python的requests、Scrapy等）来发送请求，并接收并解析网页服务器返回的响应。</li><li><strong>网页解析与DOM操作</strong>：爬虫需要解析 HTML 或 XML 格式的网页内容以提取所需的信息。通常使用解析器（如Beautiful Soup、lxml等）来解析网页结构，并使用 XPath 或 CSS 选择器等技术定位和提取所需的数据。</li><li><strong>动态网页抓取</strong>：针对使用 JavaScript 动态加载内容的网页，爬虫需要模拟浏览器行为，如使用无头浏览器（Headless Browser）或类似工具（如Selenium）来渲染 JavaScript，并获取动态生成的内容。 <strong>模拟浏览器行为</strong>：对于需要处理动态内容或使用 JavaScript 渲染的网页，模拟浏览器行为更有优势，甚至可能需要处理 WebSocket 连接。</li><li>并发 分布式： ip代理池</li><li></li></ol><p>反爬虫技术：</p><ol><li><strong>动态内容生成</strong>：网站使用动态生成内容或者 Ajax 请求，这使得爬虫难以捕获完整的页面数据。</li><li><strong>网站结构变化</strong>：经常更改网站的页面结构、URL格式或数据的位置，使得爬虫难以获取持续准确的数据。</li><li><strong>使用登录验证</strong>：限制对需要用户登录的内容的访问，要求爬虫模拟登录行为才能获取数据。</li><li><strong>robots.txt 文件</strong>：用于向搜索引擎爬虫提供指导，告知哪些页面可以被索引，哪些页面不应该被索引。</li><li><strong>IP 黑名单</strong>：阻止来自特定IP地址的请求，这些IP地址可能是已知的恶意爬虫。</li><li><strong>用户代理检测</strong>：识别请求中的用户代理（User-Agent），并阻止或限制来自爬虫的请求。</li><li><strong>验证码</strong>：通过向用户展示验证码，要求用户进行验证以确认其身份，从而阻止自动化爬虫。</li><li><strong>频率限制</strong>：限制对网站的访问频率，例如限制某个IP地址或用户在特定时间段内的请求次数。</li><li><strong>JavaScript 加载</strong>：某些爬虫不支持JavaScript，网站可以利用JavaScript动态加载内容，使得爬虫难以获取完整的页面内容。</li></ol><p>Service worker 本质上充当 Web 应用程序、浏览器与网络（可用时）之间的代理服务器。这个 API 旨在创建有效的离线体验，它会拦截网络请求并根据网络是否可用来采取适当的动作、更新来自服务器的的资源。它还提供入口以推送通知和访问后台同步 API。</p><p>Service workers 也可以用来做这些事情：</p><ul><li>后台数据同步</li><li>响应来自其他源的资源请求</li><li>集中接收计算成本高的数据更新，比如地理位置和陀螺仪信息，这样多个页面就可以利用同一组数据</li><li>在客户端进行 CoffeeScript、LESS、CJS/AMD 等模块编译和依赖管理（用于开发目的）</li><li>后台服务钩子</li><li>自定义模板用于特定 URL 模式</li><li>性能增强，比如预取用户可能需要的资源，比如相册中的后面数张图片</li></ul><p>未来 service worker 能够用来做更多使 web 平台接近原生应用的事。值得关注的是，其他标准也能并且将会使用 service worker，例如：</p><ul><li><a href="https://github.com/slightlyoff/BackgroundSync">后台同步</a>：启动一个 service worker 即使没有用户访问特定站点，也可以更新缓存</li><li><a href="https://developer.mozilla.org/zh-CN/docs/Web/API/Push_API">响应推送</a>：启动一个 service worker 向用户发送一条信息通知新的内容可用</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;Web Security&lt;/h1&gt;
&lt;p&gt;在广阔的互联网领域，信息源源不断，交易瞬息万变，一场无声的战斗正在上演。网络威胁潜伏在阴影中，试图利用漏洞并破坏我们建造的数字堡垒。这就是网络安全的领域，一个动态且不断发展的领域，它是用户与渗透到网络世界的无数风险之间的守护者。&lt;</summary>
      
    
    
    
    
    <category term="网络安全" scheme="https://stan370.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>你的网络你做主？—— 浅谈宽带限制上传、TR069 与 PCDN 那些事</title>
    <link href="https://stan370.github.io/2024/12/02/surveillance/"/>
    <id>https://stan370.github.io/2024/12/02/surveillance/</id>
    <published>2024-12-02T12:08:39.000Z</published>
    <updated>2025-06-08T15:48:59.059Z</updated>
    
    <content type="html"><![CDATA[<p>前几年受“提速降费”政策影响，国内高速宽带发展非常快。然而此一时彼一时，“互联网经济”这个话题落幕，运营商开始重新圈地。“打击 PCDN ”似乎就是吹响运营商利益至上的号角。</p><p>按照惯例，政策执行后续都会扩大化。说是禁 PCDN ，目前已经有扩大化迹象，比如顺带被封禁的 PT 和 NAS 服务。这两个服务同样容易产生较大网络流量，所以容易被误伤。不过事情还不仅如此。网络监控会进一步收紧，运营商会全面监控网络流量，这种监控是否进一步扩大化不详。</p><p>最近，不少网友反映，家里的宽带网关似乎变得“不太安分”了。以中国移动为例，后台进程里多了几个不认识的应用，比如 com.chinamobile.smartgateway.andlink、com.chinamobile.smartgateway.cmccdpi、com.chinamobile.smartgateway.appcore 和 com.cmcc.wuyougateway。这些应用是什么？它们在干什么？运营商为什么要这么做？今天我们就来聊聊这个话题。<img src="https://cdn.jsdelivr.net/gh/Stan370/stan370.github.io@main/themes/hexo-theme-matery/source/medias/image.png" alt="alt text"><br>中国移动在为用户安装宽带时，总会好心地“赠送”一个光猫(调制解调器)。这看似是个不错的促销手段，但通常情况下，这个“赠品”会给用户带来许多麻烦。</p><p>赠送的“光猫”安装了许多不必要的功能。光猫的本职工作是进行光电转换，然而中国移动的“光猫”不仅承担着光电转换的任务，还同时进行拨号上网、路由、地址转换(NAT)、端口映射、文件服务器(FTP)等等额外的功能。这些功能让本就廉价而算力低下的光猫运行缓慢，不堪重负。最可气的是，中国移动为了节约维护成本，将光猫的绝大多数设置项锁定，防止用户修改。</p><p>用户想要拿到光猫的控制权，这是一个很常见的需求，尤其是在对网络有一定了解和个性化需求的用户群体中。然而，由于运营商出于网络稳定、业务安全和管理便捷等方面的考虑，往往会对光猫进行限制，用户很难完全掌控自己的设备。为了重新“拥有”光猫，我决定夺回对光猫的控制权。</p><p><strong>“神秘”的应用们：功能与争议</strong></p><p>2019年10月28日，有人在 Pastebin 公开了一份华为路由器的某个配置文件， 其中就有 com.chinamobile.smartgateway.cmccdpi 插件。</p><p>2022 年8月，多个技术论坛（如知乎、贴吧、恩山无线论坛等）开始涌现用户对中国移动宽带服务的投诉和技术讨论。一些用户尝试通过第三方手段获取超级管理员权限（如解密密码、破解光猫固件）。另一些用户干脆自购路由器，尝试完全绕过光猫的管理干预。<br>用户发现通过 4in6 隧道接入的家庭网络通常会叠加多层 NAT，导致端口映射功能受限，无法高效实现公网通信。用户发现移动宽带在 IPv6 网络部署中引入了 4in6 隧道技术，通过将 IPv4 流量封装到 IPv6 中传输。删除 TR-069 是否有效？<br>TR-069 协议是宽带运营商常用的远程管理工具，但部分用户指出，即使禁用该协议，光猫依然接受远程指令，表明可能存在其他未知远程管理机制。<br>超级密码的再下发：<br>用户多次修改光猫管理员密码后，运营商会周期性地通过远程下发随机生成的超级密码覆盖原密码，这让用户感到隐私受侵。</p><p>2023年4月23日，谷子猫发布了博文，表示移动的光猫含有一些特殊插件，分别是：</p><p>com.cmcc.wuyougateway<br>com.chinamobile.smartgateway.andlink<br>com.chinamobile.smartgateway.cmccdpi<br>com.chinamobile.smartgateway.appcore<br>它们似乎被称为「软探针」，能够生成给用户观看的「家庭网络使用概览」，其中含有社交、游戏、视频等应用类型的流量占比， 并且还有「网络安全防护情况」，能为用户检测安全风险，比如「检测不良内容网站」。当使用桥接，通过路由器上网后， 上述功能就会失效。</p><p>所以 …cmccdpi 插件最后的 dpi，应该就是指深度包检测（DPI），或许还有 DNS 请求记录之类的功能。有这样的功能， 才能起到提供信息以及保护用户的作用。但是这些数据除了呈现给用户，是否还分享给第三方，暂不可知。</p><p><strong>TR069：运营商的“远程控制”</strong></p><p>这些应用是如何被安装到你的网关里的呢？答案就是 TR069。</p><p>TR069 是一种标准化的远程管理协议，允许运营商远程配置和管理用户家中的网关设备。通过 TR069，运营商可以下发配置、更新固件、诊断故障，当然也可以安装和启动应用。</p><p>TR069 的存在，让运营商可以更高效地管理大规模的网络设备，及时修复漏洞、推送更新，保障网络稳定运行。但同时，也赋予了运营商极大的控制权，用户在某种程度上失去了对自己网关的掌控。</p><h1><strong>PCDN 大潮下的运营商考量</strong></h1><p>这一切的背后，是 PCN（Peer Content Network，对等内容网络）和 CDN（Content Delivery Network，内容分发网络）技术的发展和普及。</p><p>随着互联网流量的爆炸式增长，传统的中心化内容分发模式已经难以满足需求。中国多地互联网服务提供商（ISP）对基于PCDN（个人云分布式网络）的相关业务采取了严厉措施，包括限速、封停宽带、甚至要求用户签署保证书恢复部分网络服务。这种强制性政策主要出于以下几点考量：</p><p>网络负担与成本问题：PCDN通过利用家庭宽带的上行带宽分发内容，可能导致网络拥堵，特别是在上行带宽较小的小区网络中，还会加大运营商在骨干网扩容和运维方面的成本​<br>商业竞争与监管合规性：运营商的核心收入来源之一是提供CDN（内容分发网络）服务，而PCDN的广泛使用可能蚕食这一市场。此外，根据中国工信部的相关规定，未取得经营许可证的个人或企业不得提供CDN服务，因此个人通过PCDN设备牟利被视为违法<br>短视频博主“影视飓风”引发了一场关于视频画质的热议。他在微博上透露，由于多种原因，其与视频清晰度相关的内容被要求在全网下架。这起事件迅速吸引了大量关注，引发了人们对视频平台画质压缩策略的讨论。</p><p>影视飓风此前发布了一则科普视频《清晰度不如4年前！视频变糊是你的错觉吗？》，指出一些视频平台为了降低流量成本，采用降低码率和改变编码格式等措施。这种动态调节码率的做法在视频热门时尤为常见，目的是节省带宽，但这可能导致画质下降</p><p>此外，DPI 技术在 PCN/CDN 架构中也扮演着重要角色。通过分析网络流量，运营商可以更精准地进行内容调度和缓存，提升 PCN/CDN 的效率。同时，DPI 也可以用于识别和过滤非法内容，保障网络安全。</p><h1><strong>如何摆脱控制</strong></h1><p>改光猫桥接，最麻烦的就是超密的获取。<br>一些省份或者运营商，是网络上可查的通用帐号密码。这就比较好办<br>还有一些地方，超密是自动下发的，甚至会定期自动更改。这就很麻烦。<br>而且运营商非常与时俱进，很多网络上容易获取的办法，他们都已经想办法屏蔽掉了。因此，即便是同运营商同型号设备，或许网络上找到的办法，也未必能在你的手里成功。</p><p>总得来说就是获取超级密码、开telnet、改桥接、改地区、禁用TR069。注意 用户需要具备一定的技术知识和技能，才能正确地配置和管理光猫。</p><p><strong>用户：知情权与选择权</strong></p><p>然而，在运营商追求效率和商业利益的同时，用户的知情权和选择权也应该得到尊重。</p><p>运营商应该向用户清晰地说明智能网关应用的功能、作用以及数据使用方式，获得用户的明确授权。用户应该有权选择是否启用这些功能，并有权卸载或禁用不需要的应用。</p><p>此外，运营商也应该加强安全防护，保护用户数据安全，防止隐私泄露。只有在用户信任的基础上，运营商的这些举措才能真正发挥作用，实现用户、运营商和整个互联网生态的多赢。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前几年受“提速降费”政策影响，国内高速宽带发展非常快。然而此一时彼一时，“互联网经济”这个话题落幕，运营商开始重新圈地。“打击 PCDN ”似乎就是吹响运营商利益至上的号角。&lt;/p&gt;
&lt;p&gt;按照惯例，政策执行后续都会扩大化。说是禁 PCDN ，目前已经有扩大化迹象，比如顺带</summary>
      
    
    
    
    
    <category term="网络安全" scheme="https://stan370.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"/>
    
  </entry>
  
  <entry>
    <title>日本麻将（日麻）策略分析</title>
    <link href="https://stan370.github.io/2024/11/07/Riichi/"/>
    <id>https://stan370.github.io/2024/11/07/Riichi/</id>
    <published>2024-11-07T06:41:43.000Z</published>
    <updated>2025-03-19T12:12:05.248Z</updated>
    
    <content type="html"><![CDATA[<h1>日本麻将（日麻）策略与基本规则</h1><h2 id="基本规则">基本规则</h2><p>日本麻将是一种四人游戏，使用136张牌。每位玩家开始时有13张牌，目标是通过摸牌和打牌来完成一个有效的和牌组合。<br>日本麻将（日麻）在规则和策略上与中国麻将有一些差异。以下是一些主要的日麻策略，以帮助你在游戏中做出更好的判断：</p><ol><li>基本策略：<br>追求速度与效率：日麻中的目标通常是尽快听牌（进入只差一张就能和牌的状态）。为了达到这个目标，你需要根据听牌的速度调整手牌，尽量去做最有效率的组合，比如三面听、两面听，避免做边张和嵌张等较难摸到的听口。<br>优先两面搭子：两面搭子（例：34等可以和2或5完成顺子）在游戏中最为常见，也是最容易形成有效听牌形态的，因此在整理手牌时，优先保留两面搭子，提高听牌概率。</li><li>役的意识：<br>追求基本役：在日麻中，至少要有一个“役”才能胡牌，因此你在整理手牌时，需要始终考虑如何达成至少一个“役”。常见的基本役包括立直（リーチ）、断幺九（タンヤオ）、平和（ピンフ）等。立直是最简单且最稳定的役之一，只要手牌接近听牌且达到门清（没有吃、碰、杠），可以选择立直来增加胜率。<br>利用役牌：如果手上有较多的场风牌、门风牌或三元牌（白、发、红中），尽量保留，形成“役牌”组合（役牌雀头），这是稳定得分的手段。</li><li>判断手牌的价值：<br>考虑点数：在日麻中，不仅仅是胡牌，点数（和牌的价值）也是非常重要的。在决定是否吃、碰、杠或立直时，需要根据当前手牌的情况评估点数。例如，只有立直+门清平和可能得点较低，如果有机会组合出高分役（如一气通贯、混一色、对对和等），可以适当放弃一些较快的听牌路线。<br>追求满贯及以上的役：当起手较好时，可以尝试追求大役（例如清一色、混全带幺九、七对子等）。这时，需要稳住心态，不急于碰牌或立直，减少暴露手牌的机会，增加隐蔽性。</li><li>防守策略：<br>学会观察舍牌：观察对手的出牌，尤其是在对手立直的情况下，尽量不要轻易打出他们可能需要的牌。例如，如果对手舍出字牌（白、发、中等），通常表示这些字牌不在他们的听牌或役牌之中，这些字牌往往是安全牌。<br>牌河判断：观察对手的舍牌序列，特别注意其连续打出的牌，寻找其可能听的牌的线索。例如，对手突然打出一张生张（没人打过的牌），可能表明他们已经听牌，尤其是对一张牌的犹豫，往往能说明手牌状态。</li><li>灵活变通：<br>根据场况调整策略：如果你在比赛的前半段得分领先，可以偏向防守，避免打出危险牌，放弃高风险高回报的打法。相反，如果你的点数较少甚至面临危险，需要积极追求高分和牌，尽量打破对手的节奏。<br>熟悉流局规则：了解流局时听牌的奖励，以及四家立直、四家碰、九种九牌等特殊情况，并利用这些规则在特定场合中止对手的攻势或为自己争取时间。</li></ol><h2 id="经验之谈">经验之谈</h2><p>给日麻新手的建议</p><ol><li>东风战，以和牌率为优先；东南战(半庄战)，以做大牌为准则。</li><li>千万、千万不要随便杠牌，尤其是大明杠。</li></ol><p>杠牌最大的意义是翻悬赏牌，每个人的手牌机率都是平等的，在1vs3的游戏中宝牌在敌人手上的机率高达75%、在自己手上的机率仅有25%，期望值极低。</p><p>所以加杠基本上也只有一个情况（但比大明杠时机常见很多）：<strong>你的手牌牌型较好</strong>听牌（或一向听好牌），且其他家还没有威胁性（没有立直或多个副露）</p><p>如果手牌中没有明确的役（例如没有成对的三元牌、风牌），杠牌可能只能带来额外的杠分，而无法大幅提高手牌的得点。这种情况下，与其选择杠牌，不如尽量保持手牌的灵活性，等待形成更高得点的牌型。</p><ol start="3"><li>确定自己有役，才考虑鸣牌(吃、碰、大明杠)</li></ol><ul><li>开局的单张<strong>自风、场风和三元牌</strong>通常可以保留几巡，以增加形成役牌的机会。</li><li>若是<strong>非自风、非场风的风牌</strong>，或牌面结构明确追求速度时，可以早些舍出这些牌，增加摸牌效率。</li><li>在<strong>速攻</strong>策略下，为减少无用牌的阻碍，风牌和三元牌也可以在确定无用时提前舍出。</li></ul><p>4o</p><p>可以先记得「什么时候不该鸣牌」，等以上几课的能力都熟悉之后再深入学习。</p><p>早巡不鸣。牌越烂越不该鸣。牌越小越不该鸣。<br>在4巡前，除非你有确定3-4翻以上的大牌，否则不该鸣牌。因为越早巡牌通常越烂，这时候自摸牌成为有效进张、让向听数前进的机会也很高。摸了几手之后手牌稍微定型，对于手牌的打点与速度判断才会更加地准确。</p><p>牌越烂指的是向听数越多的意思。在3向听以上的手牌，除非这个鸣牌能大幅度的加速手牌的进展，否则应该忍住。因为烂的牌鸣牌之后也只是变得没那么烂，往往速度上还是会输给牌形较好的玩家。若为了速度去过度鸣牌，在对手立直对攻时防守力不足就相当吃亏。</p><p>大幅落后时不鸣。</p><p>因为落后时需要高得点来逆转，而鸣牌会让手牌分数无法再提高。所以除非手牌分数足够大，否则都该忍住去拼立直。</p><p><strong>「该鸣牌的时机」</strong></p><p>后半场(例如东风场的3-4局、南风场的南2-南4)，自己大幅领先，且鸣牌确定有役又能让手牌向听数前进的时候。就是速攻不给别人逆转机会的概念，不过还是要注意鸣牌之后的手牌牌形/向听数不能太差。毕竟速攻总得确保自己有「速」对吧</p><p>倒数三巡，安全牌足够多且有听牌机会时。</p><p>因为流局有不听罚符，所以可以在确信不会放铳时，鸣牌追求形式听牌。</p><p>基本上注意以上三点有关于振听的部分，我在细项说明之后也会提及并解释一下其原理</p><p>以下分项说明：</p><ul><li>东风战，以和牌率为优先；东南战(半庄战)，以做大牌为准则。</li></ul><h2 id="基本策略">基本策略</h2><ul><li>**听牌速度：**尽快形成听牌（听牌指离和牌只差一张牌的状态）。</li><li>**防守意识：**注意其他玩家的打牌，避免放铳（给对手和牌）。</li><li>**役种意识：**了解并争取高分值的役种（特定的和牌组合）。</li><li>**牌效率：**保持手牌的灵活性，避免过早固定牌型。</li></ul><h2 id="重要概念">重要概念</h2><ul><li>**立直：**宣告听牌并锁定手牌，可以增加得分。</li><li>**副露：**通过吃、碰、杠来快速完成牌型，但会限制可能的和牌组合。</li><li>**宝牌：**特定的增加得分的牌。</li></ul><h2 id="进阶技巧">进阶技巧</h2><p>常用日麻AI： <a href="https://mjai.ekyu.moe/zh-cn.html%EF%BC%8C">https://mjai.ekyu.moe/zh-cn.html，</a> <a href="https://github.com/Equim-chan/Mortal">https://github.com/Equim-chan/Mortal</a><br>牌效率：<a href="https://euophrys.itch.io/mahjong-efficiency-trainer?fbclid=IwAR3w3WZnfmSrx4_Zi0kb38jSmWgSFRyZbAMeDQD9rZFFF4Asw1oz63n4gi0">https://euophrys.itch.io/mahjong-efficiency-trainer?fbclid=IwAR3w3WZnfmSrx4_Zi0kb38jSmWgSFRyZbAMeDQD9rZFFF4Asw1oz63n4gi0</a></p><ul><li>**读牌：**根据其他玩家的打牌推测他们的手牌。</li><li>**河底读牌：**分析已经打出的牌来判断安全牌。</li><li>**场势判断：**根据当前局势决定是否应该攻击或防守。</li></ul><p>记住，麻将是一种需要长期练习和经验积累的游戏。持续学习和实践是提高技能的关键。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;日本麻将（日麻）策略与基本规则&lt;/h1&gt;
&lt;h2 id=&quot;基本规则&quot;&gt;基本规则&lt;/h2&gt;
&lt;p&gt;日本麻将是一种四人游戏，使用136张牌。每位玩家开始时有13张牌，目标是通过摸牌和打牌来完成一个有效的和牌组合。&lt;br&gt;
日本麻将（日麻）在规则和策略上与中国麻将有一些差异。以</summary>
      
    
    
    
    <category term="随谈" scheme="https://stan370.github.io/categories/%E9%9A%8F%E8%B0%88/"/>
    
    
    <category term="概率论" scheme="https://stan370.github.io/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"/>
    
    <category term="组合数学" scheme="https://stan370.github.io/tags/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/"/>
    
    <category term="决策理论" scheme="https://stan370.github.io/tags/%E5%86%B3%E7%AD%96%E7%90%86%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>Coding philosophy</title>
    <link href="https://stan370.github.io/2024/10/10/notion/"/>
    <id>https://stan370.github.io/2024/10/10/notion/</id>
    <published>2024-10-10T04:49:46.000Z</published>
    <updated>2025-04-13T08:54:56.275Z</updated>
    
    <content type="html"><![CDATA[<h1>Coding philosophy</h1><p>我们编写的每一行代码都讲述一个故事。它反映了我们的思维过程、解决问题的方法以及我们对手头任务的理解。但除了功能之外，代码还体现了一种哲学——指导我们的决策并塑造我们创建的软件的一组原则。This blog delves into the fascinating world of coding philosophies. We’ll explore the diverse approaches developers take, from prioritizing elegance and simplicity to embracing pragmatism and efficiency. We’ll discuss the trade-offs inherent in each philosophy and how they influence everything from code readability and maintainability to project timelines and team dynamics.</p><p>水平差的程序员往往对代码 “<strong>不讲究</strong>”，这其实是工程素养差的表现。</p><p>那不讲究的代码是什么样的呢？比如，同样含义的变量使用不同的名字、对偶功能（如增删改查）命名不成体系、相似代码不断重复而没有重用、反常逻辑没有任何注释、子模块间头重脚轻、好好的封装被改出几个洞等等（关于如何命名可参考我之前的一篇<a href="https://www.qtmuniao.com/2021/12/12/how-to-write-code-scrutinize-names/">文章</a>）</p><p><strong>生命周期</strong>。生命周期越长的代码，一定要写的越干净；临时使用代码，比如小脚本，就可以不讲究一些。反过来，也正是干净的代码才能成就超长的生命周期。</p><ul><li><p><strong>不要贬低你的工作</strong></p><p>因为是新人，新手程序员总是倾向于认为他们的工作没那么重要。又或者也许你是一个有经验的程序员，但是在一个让你感到不适应的新领域里工作。在我看来，一些最好的想法正是来自于新手程序员，他们能看到现有技术的可改进之处，而那些已经形成固有观念的人却看不到。</p><p>无论如何，你的工作都是有价值的。在最坏的情况下，如果你的方法失败了，社区至少可以更好的了解为何这种方法行不通。（对社区的一点说明：这条是我们要做的，要对新人友好一些。）</p></li><li><p><strong>不用总是在压力下工作</strong></p><p>新技术每天都会出现，这可能会让你觉得如果放慢脚步，就会与这个世界脱节。然而并不是这样的。事实上，如果你能很好的休息，你就能更好的工作。你的思路将保持清晰，我发现当我不工作时，我的潜意识里会出现很多新想法。</p><p>那些每天不断发布的内容大部分都是一些现有想法的翻版。真正革命性的东西只会每几年才发生一次。关于这个话题有一个不错的分享值得一看：<a href="https://www.youtube.com/watch?v=f84n5oFoZBc">吊床驱动开发</a></p></li></ul><h1>System design</h1><p>技术创新与生产关系变革联系起来，并探讨了软件和运维架构背后的组织结构。这种观点可以为我们更好地理解技术变革的动力提供新的视角。让我们进一步探讨一下这些观点及其背后的逻辑。</p><h3 id="技术创新与生产关系的变革">技术创新与生产关系的变革</h3><p><strong>容器和容器编排的兴起：</strong></p><ul><li><strong>背景：</strong> 传统的虚拟机管理技术在面对大规模服务器时显得笨重和低效。</li><li><strong>需求：</strong> Google 等大型互联网公司需要一种更高效的管理方式，以便少数人能够管理数十万台服务器。</li><li><strong>解决方案：</strong> Kubernetes 的诞生使得容器编排成为可能，大大提高了资源利用率和管理效率。</li></ul><p>这一变化不仅仅是技术上的创新，更是生产关系的变革。容器技术和容器编排的兴起，使得运维团队能够更加高效地协作和管理庞大的计算资源，实现了真正的自动化和规模化运维。</p><h3 id="软件架构与团队组织架构">软件架构与团队组织架构</h3><p>软件架构反映团队组织（康威定律）：</p><p>你提到了软件架构设计受到团队组织结构的影响，这正是康威定律的核心思想：</p><p>“组织架构决定了系统架构。”（Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.）</p><p>这种架构的最大价值在于，它不仅仅是技术上的进步，更是对团队组织形式的一种优化，从而提升了整体的软件质量和开发效率。</p><h3 id="宏内核与微内核的争论">宏内核与微内核的争论</h3><p><strong>操作系统内核设计的选择：</strong></p><ul><li><strong>宏内核：</strong> 由一个庞大的工程团队开发和维护，功能完备，但相对复杂。</li><li><strong>微内核：</strong> 由于资源有限，只专注于核心功能，其他功能由用户态软件实现。</li></ul><p>这种选择背后实际上是组织协作方式的不同。大型公司可以投入大量资源开发复杂的宏内核，而开源项目则更倾向于开发微内核，通过社区协作来实现功能扩展。</p><h3 id="实例分析">实例分析</h3><p><strong>IPVS、cgroups、eBPF 等技术：</strong></p><ul><li>这些技术最初在用户态实现，但随着性能和功能需求的增加，逐渐进入了内核态。</li><li>这种迁移反映了对性能优化和功能需求的不断追求，同时也展示了技术发展过程中组织和协作方式的演变。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;Coding philosophy&lt;/h1&gt;
&lt;p&gt;我们编写的每一行代码都讲述一个故事。它反映了我们的思维过程、解决问题的方法以及我们对手头任务的理解。但除了功能之外，代码还体现了一种哲学——指导我们的决策并塑造我们创建的软件的一组原则。This blog delves </summary>
      
    
    
    
    <category term="感想" scheme="https://stan370.github.io/categories/%E6%84%9F%E6%83%B3/"/>
    
    
    <category term="personal growth" scheme="https://stan370.github.io/tags/personal-growth/"/>
    
  </entry>
  
  <entry>
    <title>重新认识操作系统</title>
    <link href="https://stan370.github.io/2024/09/17/Linux0/"/>
    <id>https://stan370.github.io/2024/09/17/Linux0/</id>
    <published>2024-09-17T12:43:33.000Z</published>
    <updated>2025-03-19T12:12:05.247Z</updated>
    
    <content type="html"><![CDATA[<h1>操作系统OS</h1><p>在学习操作系统的过程中，我们会接触到众多复杂的概念，如内核、进程管理、内存管理、文件系统等。为了更好地掌握这些内容，建议采取循序渐进的学习路线，从理论到实践、从基础到进阶，逐步深入。</p><p>学习路线</p><ol><li>操作系统的基本概念与历史<br>学习操作系统的基础知识，了解其核心功能和发展历史。<br>操作系统的起源（如 UNIX 的发展、GNU 项目的影响）<br>现代操作系统的类型及其关系（如 Linux、Windows、macOS）</li><li>操作系统的核心技术<br>掌握内核、进程、线程、内存管理、文件系统等关键概念。<br>内核的设计与功能（特别是 Linux 内核的架构）<br>进程与线程的管理（理解 fork()、进程调度等）<br>内存管理的机制:MMU 和虚拟内存: 深入理解 MMU 和虚拟内存的工作原理，以及分页技术和地址翻译机制。<br>页面置换算法: 了解常用的页面置换算法，如 LRU、FIFO 和 LFU。<br>写时复制 (COW): 掌握 COW 技术的概念和应用，例如在 fork() 中的使用。<br>字节序 (Endianness): 了解大端序和小端序的区别，以及它们在数据存储和网络传输中的重要性。<br>内存泄漏: 理解内存泄漏的概念和危害，并学习如何避免内存泄漏。<br>文件系统的结构与实现（从文件的存储到系统调用）</li><li>进阶专题：并发与多任务处理<br>理解并发、并行、以及多任务处理在操作系统中的应用。<br>推荐学习内容：<br>不同的文件系统类型（FAT、NTFS、ext4、Btrfs）、使用的数据结构（索引节点、目录条目）、日志记录、磁盘调度算法。<br>进程间通信（IPC）、信号量、锁机制<br>多线程编程与并发控制（如 pthread 库的使用）</li></ol><p>第四阶段：系统管理和工具<br>系统管理工具: 熟悉常用的 Linux 系统管理工具，如 systemd、cron、top/htop、ps、journalctl 和 dmesg。<br>文件管理工具: 掌握常用的 Linux 文件管理工具，如 ls、cp、mv、rm、find、grep、tar、gzip、bzip2、chmod 和 chown。<br>文本处理工具: 学习常用的 Linux 文本处理工具，如 vim、nano、sed、awk、cat、less 和 more。<br>网络工具: 熟悉常用的 Linux 网络工具，如 ifconfig/ip、ping、traceroute、ssh、curl、wget、netstat、ss、iptables 和 nftables。<br>第五阶段：高级主题<br>DMA 零拷贝: 了解 DMA 零拷贝技术及其在提高文件传输性能方面的作用。<br>空分复用和时分复用: 理解空分复用和时分复用的概念及其在操作系统中的应用。<br>多线程/多进程: 学习多线程和多进程的概念，以及它们在解决阻塞问题和提高程序并发性方面的应用。<br>协程: 了解协程的概念和优势，以及它们与线程的区别</p><p><strong>实践为主: 学习 Linux 最重要的是实践，建议你在学习过程中多动手操作，例如在虚拟机或云服务器上安装 Linux 系统 or 实现一个多线程程序，理解线程调度与同步并尝试使用各种命令和工具。</strong></p><h2 id="硬件基础">硬件基础</h2><p><img src="https://pic.leetcode-cn.com/1642125846-FXGHTw-20210216234120.png" alt="structure"><br>地址空间（address space）表示任何一个计算机实体所占用的内存大小</p><p><strong>程序局部性原理</strong>：是指程序在执行时呈现出局部性规律，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域，具体来说，局部性通常有两种形式：时间局部性和空间局部性。</p><p>**时间局部性：**被引用过一次的存储器位置在未来会被多次引用（通常在循环中）。</p><p>**空间局部性：**如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。</p><p><strong>存储器抽象</strong></p><p>在<a href="https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E6%9C%BA">计算机</a>中，每个设备以及进程都被分配了一个<strong>地址空间</strong>。处理器的地址空间由其<a href="https://baike.baidu.com/item/%E5%9C%B0%E5%9D%80%E6%80%BB%E7%BA%BF">地址总线</a>以及<a href="https://baike.baidu.com/item/%E5%AF%84%E5%AD%98%E5%99%A8">寄存器</a>决定。地址空间可以分为Flat——表示起始空间位置为0；或者Segmented——表示空间位置由<a href="https://baike.baidu.com/item/%E5%81%8F%E7%A7%BB%E9%87%8F">偏移量</a>决定。在一些系统中，可以进行地址空间的类型转换。至于IP地址空间，IPV4协议并没有预见到IP地址的需求量如此之大，32位的地址空间已经无法满足需求了。因此，开发了<a href="https://baike.baidu.com/item/IPV6%E5%8D%8F%E8%AE%AE">IPV6协议</a>，支持128位的地址空间 [1] 。</p><p><strong>暴露问题</strong></p><p>把物理地址暴露给进程会带来下面几个严重问题。第一，如果<a href="https://baike.baidu.com/item/%E7%94%A8%E6%88%B7%E7%A8%8B%E5%BA%8F">用户程序</a>可以寻址内存的每个<a href="https://baike.baidu.com/item/%E5%AD%97%E8%8A%82">字节</a>，它们就可以很容易地（故意地或偶然地）破坏操作系统，从而使系统慢慢地停止运行。即使在只有一个用户进程运行的情况下，这个问题也是存在的。第二，使用这种模型，想要同时（如果只有一个CPU就轮流执行）运行多个程序是很困难的。在<a href="https://baike.baidu.com/item/%E4%B8%AA%E4%BA%BA%E8%AE%A1%E7%AE%97%E6%9C%BA">个人计算机</a>上，同时打开几个程序是很常见的（一个文字处理器，一个邮件程序，一个<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E6%B5%8F%E8%A7%88%E5%99%A8/12509222">网络浏览器</a>，其中一个当前正在工作，其余的在按下鼠标的时候才会被激活）。在系统中没有对<a href="https://baike.baidu.com/item/%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98">物理内存</a>的抽象的情况下，很难做到上述情景，因此，我们需要其他办法。</p><p>为了解决这些问题，现代操作系统使用虚拟内存技术，将物理地址空间抽象成虚拟地址空间，并通过<strong>内存管理单元（MMU）<strong>来实现地址转换，使得每个进程只能访问自己的</strong>虚拟地址空间</strong>，从而提高系统的安全性、隔离性和稳定性。</p><h2 id="MMU管理">MMU管理</h2><h3 id="Data-fetching">Data fetching</h3><p>OS使用内存从磁盘中取数据的过程通常称为“数据加载”或“页面调度”，涉及操作系统和硬件的协作，以下是这一过程的详细解释：</p><ol><li><strong>CPU与内存的关系</strong></li></ol><p><strong>CPU</strong>：<strong>中央处理器（CPU）无法直接从磁盘读取数据，所有要执行的指令和数据都必须先加载到内存（RAM）中。</strong></p><ol start="2"><li><strong>磁盘与内存之间的数据交换机制</strong></li></ol><p><strong>分页机制（Paging）</strong>：现代操作系统通常采用虚拟内存管理，其中包含分页机制。当某个程序需要访问的数据不在内存中时，操作系统会将所需的数据从磁盘加载到内存。</p><ol start="3"><li><strong>数据从磁盘加载到内存的过程</strong></li></ol><p>3.1 <strong>虚拟内存与页表</strong></p><p><strong>虚拟内存</strong>：操作系统将每个进程分配一个虚拟地址空间，这些虚拟地址并不直接对应物理内存，而是通过页表（Page Table）进行映射。</p><p><strong>页表</strong>：页表记录了虚拟地址与物理内存地址之间的映射关系。当CPU需要访问一个内存地址时，它首先检查页表以找到对应的物理内存地址。</p><p>3.2 <strong>页错误（Page Fault）</strong></p><p><strong>页错误</strong>：如果程序访问的内存地址在当前的页表映射中未找到（即不在内存中），则发生页错误。页错误并非错误，而是一个<strong>提示</strong>操作系统需要从磁盘中加载数据的信号。</p><p><strong>处理页错误</strong>：当页错误发生时，操作系统会暂停当前进程，并将相应的数据页从磁盘加载到内存，然后更新页表以反映新的映射关系。</p><p>3.3 <strong>磁盘I/O操作</strong></p><p><strong>I/O请求</strong>：操作系统向磁盘发出I/O请求以读取特定的数据块。</p><p><strong>数据读取</strong>：磁盘控制器负责将所需的数据从磁盘读取到内存缓冲区中。这一过程涉及磁盘旋转定位（如果是HDD）或闪存寻址（如果是SSD）。</p><p><strong>DMA传输</strong>：直接内存访问（DMA）控制器可能用于加速数据传输过程，将数据从磁盘直接加载到内存，而不经过CPU，释放CPU用于其他任务。</p><p>3.4 <strong>内存更新</strong></p><p><strong>内存填充</strong>：当数据从磁盘读取到内存后，操作系统将其放入指定的内存位置，并更新页表以反映这一变化。</p><p><strong>进程恢复</strong>：在内存更新完成后，操作系统恢复原先的进程，重新执行之前因页错误而暂停的指令。</p><ol start="4"><li><strong>缓存与预读取</strong></li></ol><p><strong>磁盘缓存</strong>：操作系统可能会将从磁盘读取的数据暂时存储在内存中（缓存），以加速后续的访问。若程序在短时间内再次请求同一数据，操作系统可以直接从内存中获取数据，而无需重新访问磁盘。</p><p><strong>预读取（Prefetching）</strong>：操作系统有时会预先从磁盘读取一系列<strong>连续</strong>的数据块到内存中，预计程序可能会需要这些数据，从而减少后续的I/O操作次数。</p><ol start="5"><li><strong>文件系统和块设备管理</strong></li></ol><p><strong>文件系统</strong>：操作系统的文件系统负责将文件映射到磁盘上的物理块地址，决定如何将文件内容组织成块并存储在磁盘上。</p><p><strong>块设备管理</strong>：块设备（如磁盘）的管理程序处理低级别的读写操作，包括将逻辑块地址转换为物理块地址并执行读写。</p><ol start="6"><li><strong>总结</strong></li></ol><p>当CPU需要访问不在内存中的数据时，操作系统会通过页表映射、页错误处理、I/O请求、DMA传输、以及缓存等机制，从磁盘中读取数据并加载到内存。这一过程确保程序在物理内存不足以容纳所有数据时，依然能够顺利执行，从而实现虚拟内存的扩展。</p><p><strong>虚拟内存为每个进程提供了一个私有的地址空间 每个进程拥有一片连续完整的<a href="https://www.zhihu.com/search?q=%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%2282746153%22%7D">内存空间</a> 数据不断换入换出外存实现宏观上的大于实际内存的虚拟内存。</strong></p><ol><li><strong>虚拟地址空间和物理地址空间：</strong> 每个应用程序看到的是一组虚拟地址，而不是真正的物理内存地址。操作系统负责将这些虚拟地址映射到物理内存中的实际位置。</li><li><strong>分页技术：</strong> 操作系统将虚拟内存划分成固定大小的页面（通常是4KB），同时也将物理内存划分成相同大小的页框。虚拟页被映射到物理页框，但不一定要将所有虚拟页都加载到物理内存中。</li><li><strong>页面置换：</strong> 当应用程序需要访问一个虚拟页，但该页不在物理内存中时，会触发页面置换。操作系统会根据一定的算法，将一个当<strong>前不太可能访问</strong>的物理页替换出去，然后将需要的虚拟页加载到这个物理页中。</li><li><strong>页表：</strong> 操作系统维护一个页表，记录虚拟页与物理页的映射关系。当应用程序访问虚拟地址时，操作系统会查询页表，找到对应的物理页。</li><li><strong>页面调度算法：</strong> 操作系统使用不同的算法来决定哪些页应该被替换出物理内存，以便为新的虚拟页腾出空间。一些常见的页面调度算法包括最近最少使用（LRU）、先进先出（FIFO）、最不常用（LFU）等。</li></ol><p>虚拟内存的主要优点包括：</p><ul><li>允许运行比物理内存更大的应用程序。</li><li>提供了更好的内存管理和分配灵活性。</li><li>能够使多个应用程序同时运行，而不会发生内存冲突。</li><li>提供了更好的内存保护，防止一个应用程序影响到其他应用程序的内存空间。</li></ul><p>然而，虚拟内存也有一些缺点，比如访问虚拟内存可能会引入一定的性能开销，因为涉及到物理内存和硬盘之间的数据交换。如果系统中同时运行的应用程序过多，可能会导致频繁的页面置换，从而影响性能。</p><p>总之，虚拟内存是现代操作系统中重要的内存管理技术，它通过将物理内存和硬盘空间结合起来，使得计算机系统能够更有效地管理内存资源，并支持运行多个应用程序。</p><p>一台计算机具有16位地址意味着它可以寻址2^16个不同的地址，因此它的地址总空间为64K（64 kilobytes）</p><p>然而，物理内存只有32KB（32 kilobytes）。这意味着，实际上，计算机在物理内存中只能同时存储32KB的数据。</p><p>虚拟内存技术可以提供一种机制，允许计算机运行比其物理内存更大的程序。这是通过将部分程序数据存储在磁盘上的虚拟内存中实现的。</p><p>以下是一个简单的解释：</p><ol><li><strong>虚拟内存：</strong><ul><li>计算机上运行的程序可能比物理内存大。为了解决这个问题，操作系统使用虚拟内存技术。程序的地址空间可以分为多个部分，其中一部分被加载到物理内存中，而另一部分存储在磁盘上的虚拟内存中。</li><li>当程序访问在虚拟内存中的部分时，操作系统会将相应的数据块加载到物理内存中。这种方式允许运行大于物理内存的程序，但可能会导致性能损失，因为频繁的磁盘I/O会比内存访问慢得多。</li></ul></li><li><strong>页面交换：</strong><ul><li>当程序访问未加载到物理内存中的虚拟内存页面时，发生页面交换。操作系统可能会将一些当前不使用的物理内存页面（通常是最近未使用的页面）写回到磁盘上的虚拟内存，以便腾出空间来加载被请求的虚拟内存页面。</li></ul></li><li><strong>地址翻译：</strong><ul><li>操作系统使用地址翻译机制来将程序中的虚拟地址映射到物理地址。这个映射是由硬件的内存管理单元（MMU）来处理的。MMU负责将虚拟地址转换为物理地址，并确保访问的内存区域是有效的。</li></ul></li></ol><p><strong>分页系统映射</strong></p><p>内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。CPU 上的内存管理单元（Memory Management Unit，MMU）就是专门用来进行<strong>虚拟地址到物理地址的转换的</strong>，不过 MMU 需要借助存放在内存中的页表，而这张表的内容正是由操作系统进行管理的。</p><p>页表是一个十分重要的数据结构！</p><p><strong>操作系统为每个进程建立了一张页表。一个进程对应一张页表，进程的每个页面对应一个页表项，每个页表项由页号和块号（页框号）组成，记录着进程页面和实际存放的内存块之间的映射关系。</strong></p><h3 id="ARM架构">ARM架构</h3><ul><li><strong>模式</strong>：<ul><li><strong>用户模式 (usr)</strong>：这是应用程序运行的模式。</li><li><strong>系统管理模式 (svc - Supervisor Call)</strong>：这是内核模式，系统调用通过SWI (Software Interrupt) 指令进入此模式。</li></ul></li><li><strong>系统调用</strong>：<ul><li>在ARM中，系统调用通常是通过执行 <code>SWI</code> (或新版的 <code>SVC</code>) 指令来实现的。这个指令会触发一个软中断，使得CPU从用户模式切换到监督者模式（内核态），并跳转到预定义的中断向量去处理系统调用。</li></ul></li></ul><h3 id="x86架构">x86架构</h3><ul><li><strong>Ring级别</strong>：<ul><li><strong>Ring 0</strong>：内核态，拥有最高权限，可以执行任何指令。</li><li><strong>Ring 3</strong>：用户态，权限最低，不能执行特权指令。</li></ul></li><li><strong>系统调用</strong>：<ul><li>在x86架构上，传统上是通过 <code>int 0x80</code> 中断实现系统调用的。现代x86 CPU（特别是x86-64）通常使用 <code>syscall</code> 指令，这是为了提高系统调用的效率。</li><li><code>int 0x80</code> 触发一个中断，使得处理器从Ring 3切换到Ring 0，并跳转到中断处理程序，处理系统调用。</li></ul></li></ul><h3 id="Linux的系统调用和中断处理">Linux的系统调用和中断处理</h3><ul><li><strong>系统调用的上下文</strong>：<ul><li>系统调用的执行是在调用进程的上下文中进行的。这意味着内核代码可以访问该进程的地址空间，执行I/O操作，管理文件等。</li></ul></li><li><strong>硬件中断的上下文</strong>：<ul><li>硬件中断处理程序运行在中断上下文中，这个上下文与任何特定进程无关。处理中断的代码必须尽快完成，因为中断处理会阻止其他中断的发生（在同一IRQ线上），或者需要特别处理嵌套中断。</li></ul></li><li><strong>切换过程</strong>：<ul><li><strong>用户态到内核态</strong>：通过系统调用接口（如ARM的 <code>SWI</code> 或 x86的 <code>int 0x80</code> 或 <code>syscall</code>），或者硬件中断。</li><li><strong>内核态到用户态</strong>：通过特定的返回指令（如x86的 <code>iret</code>），恢复用户态的执行上下文。</li></ul></li></ul><h3 id="其他细节">其他细节</h3><ul><li><strong>驱动程序</strong>：<ul><li>驱动程序中的函数一部分作为系统调用的一部分执行，另一部分可能在中断处理程序中执行。驱动程序需要精心设计，以处理好在不同上下文中的操作。</li></ul></li><li><strong>安全性和稳定性</strong>：<ul><li>这种特权级别的分离确保了即使一个用户态的程序崩溃或被恶意攻击，它也不会直接影响到系统的核心功能，保护了操作系统的稳定性和安全性。</li></ul></li></ul><p>通过这种方式，Linux有效地管理了系统资源，提供了安全的环境让应用程序运行，同时保持了对硬件的完全控制。</p><p>dma零拷贝</p><p>什么是 DMA 技术？简单理解就是，<strong>在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务</strong>。</p><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/ea503cf6-9325-47ab-9fb3-3e33e40583ef/886c819c-75b8-4ea9-ac7f-812d4c949002/Untitled.png" alt="Untitled"></p><p>上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。 其次，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：</p><p>第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。</p><p>我们回过头看这个文件传输的过程，我们只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。 这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。</p><p><strong>所以，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。</strong></p><p><strong>零拷贝（<em>Zero-copy</em>）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。</strong>。</p><p>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，<strong>只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</strong></p><p>所以，总体来看，<strong>零拷贝技术可以把文件传输的性能提高至少一倍以上</strong>。<br><strong>写时复制 (Copy-on-Write, COW)</strong> 是一种重要的资源管理技术，用于高效地实现可修改资源的复制操作，尤其是在虚拟内存管理和数据结构中应用广泛。</p><p><strong>COW 的核心思想:</strong></p><ul><li><strong>延迟复制:</strong> COW 不会立即复制整个资源，而是在需要修改资源时才进行复制。</li><li><strong>共享只读数据:</strong> 在修改之前，多个进程或数据结构可以共享同一份只读数据，节省内存空间和复制时间。</li><li><strong>按需复制:</strong> 只有当某个进程或数据结构需要修改数据时，才会复制一份副本进行修改，其他进程或数据结构不受影响。</li></ul><p><strong>COW 在虚拟内存管理中的应用:</strong></p><ul><li><strong>fork() 系统调用:</strong> 在类 Unix 操作系统中，<code>fork()</code> 用于创建一个新进程，该进程是父进程的副本。COW 可以显著提高 <code>fork()</code> 的效率。<ul><li><strong>传统 fork():</strong> 需要复制父进程的整个地址空间，耗时且浪费内存。</li><li><strong>COW fork():</strong> 父进程和子进程 initially 共享相同的物理内存页面，这些页面被标记为只读。只有当某个进程需要修改页面内容时，才会复制一份副本进行修改。</li></ul></li></ul><h1><strong>What is POSIX?</strong></h1><p><strong>POSIX</strong> 是一套由 IEEE 制定的标准，旨在维护操作系统之间的兼容性。它定义了 API、命令行 shell 和实用程序接口，以确保软件与各种 Unix 变体和其他操作系统兼容。</p><h3 id="Key-Components-of-POSIX"><strong>Key Components of POSIX</strong></h3><ol><li><strong>C API Extensions</strong>:<ul><li>POSIX greatly extends the ANSI C standard with a wide array of APIs for file operations, process and thread management, networking, memory management, and more.</li><li><strong>File Operations</strong>: Includes functions like <code>mkdir</code>, <code>symlink</code>, <code>stat</code>, <code>poll</code>, etc.</li><li><strong>Process and Threads</strong>: Functions like <code>fork</code>, <code>execl</code>, <code>wait</code>, <code>pipe</code>, <code>sem_*</code>, <code>shm_*</code>, etc., are essential for process creation, inter-process communication, and synchronization.</li><li><strong>Networking</strong>: The <code>socket()</code> API is crucial for network communication.</li><li><strong>Memory Management</strong>: Functions like <code>mmap</code>, <code>mlock</code>, <code>mprotect</code>, etc., manage memory allocation, protection, and advice.</li></ul></li><li><strong>CLI Utilities</strong>:<ul><li>POSIX defines a set of standard command-line utilities like <code>cd</code>, <code>ls</code>, <code>echo</code>, <code>mkdir</code>, etc. Many of these utilities are direct shell front-ends for corresponding C API functions.</li><li>Major implementations include GNU Coreutils, which provides the majority of these utilities on Linux systems.</li></ul></li><li><strong>Shell Language</strong>:<ul><li>POSIX standardizes the shell scripting language, which includes variable assignments, command execution, and control structures. The most common implementation in Linux is GNU Bash.</li></ul></li><li><strong>Environment Variables</strong>:<ul><li>POSIX specifies standard environment variables like <code>HOME</code>, <code>PATH</code>, which play a crucial role in the shell and other utilities.</li></ul></li><li><strong>Program Exit Status</strong>:<ul><li>POSIX extends the ANSI C standard by defining specific exit codes, such as 126 (command found but not executable), 127 (command not found), and values greater than 128 indicating termination by a signal.</li></ul></li><li><strong>Regular Expressions</strong>:<ul><li>POSIX defines two types of regular expressions: Basic (BRE) and Extended (ERE). These are used in various CLI utilities, such as <code>grep</code>, and are implemented in C libraries under <code>regex.h</code>.</li></ul></li><li><strong>Directory Structure and Filenames</strong>:<ul><li>POSIX specifies aspects of the filesystem, such as the path separator (<code>/</code>), special directories (<code>.</code> for current directory, <code>..</code> for parent directory), and restrictions on filenames.</li></ul></li><li><strong>Command Line Utility API Conventions</strong>:<ul><li>POSIX outlines conventions for command-line utilities, such as using `` for standard input, <code>-</code> to terminate option parsing, and single-letter flags, although these are not strictly enforced by all implementations (e.g., GNU utilities often use long options).</li></ul></li><li><strong>POSIX ACLs (Access Control Lists)</strong>:<ul><li>Although originally part of POSIX, ACLs were withdrawn but have been implemented in several operating systems, including Linux.</li></ul></li></ol><h3 id="POSIX-Compliance-and-Implementations"><strong>POSIX Compliance and Implementations</strong></h3><ol><li><strong>Certified Systems</strong>:<ul><li>Not all systems are officially certified as POSIX-compliant due to the cost of certification, but many closely follow the standards. Examples of certified systems include macOS (formerly OS X), AIX, HP-UX, and Solaris.</li><li>Most Linux distributions are very compliant with POSIX, although not officially certified.</li></ul></li><li><strong>Windows and POSIX</strong>:<ul><li>Windows had limited POSIX support in some professional editions, but this was deprecated in Windows 8. Since 2016, Microsoft introduced the Windows Subsystem for Linux (WSL), which provides a Linux-like environment with system calls, ELF binary execution, and more, bringing Windows closer to POSIX compliance for developer usage.</li></ul></li><li><strong>Cygwin and MSYS2</strong>:<ul><li>These are third-party projects that provide substantial POSIX API functionality on Windows. Cygwin offers a large collection of GNU and Open Source tools that provide functionality similar to a Linux distribution on Windows.</li></ul></li><li><strong>Android</strong>:<ul><li>While Android is based on the Linux kernel, it does not fully comply with POSIX, primarily because it uses its own libraries and runtime environment (Dalvik/ART) rather than standard Linux libraries like glibc.</li></ul></li></ol><p>POSIX 在确保不同类 Unix 系统之间的互操作性和可移植性方面发挥着关键作用。虽然 Linux 和 macOS 等一些系统密切遵循 POSIX，但 Windows 等其他系统历来对 POSIX 的支持有限，尽管 WSL 等最近的发展已经改进了这一点。对于想要编写跨不同操作系统的可移植且可互操作的代码的开发人员来说，了解 POSIX 至关重要</p><h1>Linux</h1><p>Linus Torvalds 创建了前者。后者是全球数百万开发人员之间的协作，涉及<a href="https://www.gnu.org/home.en.html">GNU 项目</a>, <a href="https://www.kernel.org/">Linux 内核开发团队</a><a href="http://www.x.org/wiki/">由 Torvalds 领导， X Window 系统的</a>各种开发人员在过去的 29 年中，以及其他。这就是自由软件基金会要求将使用来自 GNU 项目的软件的完整 Linux 操作系统称为“GNU/Linux”的原因。</p><p>Many <a href="https://en.wikipedia.org/wiki/Open_source">open source</a> developers agree that the Linux kernel was not designed but rather <a href="https://en.wikipedia.org/wiki/Evolution">evolved</a> through <a href="https://en.wikipedia.org/wiki/Natural_selection">natural selection</a>. Torvalds considers that although the design of Unix served as a scaffolding, “Linux grew with a lot of mutations – and because the mutations were less than random, they were faster and more directed than <a href="https://en.wikipedia.org/wiki/Mutation#Induced_mutation">alpha-particles in DNA</a>.”<a href="https://en.wikipedia.org/wiki/Linux#cite_note-77">[73]</a> <a href="https://en.wikipedia.org/wiki/Eric_S._Raymond">Eric S. Raymond</a> considers Linux’s revolutionary aspects to be social, not technical: before Linux, complex software was designed carefully by small groups, but “Linux evolved in a completely different way. From nearly the beginning, it was rather casually hacked on by huge numbers of volunteers coordinating only through the Internet. Quality was maintained not by rigid standards or autocracy but by the naively simple strategy of releasing every week and getting feedback from hundreds of users within days, creating a sort of rapid Darwinian selection on the mutations introduced by developers.”<a href="https://en.wikipedia.org/wiki/Linux#cite_note-78">[74]</a> <a href="https://en.wikipedia.org/wiki/Bryan_Cantrill">Bryan Cantrill</a>, an engineer of a competing OS, agrees that “Linux wasn’t designed, it evolved”, but considers this to be a limitation, proposing that some features, especially those related to security,<a href="https://en.wikipedia.org/wiki/Linux#cite_note-79">[75]</a> cannot be evolved into, “this is not a biological system at the end of the day, it’s a software system.”</p><p><strong>全称GNU/Linux，是一种免费使用和自由传播的<a href="https://baike.baidu.com/item/%E7%B1%BBUNIX/9032872">类UNIX</a>操作系统</strong>，其内核由<a href="https://baike.baidu.com/item/%E6%9E%97%E7%BA%B3%E6%96%AF%C2%B7%E6%9C%AC%E7%BA%B3%E7%AC%AC%E5%85%8B%E7%89%B9%C2%B7%E6%89%98%E7%93%A6%E5%85%B9/1034429">林纳斯·本纳第克特·托瓦兹</a>于1991年10月5日首次发布，它主要受到<a href="https://baike.baidu.com/item/Minix/7106045">Minix</a>和Unix思想的启发，是一个基于<a href="https://baike.baidu.com/item/POSIX/3792413">POSIX</a>的多用户、<a href="https://baike.baidu.com/item/%E5%A4%9A%E4%BB%BB%E5%8A%A1/1011764">多任务</a>、支持<a href="https://baike.baidu.com/item/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1190404">多线程</a>和多<a href="https://baike.baidu.com/item/CPU/120556">CPU</a>的操作系统。它能运行主要的<a href="https://baike.baidu.com/item/Unix/219943">Unix</a>工具软件、应用程序和网络协议。它支持<a href="https://baike.baidu.com/item/32%E4%BD%8D/5812218">32位</a>和<a href="https://baike.baidu.com/item/64%E4%BD%8D/2262282">64位</a>硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。Linux有上百种不同的发行版，如基于社区开发的<a href="https://baike.baidu.com/item/debian/748667">debian</a>、<a href="https://baike.baidu.com/item/archlinux/10857530">archlinux</a>，和基于商业开发的<a href="https://baike.baidu.com/item/Red%20Hat%20Enterprise%20Linux/10770503">Red Hat Enterprise Linux</a>、<a href="https://baike.baidu.com/item/SUSE/60409">SUSE</a>、<a href="https://baike.baidu.com/item/Oracle%20Linux/6876458">Oracle Linux</a>等。</p><p>Linus built kernel to solve unix hard-use and lack I/O RPC function.  区分 Linux（内核）和 Linux（操作系统）。</p><p>Kernel 是计算机<a href="https://en.wikipedia.org/wiki/Operating_system">操作系统</a>核心的<a href="https://en.wikipedia.org/wiki/Computer_program">计算机程序</a>，通常可以完全控制系统中的所有内容**。**<a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)#cite_note-Linfo-1">[1]</a>它是操作系统代码的一部分，始终驻留在内存中<a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)#cite_note-2">[2]</a>并促进硬件和软件组件之间的交互。完整的内核通过<a href="https://en.wikipedia.org/wiki/Device_driver">设备驱动程序控制</a>所有硬件资源（例如 I/O、内存、密码） ，仲裁涉及这些资源的进程之间的冲突，并优化公共资源的利用，例如 CPU 和缓存使用、文件系统和网络套接字。<a href="https://en.wikipedia.org/wiki/Booting">在大多数系统上，内核是启动</a>时最先加载的程序之一（在<a href="https://en.wikipedia.org/wiki/Bootloader">引导加载程序</a>）。它处理其余的启动以及内存、<a href="https://en.wikipedia.org/wiki/Peripheral">外围设备</a>和来自<a href="https://en.wikipedia.org/wiki/Software">软件的</a><a href="https://en.wikipedia.org/wiki/Input/output">输入/输出</a>(I/O) 请求，将它们转换为<a href="https://en.wikipedia.org/wiki/Central_processing_unit">中央处理器的</a><a href="https://en.wikipedia.org/wiki/Data_processing">数据处理</a>指令。</p><p>内核是操作系统的核心部分，具有完全控制系统资源的能力。它始终驻留在内存中，促进硬件和软件之间的交互。内核通过设备驱动程序控制硬件资源，仲裁进程之间的冲突，并优化共享资源的利用。在大多数系统上，内核是启动时最先加载的程序。<br>内核的关键代码被加载到受保护的内核空间中，与应用程序运行的用户空间分离。这种分离可以防止用户数据和内核数据相互干扰，并提高系统的稳定性和安全性。内核提供了一个低级的接口，进程通过系统调用来请求内核服务。<br>内核架构有<strong>整体内核和微内核</strong>两种设计。整体内核在单个地址空间中运行，以提高速度；微内核在用户空间中运行大部分服务，以提高灵活性和模块化。Linux内核是整体式的，但也支持模块化，可以在运行时加载和卸载内核模块。<br>内核负责决定将哪些正在运行的程序分配给处理器，从而执行程序。它是计算机系统的中央组件，控制和管理系统的各个方面。</p><p>Linux 操作系统将其运行环境分为两种状态：用户态和内核态。用户态是指应用程序运行的环境，而内核态是指操作系统内核运行的环境。</p><h3 id="用户态">用户态</h3><p>用户态（User Mode）是指应用程序运行的环境。在用户态下，应用程序可以使用用户态提供的系统调用接口来请求操作系统服务。用户态的应用程序不能直接访问硬件资源，必须通过系统调用来请求内核态的服务。</p><p>用户态的特点：</p><ul><li>应用程序运行在用户态下</li><li>不允许直接访问硬件资源</li><li>必须通过系统调用来请求内核态服务</li></ul><h3 id="内核态">内核态</h3><p>内核态（Kernel Mode）是指操作系统内核运行的环境。在内核态下，内核可以直接访问硬件资源，管理系统资源，并提供服务给用户态的应用程序。</p><p>内核态的特点：</p><ul><li>操作系统内核运行在内核态下</li><li>允许直接访问硬件资源</li><li>管理系统资源并提供服务给用户态应用程序</li></ul><h3 id="系统调用">系统调用</h3><p>系统调用（System Call）是用户态应用程序请求内核态服务的接口。用户态应用程序通过系统调用来请求内核态的服务，例如读取文件、创建进程等。</p><p>系统调用的过程：</p><ol><li>应用程序在用户态下执行</li><li>应用程序需要请求内核态服务</li><li>应用程序通过系统调用接口请求服务</li><li>内核态接收到请求并处理</li><li>内核态将结果返回给应用程序</li></ol><p><strong>实践</strong></p><p>$表明是非root用户登录，#表示是root用户登录，它们是终端shell的命令提示符 几种常用终端的命令提示符</p><p>BASH: root账户: # ,非root账户: <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="39.819ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 17600 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="merror" data-mjx-error="You can't use 'macro parameter character #' in math mode" title="You can't use 'macro parameter character #' in math mode"><rect data-background="true" width="17600" height="950" y="-200"></rect><title>You can't use 'macro parameter character #' in math mode</title><g data-mml-node="mtext" style="font-family: serif;"><text data-variant="-explicitFont" transform="scale(1,-1)" font-size="884px"> KSH: root账户: # ,非root账户: </text></g></g></g></g></svg></mjx-container> CSH[TCSH]: root账户: % ,非root账户: %</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">而/ 是根节点， ~ 是 home</span><br><span class="line">如果以root账号登陆   ~ 是 /root/</span><br></pre></td></tr></table></figure><p>Program: a file containing instructions to be executed, static Process: an instance of a program in execution, live entity</p><p>execve（执行文件）在<a href="https://baike.baidu.com/item/%E7%88%B6%E8%BF%9B%E7%A8%8B/614062">父进程</a>中fork一个子进程，在子进程中调用exec函数启动新的程序。exec函数一共有六个，其中execve为内核级<a href="https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/861110">系统调用</a>，其他（execl，execle，execlp，execv，execvp）exec(): often used after fork() to <strong>load</strong> another process</p><p>许多程序需要开机启动。它们在Windows叫做"服务"（service），在Linux就叫做"<a href="https://zh.wikipedia.org/wiki/%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B">守护进程</a>"（daemon）。Linux Daemon（守护进程）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。</p><ol><li><strong>syslogd</strong>：系统日志守护进程，负责记录系统日志消息。</li><li><strong>httpd</strong>：Web 服务器守护进程，如 Apache 或 Nginx，用于提供 Web 服务。</li><li><strong>sendmail</strong>：邮件服务器守护进程，负责处理发送和接收邮件的功能。</li><li><strong>mysqld</strong>：数据库服务器守护进程，比如 MySQL 或 MariaDB，用于管理和提供数据库服务。</li></ol><p>这些守护进程通常在系统启动时自动启动，并在系统运行期间持续<strong>监听、处理或提供服务</strong>。它们的运行通常不需要用户的直接干预，而是通过配置文件或其他设置来控制其行为和功能。</p><p><strong>FTP</strong></p><p><strong>主动</strong>模式的FTP是指<strong>服务器主动</strong>连接客户端的数据端口，被动模式的FTP是指<strong>服务器被动等待</strong>客户端连接自己的数据端口。</p><p>被动模式的FTP通常用在处于防火墙之后的FTP客户访问外界FTP服务器的情况，因为在这种情况下，防火墙通常配置为<strong>不允许外界访问防火墙之内的主机</strong>，而<strong>只允许由防火墙之内的主机发起对外的连接请求</strong>。因此，在这种情况下不能使用主动模式的FTP传输，而被动模式的FTP可以良好的工作。</p><p>主动模式需要服务器主动向客户端发起连接，而现在普通的客户端大多位于NAT之后，所以主动模式常常无法进行。即使可以，也需要客户端打开防火墙，允许服务端的20端口访问。所以服务端基本需要支持被动模式，但被动模式需要开放一段端口。为了安全，可以选择一小段端口，然后在防火墙开放这一段端口。</p><h3 id="Everything-is-a-file">Everything is a file</h3><p><strong>Linux操作系统的设计哲学之一：将所有设备、资源或进程都视为文件或文件类似的对象。</strong></p><p>在Linux中，不仅普通的文本文件、目录、硬件设备和外部设备都被视为文件，甚至系统中的进程、网络连接、硬件接口等也被抽象为文件。这种抽象化使得Linux系统更加统一和灵活，因为它允许对不同资源使用相似的操作方式。</p><p>好处是读写这些资源都可用open()/close()/write()/read()等函数进行处理。屏蔽了硬件的区别，所有设备都抽象成文件，提供统一的接口给用户。虽然类型各不相同，但是对其提供的却是同一套API。更进一步，对文件的操作也可以跨文件系统执行。在Linux系统中有三类文件：普通文件、目录文件和特殊文件。</p><p>网络 I/O 通过网络进行数据传输，通常包括 TCP 或 UDP 等协议。网络 I/O 的延迟较高，取决于网络带宽、路由器、中继设备等，数据包可能需要经过多个中间节点才能到达目标服务器。</p><p>局域网的延迟通常在微秒到毫秒级，而广域网（如互联网）的延迟可能会达到几十毫秒甚至更高。网络 I/O 并发是非常常见的需求，特别是在高并发服务器（如 Web 服务器）中。服务器通常需要同时处理数百甚至数千个网络连接。为了提高性能，使用了 I/O 多路复用（select、poll、epoll）和异步 I/O 来管理大量的并发连接。网络 I/O 带宽受到网络设备（如网卡、路由器）的限制。千兆以太网的带宽是 1 Gbps，大约相当于 125 MB/s，而如今常见的 10 Gbps 网卡能达到 1.25 GB/s，远低于本地存储设备。</p><p>现代服务器（如 Nginx、Node.js）通常使用异步非阻塞 I/O 模型，以最大限度提高 I/O 吞吐量。</p><h2 id="多路复用I-O">多路复用I/O</h2><p>select()、poll() 和 epoll() 函数在网络编程和操作系统中用于同时监控多个文件描述符（例如，套接字）的<strong>可读性、可写性或异常状态</strong>。它们的核心思想是通过监听<strong>一组</strong>文件描述符，来处理多个输入/输出操作，<strong>而不需要每个连接都使用一个独立的线程或进程</strong>。它们主要用于事件驱动编程，特别是在服务器中同时处理多个连接时。</p><h3 id="1-select">1. <code>select()</code></h3><p><code>select()</code> 是一个 POSIX 标准函数，用于监控多个文件描述符，等待其中的某个变为就绪（可读、可写或有异常）。主要应用于网络编程中处理多客户端的并发连接。</p><h3 id="用法">用法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/select.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">select</span><span class="params">(<span class="type">int</span> nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, <span class="keyword">struct</span> timeval *timeout)</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><strong><code>nfds</code></strong>: 是需要监控的最大文件描述符加1。</li><li><strong><code>readfds</code></strong>: 监控可读事件的文件描述符集合。</li><li><strong><code>writefds</code></strong>: 监控可写事件的文件描述符集合。</li><li><strong><code>exceptfds</code></strong>: 监控异常事件的文件描述符集合。</li><li><strong><code>timeout</code></strong>: 超时参数，指定 <code>select()</code> 应等待的时间。</li></ul><h3 id="使用步骤">使用步骤</h3><ol><li>创建一个 <code>fd_set</code> 集合，并通过 <code>FD_SET()</code> 向其中添加文件描述符。</li><li>调用 <code>select()</code>，等待文件描述符就绪。</li><li>检查返回的集合，处理就绪的文件描述符。</li></ol><h3 id="例子">例子</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">fd_set readfds;</span><br><span class="line">FD_ZERO(&amp;readfds);       <span class="comment">// 初始化集合</span></span><br><span class="line">FD_SET(sockfd, &amp;readfds); <span class="comment">// 添加一个socket到集合中</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> result = select(sockfd + <span class="number">1</span>, &amp;readfds, <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line"><span class="keyword">if</span> (result &gt; <span class="number">0</span>) {</span><br><span class="line">    <span class="keyword">if</span> (FD_ISSET(sockfd, &amp;readfds)) {</span><br><span class="line">        <span class="comment">// sockfd 可读，处理数据</span></span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="使用场景">使用场景</h3><ul><li><strong>多客户端 TCP 服务器</strong>：在一个进程或线程中，<code>select()</code> 可以同时处理多个客户端的 I/O 请求，而不需要为每个连接创建一个线程。</li><li><strong>事件驱动系统</strong>：通过 <code>select()</code> 来处理多个 I/O 事件或定时事件。</li></ul><h3 id="2-poll">2. <code>poll()</code></h3><p><code>poll()</code> 是 <code>select()</code> 的增强版本，解决了 <code>select()</code> 一些性能上的瓶颈（如文件描述符限制）。它更灵活，适合处理大量文件描述符。</p><h3 id="用法-2">用法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;poll.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">poll</span><span class="params">(<span class="keyword">struct</span> pollfd *fds, <span class="type">nfds_t</span> nfds, <span class="type">int</span> timeout)</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><strong><code>fds</code></strong>: 一个结构体数组，每个结构体表示一个文件描述符及其事件。</li><li><strong><code>nfds</code></strong>: 要监控的文件描述符数量。</li><li><strong><code>timeout</code></strong>: 超时参数，指定等待的时间。</li></ul><h3 id="使用步骤-2">使用步骤</h3><ol><li>创建一个 <code>pollfd</code> 数组，为每个文件描述符设置感兴趣的事件。</li><li>调用 <code>poll()</code>，等待文件描述符就绪。</li><li>检查返回的结构体数组，处理就绪的文件描述符。</li></ol><h3 id="例子-2">例子</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">pollfd</span> <span class="title">fds</span>[1];</span></span><br><span class="line">fds[<span class="number">0</span>].fd = sockfd;</span><br><span class="line">fds[<span class="number">0</span>].events = POLLIN;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> result = poll(fds, <span class="number">1</span>, <span class="number">-1</span>); <span class="comment">// -1表示无限等待</span></span><br><span class="line"><span class="keyword">if</span> (result &gt; <span class="number">0</span>) {</span><br><span class="line">    <span class="keyword">if</span> (fds[<span class="number">0</span>].revents &amp; POLLIN) {</span><br><span class="line">        <span class="comment">// sockfd 可读，处理数据</span></span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="使用场景-2">使用场景</h3><ul><li><strong>高并发系统</strong>：<code>poll()</code> 适用于处理大量并发连接，如高性能 HTTP 服务器。</li><li><strong>文件描述符大于 <code>select()</code> 限制</strong>：<code>poll()</code> 没有 <code>select()</code> 的最大文件描述符限制，更适合需要监控大量文件描述符的场景。</li></ul><h3 id="3-select-vs-poll">3. <code>select()</code> vs <code>poll()</code></h3><ul><li><strong>性能</strong>: <code>poll()</code> 通常比 <code>select()</code> 更快，尤其是在需要监控大量文件描述符时，因为 <code>select()</code> 的文件描述符集合在每次调用时都需要重新填充，而 <code>poll()</code> 使用的 <code>pollfd</code> 数组更高效。</li><li><strong>灵活性</strong>: <code>poll()</code> 更灵活，支持更多的事件类型，且不受 <code>select()</code> 最大文件描述符数量的限制。</li><li><strong>兼容性</strong>: <code>select()</code> 是较旧的函数，几乎在所有平台上都支持，而 <code>poll()</code> 是较新的替代方案，适合更现代的系统。</li></ul><h3 id="4-现代替代方案">4. 现代替代方案</h3><ul><li><strong><code>epoll()</code></strong>（Linux）：比 <code>poll()</code> 更加高效，特别是在大量文件描述符同时就绪的场景下。适合高并发场景，如大型网络服务器。</li><li><strong><code>kqueue()</code></strong>（BSD 系统）：FreeBSD、OpenBSD 和 macOS 等系统中的多路复用函数，类似 <code>epoll()</code>。</li></ul><h3 id="总结">总结</h3><ul><li><strong><code>select()</code></strong>: 简单但有文件描述符数量限制，适用于小型并发场景。</li><li><strong><code>poll()</code></strong>: 更灵活、适合大量并发连接，解决了 <code>select()</code> 的一些局限性。</li></ul><p>在现代高并发系统中，通常会更倾向于使用 <code>epoll()</code> 或者 <code>kqueue()</code>，而 <code>select()</code> 和 <code>poll()</code> 更多用于相对简单或跨平台的场景。</p><h3 id="epoll-Linux-specific"><strong><code>epoll()</code> (Linux-specific)</strong></h3><ul><li><p><strong>Usage</strong>: A more scalable and efficient mechanism designed specifically for high-performance applications (e.g., handling thousands of file descriptors).</p></li><li><p><strong>Benefits</strong>:</p><ul><li>More efficient than <code>poll()</code> and <code>select()</code> because it uses an event-based model.</li><li>The kernel only returns file descriptors that are ready, rather than polling each one.</li><li>Allows edge-triggered and level-triggered modes, offering flexibility.</li></ul></li><li><p><strong>Drawbacks</strong>:</p><ul><li>Only available on Linux, so it’s not portable to other operating systems like macOS or Windows.</li></ul><p><strong>epoll为什么更高效?</strong></p><ul><li><strong>高效的事件通知机制</strong></li><li>epoll它的工作原理是只向内核注册一次文件描述符（使用epoll_ctl()）。此后，内核会跟踪哪些文件描述符已就绪。当您调用时epoll_wait()，它仅返回具有事件（即数据就绪）的文件描述符，而不会扫描所有文件描述符。这使得它更加高效，尤其是在监视大量描述符时，因为它消除了重复扫描的需要。<br>它不再在每次调用时检查所有文件描述符，epoll而是更像一个“事件驱动”系统：当注册描述符的状态发生变化时，内核会通知您。</li><li><code>epoll()</code> offers two modes: <strong>edge-triggered (ET)</strong> and <strong>level-triggered (LT)</strong>.<ul><li><strong>Edge-triggered</strong>: The application is notified <strong>only once</strong> when the state of a file descriptor changes (e.g., when data becomes available). The application is then responsible for reading/writing all available data. This minimizes system calls, as the application doesn’t need to continuously poll the kernel.</li><li><strong>Level-triggered</strong>: The behavior is more like <code>poll()</code> or <code>select()</code>; it keeps notifying the application as long as the file descriptor remains ready. This provides flexibility, but edge-triggered mode can significantly reduce overhead in high-performance applications.</li></ul></li></ul><h3 id="3-O-1-Performance-with-Large-Numbers-of-Descriptors">3. <strong>O(1) Performance with Large Numbers of Descriptors</strong></h3><ul><li><strong><code>select()</code> and <code>poll()</code></strong>:<ul><li>Both have <strong>O(n)</strong> complexity, where <code>n</code> is the number of file descriptors being monitored. As the number of descriptors grows, the time taken to check them grows linearly.</li></ul></li><li><strong><code>epoll()</code></strong>:<ul><li><code>epoll_wait()</code> has <strong>O(1)</strong> complexity for most operations, meaning it doesn’t degrade in performance as the number of file descriptors increases. This allows it to scale much better when handling thousands (or even tens of thousands) of connections.</li></ul></li></ul><h3 id="4-Kernel-Space-Data-Structures">4. <strong>Kernel-Space Data Structures</strong></h3><ul><li><code>epoll()</code> uses more advanced kernel-space data structures (like red-black trees and linked lists) to efficiently track the file descriptors. Once a file descriptor is registered, it is stored in a tree, allowing quick lookups and updates, further improving performance.</li><li>In contrast, <code>select()</code> and <code>poll()</code> need to copy all file descriptors from user space to kernel space on every call, and the kernel has to check each one, leading to more overhead.</li></ul><p>此外还使用了内存映射（ <code>mmap</code> ）技术</p><p>另一个本质的改进在于 <code>epoll</code> 采用基于事件的就绪通知方式。在 <code>select/poll</code> 中，进程只有在调用一定的方法后，内核才对所有监视的socket描述符进行扫描，而 <code>epoll</code> 事先通过 <code>epoll_ctl()</code> 来注册一个socket描述符，一旦检测到epoll管理的socket描述符就绪时，内核会采用类似 <code>callback</code> 的回调机制，迅速激活这个socket描述符，当进程调用 <code>epoll_wait()</code> 时便可以得到通知，也就是说epoll最大的优点就在于它 <strong>只管就绪的socket描述符，而跟socket描述符的总数无关</strong> 。</p></li></ul><ol><li><p>提出一个问题：当在O_APPEND打开后，然后用 lseek移动到其他的位置，然后再用write写，这个时候，请问你数据写到哪里去了？</p></li><li><p>系统调用：</p><p>主要使用 open() 系统调用来打开文件。</p><p>函数原型：int open(const char *pathname, int flags, mode_t mode);</p></li><li><p>常用标志（flags）：</p><ul><li>O_RDONLY：只读模式</li><li>O_WRONLY：只写模式</li><li>O_RDWR：读写模式</li><li>O_CREAT：如果文件不存在则创建</li><li>O_APPEND：追加模式</li><li>O_TRUNC：如果文件存在则清空</li><li>O_NONBLOCK：非阻塞模式</li></ul></li><li><p>权限模式（mode）：</p><p>当创建新文件时使用，如 0644（所有者可读写，其他人可读）</p></li><li><p>返回值：</p><p>成功返回文件描述符（非负整数），失败返回-1</p></li><li><p>文件描述符：</p><ul><li>是一个小的非负整数</li><li>用作I/O操作的句柄</li><li>0, 1, 2 分别预留给标准输入、输出和错误</li></ul></li><li><p>打开文件的限制：</p><ul><li>每个进程有打开文件的最大数量限制</li><li>系统全局也有打开文件的最大数量限制</li></ul></li><li><p>关闭文件：</p><p>使用 close() 系统调用关闭文件描述符</p></li><li><p><strong>错误处理</strong></p><p>使用 errno 来检查具体的错误原因,     在 Linux 中打开和处理文件时，可能会遇到各种问题或错误，这些问题通常与文件系统状态、权限、系统资源限制有关：</p><ol><li>文件描述符耗尽：<ul><li>原因：打开太多文件而不关闭</li><li>症状：open() 调用失败，返回 EMFILE 错误</li><li>解决：及时关闭不用的文件，使用 select()/poll()/epoll() 管理多个文件描述符</li></ul></li><li>权限问题：<ul><li>原因：没有足够的权限访问文件</li><li>症状：open() 返回 EACCES 错误</li><li>解决：检查文件权限和进程权限，必要时调整</li></ul></li><li>文件不存在：<ul><li>原因：尝试打开不存在的文件（未使用 O_CREAT 标志）</li><li>症状：open() 返回 ENOENT 错误</li><li>解决：确保文件存在或使用适当的标志创建</li></ul></li><li>磁盘空间不足：<ul><li>原因：写入数据时磁盘已满</li><li>症状：write() 调用失败，返回 ENOSPC 错误</li><li>解决：清理磁盘空间或使用更大的存储设备</li></ul></li><li>文件锁冲突：<ul><li>原因：多个进程同时访问同一文件</li><li>症状：fcntl() 锁定操作失败</li><li>解决：实现适当的锁定机制和错误处理</li></ul></li><li>符号链接循环：<ul><li>原因：符号链接形成循环</li><li>症状：open() 返回 ELOOP 错误</li><li>解决：检查和修复符号链接结构</li></ul></li><li>文件系统只读：<ul><li>原因：尝试写入只读文件系统</li><li>症状：open() 或 write() 返回 EROFS 错误</li><li>解决：确保文件系统可写或更改操作逻辑</li></ul></li></ol></li></ol><p>在 Linux 和类 Unix 系统中，当一个文件以 <code>O_APPEND</code> 模式打开时，每次进行 <code>write</code> 操作时，文件的偏移量都会自动设置到文件的末尾，即使在此之前使用 <code>lseek</code> 改变了文件位置。因此，<code>O_APPEND</code> 标志会导致所有写操作都追加到文件的末尾。</p><p>因为 O_APPEND打开后，是一个<a href="https://so.csdn.net/so/search?q=%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C&amp;spm=1001.2101.3001.7020">原子操作</a>：移动到末端，写数据。这是O_APPEND打开的作用。中间的插入时无效的</p><p>2.<strong>Linux 里利用 grep 和 find 命令查找文件内容</strong></p><p><strong>从文件内容查找匹配指定字符串的行：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grep "被查找的字符串" 文件名</span><br></pre></td></tr></table></figure><p>例子：在当前目录里第一级文件夹中寻找包含指定字符串的 .in 文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep "thermcontact" /.in</span><br></pre></td></tr></table></figure><p>从文件内容查找与正则表达式匹配的行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grep –e "正则表达式" 文件名</span><br></pre></td></tr></table></figure><p>查找时不区分大小写：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grep –i "被查找的字符串" 文件名</span><br></pre></td></tr></table></figure><h3 id="fork">fork()</h3><p><code>fork()</code> 系统调用，父进程调用fork会创建一个进程副本，代码中还可以通过fork返回值是否为0来区分是子进程还是父进程。<em><strong>子进程与</strong></em>进行 fork() 调用的进程（父进程）同时运行。创建新的子进程后，两个进程都将执行 fork() 系统调用之后的下一条指令。</p><p><strong>子进程使用与父进程相同的 pc（程序计数器）、相同的 CPU 寄存器、相同的打开文件。</strong></p><p><strong>不同线程,父子拥有独立的内存空间</strong></p><p>fork是用来创建子进程的，这个函数的特别之处在于一次调用，两次返回，一次返回到父进程中，一次返回到子进程中，我们可以通过返回值来判断其返回点：   它不接受任何参数并返回一个整数值。下面是 fork() 返回的不同值。</p><p>1. <strong><code>fork()</code> 的工作原理</strong></p><p>当一个进程调用 <code>fork()</code> 时，操作系统会执行以下操作：</p><p><strong>创建子进程</strong>：操作系统为子进程分配一个新的进程控制块（PCB），这是操作系统用于管理进程的结构。</p><p><strong>复制父进程的资源</strong>：</p><ul><li>子进程会获得父进程的几乎完全相同的<strong>资源副本，包括进程的代码段、数据段、堆、栈、文件描述符等。</strong></li><li>但这只是“写时复制”（Copy-On-Write，COW）的副本，父子进程最初共享相同的内存区域，直到其中一个进程试图修改数据时才会实际进行内存的复制。</li></ul><p><strong>返回值</strong>：</p><ul><li>在父进程中，<code>fork()</code> 返回子进程的进程ID（PID）。</li><li>在子进程中，<code>fork()</code> 返回 0。</li><li>如果 <code>fork()</code> 调用失败（例如系统资源不足），则会返回 -1，并设置 <code>errno</code> 以指示错误原因。</li></ul><p>2. <strong><code>fork()</code> 的使用</strong></p><p>以下是一个简单的示例代码，展示了如何使用 <code>fork()</code> 创建一个子进程：</p><p>`#include &lt;stdio.h&gt;<br>#include &lt;unistd.h&gt;</p><p>int main() {<br>pid_t pid = fork();  // 创建子进程</p><pre><code>if (pid &lt; 0) {  // fork() 调用失败    perror("fork failed");    return 1;} else if (pid == 0) {  // 子进程    printf("This is the child process. PID: %d\n", getpid());} else {  // 父进程    printf("This is the parent process. Child PID: %d, Parent PID: %d\n", pid, getpid());}return 0;</code></pre><p>}`<em><strong>负值</strong></em>：创建子进程不成功。<em><strong>零</strong></em>：返回新创建的子进程。<em><strong>正值</strong></em>：返回给父级或调用者。该值包含新创建的子进程的进程 ID。</p><p>3. <strong><code>fork()</code> 的典型行为</strong></p><p><strong>父子进程的执行顺序</strong>：</p><ul><li><code>fork()</code> 之后，父进程和子进程会继续执行 <code>fork()</code> 后的代码，但它们的执行顺序是不确定的。父进程可能先执行，也可能子进程先执行。</li></ul><p><strong>变量的独立性</strong>：</p><ul><li>尽管子进程复制了父进程的内存空间，但它们的变量是独立的。如果子进程修改了某个变量的值，父进程不会看到这个修改，反之亦然。</li></ul><p><strong>文件描述符的共享</strong>：</p><ul><li>子进程复制了父进程的文件描述符表，这意味着父子进程可以访问相同的文件。然而，它们的文件偏移量是共享的；如果一个进程改变了文件的偏移量，另一个进程会受影响。</li></ul><p>4. <strong><code>fork()</code> 的典型应用</strong></p><p><strong>创建守护进程</strong>：<code>fork()</code> 常用于创建守护进程（daemon）。守护进程通常在后台运行，不与终端关联。</p><p><strong>多进程服务器</strong>：在一个多进程服务器中，服务器进程会 <code>fork()</code> 一个子进程来处理每个客户端请求，从而实现并行处理。</p><p><strong>进程隔离</strong>：<code>fork()</code> 可以用于创建一个子进程来执行不同的任务，从而实现进程隔离。</p><p>5. <strong><code>fork()</code> 相关的其他系统调用</strong></p><p><strong><code>exec()</code> 系列</strong>：<code>fork()</code> 通常与 <code>exec()</code> 系列函数（如 <code>execl()</code>、<code>execvp()</code>）一起使用。<code>fork()</code> 创建子进程后，子进程可以调用 <code>exec()</code> 来加载一个新的程序。</p><p><strong><code>wait()</code> 和 <code>waitpid()</code></strong>：父进程通常通过 <code>wait()</code> 或 <code>waitpid()</code> 等系统调用等待子进程完成。这些调用会阻塞父进程，直到子进程终止，并返回子进程的退出状态。</p><p>6. <strong>常见的 <code>fork()</code> 问题</strong></p><p><strong>僵尸进程</strong>：当一个子进程结束而父进程尚未调用 <code>wait()</code> 或 <code>waitpid()</code> 来读取其退出状态时，子进程会成为僵尸进程，占用系统资源。可以通过父进程调用 `wait</p><p><strong>现代替代方案</strong></p><ul><li><strong><code>pthread</code> 库</strong>：与 <code>fork</code> 不同，<code>pthread</code> 提供了真正的多线程支持，允许多个线程共享同一个进程的地址空间，这在需要高效并发的场景中更加实用。</li><li><strong><code>CreateProcess</code></strong>：在 Windows 上，<code>CreateProcess</code> 是一个更为灵活的进程创建机制，它提供了比 <code>fork</code> 更为丰富的选项和功能。</li></ul><p>fork只能创建调用该函数的线程的副本，进程中其他运行的线程，fork不予处理。这就意味着，对于多线程程序而言，寄希望于通过fork来<strong>创建一个完整进程副本是不可行的。</strong></p><ul><li><strong>不一致性</strong>：如果在<strong>多线程环境</strong>中使用 <code>fork()</code>，子进程可能会进入一个不一致的状态，因为它只继承了一个线程的状态，而其他线程的状态未被复制。比如，父进程中的某个锁可能正在被另一个线程持有，而子进程中没有这个线程，这可能导致死锁或其他同步问题。</li><li><strong>资源竞争</strong>：多线程程序中，多个线程可能会竞争同一资源（如文件描述符、网络连接等）。当 <code>fork()</code> 只复制一个线程时，子进程中的资源状态可能与父进程不一致，导致资源竞争问题。</li></ul><p>Best practice</p><ul><li><strong><code>fork()</code> 后立即调用 <code>exec()</code></strong>：在多线程程序中，如果必须使用 <code>fork()</code>，通常的做法是在 <code>fork()</code> 之后立即调用 <code>exec()</code> 系列函数来启动一个新的程序。这将完全替换子进程的地址空间，避免了与父进程共享资源或状态的不一致性问题。</li><li><strong>使用 <code>pthread_atfork()</code></strong>：POSIX 提供了 <code>pthread_atfork()</code> 函数，用于在 <code>fork()</code> 调用前后执行特定的准备和恢复操作。通过 <code>pthread_atfork()</code>，可以在 <code>fork()</code> 之前锁定所有全局资源，在子进程中释放这些锁，从而避免潜在的竞争条件。</li></ul><h3 id="Libs">Libs</h3><ol><li>系统管理<ul><li>systemd: 系统和服务管理器</li><li>cron: 定时任务管理</li><li>top/htop: 系统资源监控</li><li>ps: 进程状态查看</li><li>journalctl: 日志查看</li><li>dmesg: 内核日志查看</li></ul></li><li>文件管理<ul><li>ls, cp, mv, rm: 基本文件操作</li><li>find: 文件搜索</li><li>grep: 文本搜索</li><li>tar, gzip, bzip2: 文件压缩和归档</li><li>chmod, chown: 文件权限管理</li></ul></li><li>文本处理<ul><li>vim, nano: 文本编辑器</li><li>sed, awk: 文本处理工具</li><li>cat, less, more: 文件查看</li></ul></li><li>网络工具<ul><li>ifconfig/ip: 网络接口配置</li><li>ping, traceroute: 网络诊断</li><li>ssh: 远程登录</li><li>curl, wget: 文件下载</li><li>netstat, ss: 网络连接状态</li><li>iptables/nftables: 防火墙管理</li></ul></li></ol><p>Systemd 是许多现代 Linux 发行版中使用的初始化系统和系统管理器。以下是关于 systemd 的一些重要概念和常用命令：</p><ol><li>核心概念：<ul><li>Unit：systemd 管理的基本对象，包括服务、挂载点、设备和网络配置等</li><li>Service：最常见的 unit 类型，用于管理守护进程</li><li>Target：一组 unit 的集合，类似于运行级别</li></ul></li></ol><p>Unit 文件结构</p><p>一个典型的 <code>.service</code> 单元文件结构如下：</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">`[Unit]</span></span><br><span class="line"><span class="string">Description=My Custom Service</span></span><br><span class="line"><span class="string">After=network.target</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">ExecStart=/usr/bin/my-service</span></span><br><span class="line"><span class="string">ExecReload=/bin/kill -HUP $MAINPID</span></span><br><span class="line"><span class="string">ExecStop=/bin/kill $MAINPID</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target`</span></span><br><span class="line"></span><br><span class="line"><span class="string">`[Unit]`</span>：描述单元和其依赖关系。</span><br><span class="line"></span><br><span class="line"><span class="string">`[Service]`</span>：定义服务如何启动、停止，以及重启策略。</span><br><span class="line"></span><br><span class="line"><span class="string">`[Install]`</span>：定义单元如何被启用或关联到其他目标。</span><br></pre></td></tr></table></figure><p>注意事项</p><p><strong>权限</strong>：许多 <code>systemctl</code> 命令需要以 <code>root</code> 权限运行。</p><p><strong>配置修改后重载</strong>：修改 <code>.service</code> 文件后，需要运行 <code>systemctl daemon-reload</code> 来重新加载配置。</p><p><strong>安全性</strong>：<code>systemd</code> 提供了许多安全选项，可以限制服务的权限和资源使用。</p><p>Endian refers to the order in which bytes are arranged in memory, particularly in multi-byte data types like integers or floating-point numbers. There are two main types of endianess: Big-endian and Little-endian.</p><ol><li><strong>Big-endian:</strong> In this format, the most significant byte (the one with the highest address) is stored first. That means the leftmost byte is stored at the lowest memory address. It’s like reading a number from left to right.</li><li><strong>Little-endian:</strong> Conversely, in little-endian format, the least significant byte (the one with the lowest address) is stored first. The rightmost byte is stored at the lowest memory address. It’s like reading a number from right to left.</li></ol><p>For example, let’s take a 32-bit integer <strong><code>0x12345678</code></strong>:</p><ul><li>In Big-endian:<ul><li>Memory: <strong><code>12 34 56 78</code></strong></li><li>Addresses: <strong><code>0x00 0x01 0x02 0x03</code></strong></li></ul></li><li>In Little-endian:<ul><li>Memory: <strong><code>78 56 34 12</code></strong></li><li>Addresses: <strong><code>0x00 0x01 0x02 0x03</code></strong></li></ul></li></ul><p>The choice between big-endian and little-endian is important in systems where data needs to be communicated between different architectures, as interpreting multi-byte data requires knowing the byte order. Some architectures use big-endian (e.g., PowerPC, SPARC), while others use little-endian (e.g., x86, ARM).</p><ol><li>**序列化和反序列化：**将数据结构转换为字节流（序列化）或从字节流重建数据结构（反序列化）时，字节顺序可能会变得相关。序列化库或协议可能会隐式或显式指定或处理字节顺序。</li><li>网络传输协议通常定义为bigEndian</li><li>文件读取保存</li><li>**跨平台兼容性：**开发在不同架构上运行的应用程序可能需要注意字节顺序，以确保在系统之间共享数据时数据的一致性和正确性。</li></ol><p>许多现代高级编程语言通过提供处理数据表示和转换的标准化方法，在一定程度上抽象了字节顺序问题。例如：</p><ul><li>Python、Java 或 C# 等语言提供了显式处理字节排序的库或方法。在Java中，<strong><code>java.nio.ByteBuffer</code></strong> 类可以用于处理字节顺序。它提供了 <strong><code>order()</code></strong> 方法，允许你设置字节顺序为大端或小端。</li><li>序列化库通常在内部处理字节序，将其从开发人员手中抽象出来。</li><li>标准化网络协议定义了字节顺序约定（例如，HTTP 对某些数据使用大端字节序）。</li></ul><h3 id="内存泄漏（Memory-Leak）："><strong>内存泄漏（Memory Leak）：</strong></h3><p>内存泄漏是指计算机程序中分配的内存空间在不再需要时未被释放，导致系统中的可用内存持续减少。当程序中的内存泄漏严重时，最终可能会导致系统性能下降、程序崩溃甚至系统崩溃。<strong>内存泄漏通常由编程错误或设计问题引起，例如忘记释放动态分配的内存、循环引用、指针问题等</strong>。为了解决内存泄漏问题，程序员需要定期检查和清理不再使用的内存，或者使用专门的工具来帮助识别和解决内存泄漏。</p><p>指针本质上可以在整个OS允许的<a href="https://www.zhihu.com/search?q=%E5%86%85%E5%AD%98%E5%9D%97&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A%2216303748%22%7D">内存块</a>上任意移动，有时候还会跨界到其他内存块上去。本质上它离机器语言太近，能够造成非常巨大的<a href="https://www.zhihu.com/search?q=%E5%A4%96%E5%BB%B6%E6%80%A7&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A%2216303748%22%7D">外延性</a>破坏。一个最经典的例子就是内存践踏造成的缓冲区溢出。</p><p>Java语言中没有明确的指针概念，它使用引用（reference）来操作对象。这是为了提高安全性和简化开发，因为指针容易导致内存泄漏、越界访问和悬空指针等问题。Java的对象引用是由Java虚拟机（JVM）管理的，这种方式有助于减少对内存的直接操作，从而提高了安全性和可靠性。</p><p>C++ 利用 智能指针达成的效果是：一旦某对象不再被引用，系统刻不容缓，立刻回收内存</p><p>一个解决<strong>空悬指针</strong>的办法是，引入一层间接性，让 p1 和 p2 所指的对象永久有 效。</p><p>在Java中，常见的内存泄漏情况包括：</p><ol><li><strong>长期持有对象的引用：</strong> 如果一个对象被分配了内存，并被存储在某个全局变量、静态变量、集合或缓存中，但在后续的程序执行过程中未释放对该对象的引用，即使该对象不再需要，也无法被垃圾回收。</li><li><strong>监听器未及时移除：</strong> 当一个对象作为监听器注册到某个事件上，但在对象不再需要时，未取消注册或者移除对监听器的引用，这可能导致对象无法被垃圾回收。</li><li><strong>未关闭资源：</strong> 例如打开了文件、数据库连接、网络连接等资源，但在使用完后未显式地关闭或释放这些资源，会导致资源泄漏，进而可能导致内存泄漏。</li><li><strong>循环引用：</strong> 当两个或多个对象相互引用，并且这些对象之间形成了一个环形的引用结构，即使这些对象在外部不再被使用，但由于它们互相引用导致它们之间的引用计数不为零，无法被垃圾回收。</li></ol><p>为避免内存泄漏，需要进行良好的内存管理和编程实践：</p><ul><li>及时释放不再需要的对象引用，可以手动将对象引用置为null。</li><li>在使用完资源后及时关闭文件、数据库连接、网络连接等。</li><li>避免循环引用，使用弱引用或软引用来避免形成永久性的对象引用。</li><li>对于监听器等注册的对象，及时取消注册或移除引用。</li></ul><p>Golang:</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> s0 string <span class="comment">// 一个包级变量</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个演示目的函数。</span></span><br><span class="line">func <span class="title function_">f</span>(<span class="params">s1 string</span>) {</span><br><span class="line">    <span class="comment">// s0 s1 共享同一块内存空间，s0正在被使用所以不会</span></span><br><span class="line">    <span class="comment">//释放，我们只使用了50字节的内存还有2^20-50未被使用，造成很大的内存泄漏</span></span><br><span class="line">    s0 = s1[:<span class="number">50</span>]</span><br><span class="line">    <span class="comment">// Solution: So，有较大范围的内存泄漏时  创建s1的一个副本的子串，而不是直接引用s1的子串。</span></span><br><span class="line">    s0 = <span class="title function_">string</span>([]<span class="title function_">byte</span>(s1[:<span class="number">50</span>]))</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">func <span class="title function_">demo</span>(<span class="params"></span>) {</span><br><span class="line">    s := <span class="title function_">createStringWithLengthOnHeap</span>(<span class="number">1</span> &lt;&lt; <span class="number">20</span>) <span class="comment">// 1M bytes</span></span><br><span class="line">    <span class="title function_">f</span>(s)</span><br><span class="line">}</span><br><span class="line">func <span class="title function_">createStringWithLengthOnHeap</span>(length int) string {</span><br><span class="line">    <span class="comment">// Create a byte slice of the specified length</span></span><br><span class="line">    strBytes := <span class="title function_">make</span>([]byte, length)</span><br><span class="line">    fillChar := <span class="string">'a'</span></span><br><span class="line">    <span class="keyword">for</span> i := range strBytes {</span><br><span class="line">        strBytes[i] = <span class="title function_">byte</span>(fillChar)</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Convert the byte slice to a string and return</span></span><br><span class="line">    <span class="keyword">return</span> <span class="title function_">string</span>(strBytes)</span><br><span class="line">}</span><br></pre></td></tr></table></figure><h2 id="进程间通信IPC"><strong>进程间通信IPC</strong></h2><p><strong>可选用的6种方法</strong></p><ol><li><p>管道 Linux管道是一种特殊的文件描述符的「<code>|</code>」竖线就是一个<strong>管道</strong>，它的功能是将前一个命令（<code>ps auxf</code>）的输出，作为后一个命令（<code>grep mysql</code>）的输入，从这功能描述，可以看出<strong>管道传输数据是单向的</strong>，如果想相互通信，我们需要创建两个管道才行。管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。Channel是Go语言中的一种特殊类型，用于在Goroutine之间进行通信和同步。</p></li><li><p>消息队列（Message Queue）：以上三种方式只适合传递传递少量信息，POSIX 标准中 定义了消息队列用于<strong>进程间数据量较多小数据的通信</strong>。进程可以向队列添加消息，被赋予读权 限的进程则可以从队列消费消息。消息队列克服了信号承载信息量少，管道只能用于无 格式字节流以及缓冲区大小受限等缺点，但实时性相对受限。</p></li><li><p>信号（Signal）：信号用于通知目标进程有某种事件发生，除了用于进程间通信外，进 程还可以发送信号给进程自身。信号的典型应用是 kill 命令  <code>kill -l</code>运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如Ctrl+C 产生 <code>SIGINT</code> 信号，表示终止该进程； - Ctrl+Z 产生 <code>SIGTSTP</code> 信号，表示停止该进程，但还未结束； 如果进程在后台运行，可以通过 <code>kill</code> 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，</p><p>例如： - kill -9 1050 ，表示给 PID 为 1050 的进程发送 <code>SIGKILL</code> 信号，用来立即结束该进程； 所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。 信号是进程间通信机制中<strong>唯一的异步通信机制</strong></p></li><li><p>信号量（Semaphore）：为了防止多进程竞争共享资源，互斥和同步问题。<strong>信号量</strong>就实现了这一保护机制。PV操作，信号量用于两个进程之间同步协作手段，它相当于操作系统提 供的一个特殊变量，程序可以在上面进行 wait() 和 notify() 操作。进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。 若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源<strong>已被占用</strong>，因此进程 B 被阻塞。 直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。</p></li><li><p><strong>共享内存（Shared Memory）</strong>：允许多个进程访问同一块公共的内存空间，这是效率最高的进程间通信形式。<strong>原本每个进程的内存地址空间都是相互隔离的，但操作系统提供了让进程主动创建、映射、分离、控制某一块内存的程序接口。当一块内存被多进程共享</strong>时，各个进程往往会与其它通信机制，譬如信号量结合使用，来达到进程间同步及互斥的协调操作。</p></li><li><p>套接字接口（Socket）RPc：<strong>消息队列和共享内存只适合单机多进程间的通信，套接字接口 是更为普适的进程间通信机制，可用于不同机器之间的进程通信</strong>。套接字（Socket）起 初是由 UNIX 系统的 BSD 分支开发出来的，现在已经移植到所有主流的操作系统上。</p></li></ol><p>当仅限于本机进程间通信时，套接字接口是被优化过的，不会经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等操作，只是简单地将应用层数 据从一个进程拷贝到另一个进程，这种进程间通信方式有个专名的名称：UNIX Domain Socket，又叫做 IPC Socket。</p><ul><li><strong>只支持半双工通信：</strong> 意味着数据传输是单向交替的，通信的一方既是发送者也是接收者，但同一时间只能进行一种操作。</li><li><strong>仅限于父子进程或兄弟进程之间使用：</strong> 由于UNIX Domain Socket是本地通信的一种方式，因此通常用于同一台机器上的进程间通信，比如父子进程或兄弟进程之间。</li></ul><ol><li><strong>空分复用技术（Swapping）：</strong> 中。这种技术能够有效地扩展可用内存的大小。空分复用需要快速的内存地址映射，使得操作系统能够迅速将虚拟内存地址转换为实际物理内存地址。这种映射是由CPU中的存储器管理单元（Memory Management Unit，MMU）负责完成的。</li><li><strong>时分复用技术（Time Division Multiplexing，TDM）：</strong> 时分复用是一种通信技术，用于多路复用，让多个用户或信号共享同一个通信信道或资源。在操作系统中，时分复用也可以被理解为在单个CPU上执行多个进程的技术。这种技术会分割时间成为多个时间片（Time Slice），每个时间片分配给不同的进程，使得它们轮流占用CPU并执行。这种技术可以使系统中的多个进程表现出并发性，尽管实际上在同一时间点只有一个进程在执行。这种并发性是通过快速的进程切换和调度实现的。</li></ol><p><strong>多线程/多进程解决了阻塞问题</strong></p><p>线程是抢占式，<strong>而协程是非抢占式的</strong>，所以需要用户自己释放使用权来切换到其他协程，因此同一时间其实只有一个协程拥有运行权，相当于单线程的能力。</p><p>协程并不是取代线程, 而且<strong>抽象于线程之上</strong>, 线程是被分割的CPU资源, 协程是组织好的代码流程, 协程需要线程来承载运行, 线程是协程的资源, 但协程不会直接使用线程, 协程直接利用的是执行器(Interceptor), 执行器可以关联任意线程或线程池, 可以使当前线程, UI线程, 或新建新程.。</p><p><strong>线程是协程的资源。协程通过Interceptor来间接使用线程这个资源。</strong></p><p>内核态和用户态</p><p>内核kernel是程序，它需要运行，就必须被分配 CPU。因此，CPU 上会运行两种程序，一种是操作系统的内核程序（也称为系统程序），一种是应用程序。前者完成系统任务，后者实现应用任务。两者之间有控制和被控制的关系，前者有权管理和分配资源，而后者只能<strong>向系统申请使用资源。</strong></p><p>您对内核态（Kernel Mode）和用户态（User Mode）的描述非常准确。以下是进一步的详细解释和一些补充信息：</p><h3 id="内核态（Kernel-Mode）">内核态（Kernel Mode）</h3><ul><li><strong>权限</strong>：在内核态中，运行的代码拥有最高的权限，可以访问系统的所有资源，包括硬件和所有内存空间。这意味着内核可以执行任何CPU指令，管理系统的所有硬件资源，如I/O设备、CPU、内存等。</li><li><strong>用途</strong>：<ul><li><strong>系统调用</strong>：当用户态的程序需要执行需要高权限的操作（如I/O操作、进程管理等），它通过系统调用陷入内核态。</li><li><strong>硬件中断处理</strong>：硬件中断发生时，系统会切换到内核态来处理中断。</li><li><strong>内存管理</strong>：内核负责管理虚拟内存到物理内存的映射，保护内存空间不被非法访问。</li></ul></li><li><strong>风险</strong>：由于内核态的代码有如此高的权限，任何错误或漏洞都可能导致系统崩溃或安全性问题。</li></ul><h3 id="用户态（User-Mode）">用户态（User Mode）</h3><ul><li><strong>权限</strong>：在用户态，程序的执行权限受到限制。它们只能访问由内核分配和管理的内存空间，并且只能通过系统调用来请求内核执行高权限操作。</li><li><strong>用途</strong>：<ul><li><strong>应用程序执行</strong>：所有用户应用程序如浏览器、文本编辑器等都在用户态运行。</li><li><strong>安全性</strong>：限制用户态程序的权限可以保护系统的整体稳定性和安全性，防止一个程序恶意或错误地影响整个系统。</li></ul></li><li><strong>内存访问</strong>：用户态下的程序只能访问那些在其进程的虚拟地址空间中被映射的内存页。试图访问未映射或无权限的内存会导致保护错误（如段错误）。</li><li><strong>系统调用</strong>：当用户态程序需要进行需要内核权限的操作时（例如读取文件、网络通信等），它必须通过系统调用接口。这时，CPU会切换到内核态，执行相应的内核代码，完成操作后再返回到用户态。</li></ul><h3 id="切换机制">切换机制</h3><ul><li><strong>从用户态到内核态</strong>：主要通过以下方式：<ul><li><strong>系统调用</strong>（如 <code>fork</code>, <code>exec</code>, <code>read</code>, <code>write</code> 等）。</li><li><strong>中断</strong>：如时钟中断，硬件设备中断。</li><li><strong>异常</strong>：如页面错误（page fault），除零错误等。</li></ul></li><li><strong>从内核态返回用户态</strong>：当内核完成其任务后，通过特定的CPU指令（如在x86架构上的 <code>iret</code> 或 <code>sysret</code>）返回到用户态，恢复之前的执行上下文。</li></ul><p>这种分离的设计有助于系统的稳定性和安全性，因为它限制了用户程序直接操作硬件的能力，从而保护了系统的核心功能不受用户程序的错误或恶意行为影响。</p><h1>Linux</h1><p>Linus Torvalds 创建。GNU/LInux是全球数百万开发人员之间的协作，涉及<a href="https://www.gnu.org/home.en.html">GNU 项目</a>, <a href="https://www.kernel.org/">Linux 内核开发团队</a><a href="http://www.x.org/wiki/">由 Torvalds 领导， X Window 系统的</a>各种开发人员在过去的 29 年中，以及其他。这就是自由软件基金会要求将使用来自 GNU 项目的软件的完整 Linux 操作系统称为“GNU/Linux”的原因。</p><p>Many <a href="https://en.wikipedia.org/wiki/Open_source">open source</a> developers agree that the Linux kernel was not designed but rather <a href="https://en.wikipedia.org/wiki/Evolution">evolved</a> through <a href="https://en.wikipedia.org/wiki/Natural_selection">natural selection</a>. Torvalds considers that although the design of Unix served as a scaffolding, “Linux grew with a lot of mutations – and because the mutations were less than random, they were faster and more directed than <a href="https://en.wikipedia.org/wiki/Mutation#Induced_mutation">alpha-particles in DNA</a>.”<a href="https://en.wikipedia.org/wiki/Linux#cite_note-77">[73]</a> <a href="https://en.wikipedia.org/wiki/Eric_S._Raymond">Eric S. Raymond</a> considers Linux’s revolutionary aspects to be social, not technical: before Linux, complex software was designed carefully by small groups, but “Linux evolved in a completely different way. From nearly the beginning, it was rather casually hacked on by huge numbers of volunteers coordinating only through the Internet. Quality was maintained not by rigid standards or autocracy but by the naively simple strategy of releasing every week and getting feedback from hundreds of users within days, creating a sort of rapid Darwinian selection on the mutations introduced by developers.”<a href="https://en.wikipedia.org/wiki/Linux#cite_note-78">[74]</a> <a href="https://en.wikipedia.org/wiki/Bryan_Cantrill">Bryan Cantrill</a>, an engineer of a competing OS, agrees that “Linux wasn’t designed, it evolved”, but considers this to be a limitation, proposing that some features, especially those related to security,<a href="https://en.wikipedia.org/wiki/Linux#cite_note-79">[75]</a> cannot be evolved into, “this is not a biological system at the end of the day, it’s a software system.”</p><p><strong>全称GNU/Linux，是一种免费使用和自由传播的<a href="https://baike.baidu.com/item/%E7%B1%BBUNIX/9032872">类UNIX</a>操作系统</strong>，其内核由<a href="https://baike.baidu.com/item/%E6%9E%97%E7%BA%B3%E6%96%AF%C2%B7%E6%9C%AC%E7%BA%B3%E7%AC%AC%E5%85%8B%E7%89%B9%C2%B7%E6%89%98%E7%93%A6%E5%85%B9/1034429">林纳斯·本纳第克特·托瓦兹</a>于1991年10月5日首次发布，它主要受到<a href="https://baike.baidu.com/item/Minix/7106045">Minix</a>和Unix思想的启发，是一个基于<a href="https://baike.baidu.com/item/POSIX/3792413">POSIX</a>的多用户、<a href="https://baike.baidu.com/item/%E5%A4%9A%E4%BB%BB%E5%8A%A1/1011764">多任务</a>、支持<a href="https://baike.baidu.com/item/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1190404">多线程</a>和多<a href="https://baike.baidu.com/item/CPU/120556">CPU</a>的操作系统。它能运行主要的<a href="https://baike.baidu.com/item/Unix/219943">Unix</a>工具软件、应用程序和网络协议。它支持<a href="https://baike.baidu.com/item/32%E4%BD%8D/5812218">32位</a>和<a href="https://baike.baidu.com/item/64%E4%BD%8D/2262282">64位</a>硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统。Linux有上百种不同的发行版，如基于社区开发的<a href="https://baike.baidu.com/item/debian/748667">debian</a>、<a href="https://baike.baidu.com/item/archlinux/10857530">archlinux</a>，和基于商业开发的<a href="https://baike.baidu.com/item/Red%20Hat%20Enterprise%20Linux/10770503">Red Hat Enterprise Linux</a>、<a href="https://baike.baidu.com/item/SUSE/60409">SUSE</a>、<a href="https://baike.baidu.com/item/Oracle%20Linux/6876458">Oracle Linux</a>等。</p><p>Linus built kernel to solve unix hard-use and lack I/O RPC function.  区分 Linux（内核）和 Linux（操作系统）。</p><p>Kernel 是计算机<a href="https://en.wikipedia.org/wiki/Operating_system">操作系统</a>核心的<a href="https://en.wikipedia.org/wiki/Computer_program">计算机程序</a>，通常可以完全控制系统中的所有内容**。**<a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)#cite_note-Linfo-1">[1]</a>它是操作系统代码的一部分，始终驻留在内存中<a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)#cite_note-2">[2]</a>并促进硬件和软件组件之间的交互。完整的内核通过<a href="https://en.wikipedia.org/wiki/Device_driver">设备驱动程序控制</a>所有硬件资源（例如 I/O、内存、密码） ，仲裁涉及这些资源的进程之间的冲突，并优化公共资源的利用，例如 CPU 和缓存使用、文件系统和网络套接字。<a href="https://en.wikipedia.org/wiki/Booting">在大多数系统上，内核是启动</a>时最先加载的程序之一（在<a href="https://en.wikipedia.org/wiki/Bootloader">引导加载程序</a>）。它处理其余的启动以及内存、<a href="https://en.wikipedia.org/wiki/Peripheral">外围设备</a>和来自<a href="https://en.wikipedia.org/wiki/Software">软件的</a><a href="https://en.wikipedia.org/wiki/Input/output">输入/输出</a>(I/O) 请求，将它们转换为<a href="https://en.wikipedia.org/wiki/Central_processing_unit">中央处理器的</a><a href="https://en.wikipedia.org/wiki/Data_processing">数据处理</a>指令。</p><p>内核是操作系统的核心部分，具有完全控制系统资源的能力。它始终驻留在内存中，促进硬件和软件之间的交互。内核通过设备驱动程序控制硬件资源，仲裁进程之间的冲突，并优化共享资源的利用。在大多数系统上，内核是启动时最先加载的程序。<br>内核的关键代码被加载到受保护的内核空间中，与应用程序运行的用户空间分离。这种分离可以防止用户数据和内核数据相互干扰，并提高系统的稳定性和安全性。内核提供了一个低级的接口，进程通过系统调用来请求内核服务。<br>内核架构有<strong>整体内核和微内核</strong>两种设计。整体内核在单个地址空间中运行，以提高速度；微内核在用户空间中运行大部分服务，以提高灵活性和模块化。Linux内核是整体式的，但也支持模块化，可以在运行时加载和卸载内核模块。<br>内核负责决定将哪些正在运行的程序分配给处理器，从而执行程序。它是计算机系统的中央组件，控制和管理系统的各个方面。</p><p>Linux 操作系统将其运行环境分为两种状态：用户态和内核态。用户态是指应用程序运行的环境，而内核态是指操作系统内核运行的环境。</p><h3 id="用户态-2">用户态</h3><p>用户态（User Mode）是指应用程序运行的环境。在用户态下，应用程序可以使用用户态提供的系统调用接口来请求操作系统服务。用户态的应用程序不能直接访问硬件资源，必须通过系统调用来请求内核态的服务。</p><p>用户态的特点：</p><ul><li>应用程序运行在用户态下</li><li>不允许直接访问硬件资源</li><li>必须通过系统调用来请求内核态服务</li></ul><h3 id="内核态-2">内核态</h3><p>内核态（Kernel Mode）是指操作系统内核运行的环境。在内核态下，内核可以直接访问硬件资源，管理系统资源，并提供服务给用户态的应用程序。</p><p>内核态的特点：</p><ul><li>操作系统内核运行在内核态下</li><li>允许直接访问硬件资源</li><li>管理系统资源并提供服务给用户态应用程序</li></ul><h3 id="系统调用-2">系统调用</h3><p>系统调用（System Call）是用户态应用程序请求内核态服务的接口。用户态应用程序通过系统调用来请求内核态的服务，例如读取文件、创建进程等。</p><p>系统调用的过程：</p><ol><li>应用程序在用户态下执行</li><li>应用程序需要请求内核态服务</li><li>应用程序通过系统调用接口请求服务</li><li>内核态接收到请求并处理</li><li>内核态将结果返回给应用程序</li></ol><p><strong>实践</strong></p><h3 id="Libs-2">Libs</h3><ol><li>系统管理<ul><li>systemd: 系统和服务管理器</li><li>cron: 定时任务管理</li><li>top/htop: 系统资源监控</li><li>ps: 进程状态查看</li><li>journalctl: 日志查看</li><li>dmesg: 内核日志查看</li></ul></li><li>文件管理<ul><li>ls, cp, mv, rm: 基本文件操作</li><li>find: 文件搜索</li><li>grep: 文本搜索</li><li>tar, gzip, bzip2: 文件压缩和归档</li><li>chmod, chown: 文件权限管理</li></ul></li><li>文本处理<ul><li>vim, nano: 文本编辑器</li><li>sed, awk: 文本处理工具</li><li>cat, less, more: 文件查看</li></ul></li><li>网络工具<ul><li>ifconfig/ip: 网络接口配置</li><li>ping, traceroute: 网络诊断</li><li>ssh: 远程登录</li><li>curl, wget: 文件下载</li><li>netstat, ss: 网络连接状态</li><li>iptables/nftables: 防火墙管理</li></ul></li></ol><p>Systemd 是许多现代 Linux 发行版中使用的初始化系统和系统管理器。以下是关于 systemd 的一些重要概念和常用命令：</p><ol><li>核心概念：<ul><li>Unit：systemd 管理的基本对象，包括服务、挂载点、设备和网络配置等</li><li>Service：最常见的 unit 类型，用于管理守护进程</li><li>Target：一组 unit 的集合，类似于运行级别</li></ul></li></ol><p>Unit 文件结构</p><p>一个典型的 <code>.service</code> 单元文件结构如下：</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">`[Unit]</span></span><br><span class="line"><span class="string">Description=My Custom Service</span></span><br><span class="line"><span class="string">After=network.target</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Service]</span></span><br><span class="line"><span class="string">ExecStart=/usr/bin/my-service</span></span><br><span class="line"><span class="string">ExecReload=/bin/kill -HUP $MAINPID</span></span><br><span class="line"><span class="string">ExecStop=/bin/kill $MAINPID</span></span><br><span class="line"><span class="string">Restart=on-failure</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[Install]</span></span><br><span class="line"><span class="string">WantedBy=multi-user.target`</span></span><br><span class="line"></span><br><span class="line"><span class="string">`[Unit]`</span>：描述单元和其依赖关系。</span><br><span class="line"></span><br><span class="line"><span class="string">`[Service]`</span>：定义服务如何启动、停止，以及重启策略。</span><br><span class="line"></span><br><span class="line"><span class="string">`[Install]`</span>：定义单元如何被启用或关联到其他目标。</span><br></pre></td></tr></table></figure><p>注意事项</p><p><strong>权限</strong>：许多 <code>systemctl</code> 命令需要以 <code>root</code> 权限运行。</p><p><strong>配置修改后重载</strong>：修改 <code>.service</code> 文件后，需要运行 <code>systemctl daemon-reload</code> 来重新加载配置。</p><p><strong>安全性</strong>：<code>systemd</code> 提供了许多安全选项，可以限制服务的权限和资源使用。</p><p>$表明是非root用户登录，#表示是root用户登录，它们是终端shell的命令提示符 几种常用终端的命令提示符</p><p>BASH: root账户: # ,非root账户: <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="39.819ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 17600 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="merror" data-mjx-error="You can't use 'macro parameter character #' in math mode" title="You can't use 'macro parameter character #' in math mode"><rect data-background="true" width="17600" height="950" y="-200"></rect><title>You can't use 'macro parameter character #' in math mode</title><g data-mml-node="mtext" style="font-family: serif;"><text data-variant="-explicitFont" transform="scale(1,-1)" font-size="884px"> KSH: root账户: # ,非root账户: </text></g></g></g></g></svg></mjx-container> CSH[TCSH]: root账户: % ,非root账户: %</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">而/ 是根节点， ~ 是 home</span><br><span class="line">如果以root账号登陆   ~ 是 /root/</span><br></pre></td></tr></table></figure><p>Program: a file containing instructions to be executed, static Process: an instance of a program in execution, live entity</p><p>execve（执行文件）在<a href="https://baike.baidu.com/item/%E7%88%B6%E8%BF%9B%E7%A8%8B/614062">父进程</a>中fork一个子进程，在子进程中调用exec函数启动新的程序。exec函数一共有六个，其中execve为内核级<a href="https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/861110">系统调用</a>，其他（execl，execle，execlp，execv，execvp）exec(): often used after fork() to <strong>load</strong> another process</p><p>许多程序需要开机启动。它们在Windows叫做"服务"（service），在Linux就叫做"<a href="https://zh.wikipedia.org/wiki/%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B">守护进程</a>"（daemon）。Linux Daemon（守护进程）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。</p><ol><li><strong>syslogd</strong>：系统日志守护进程，负责记录系统日志消息。</li><li><strong>httpd</strong>：Web 服务器守护进程，如 Apache 或 Nginx，用于提供 Web 服务。</li><li><strong>sendmail</strong>：邮件服务器守护进程，负责处理发送和接收邮件的功能。</li><li><strong>mysqld</strong>：数据库服务器守护进程，比如 MySQL 或 MariaDB，用于管理和提供数据库服务。</li></ol><p>这些守护进程通常在系统启动时自动启动，并在系统运行期间持续<strong>监听、处理或提供服务</strong>。它们的运行通常不需要用户的直接干预，而是通过配置文件或其他设置来控制其行为和功能。</p><p><strong>FTP</strong></p><p><strong>主动</strong>模式的FTP是指<strong>服务器主动</strong>连接客户端的数据端口，被动模式的FTP是指<strong>服务器被动等待</strong>客户端连接自己的数据端口。</p><p>被动模式的FTP通常用在处于防火墙之后的FTP客户访问外界FTP服务器的情况，因为在这种情况下，防火墙通常配置为<strong>不允许外界访问防火墙之内的主机</strong>，而<strong>只允许由防火墙之内的主机发起对外的连接请求</strong>。因此，在这种情况下不能使用主动模式的FTP传输，而被动模式的FTP可以良好的工作。</p><p>主动模式需要服务器主动向客户端发起连接，而现在普通的客户端大多位于NAT之后，所以主动模式常常无法进行。即使可以，也需要客户端打开防火墙，允许服务端的20端口访问。所以服务端基本需要支持被动模式，但被动模式需要开放一段端口。为了安全，可以选择一小段端口，然后在防火墙开放这一段端口。</p><h3 id="Everything-is-a-file-2">Everything is a file</h3><p><strong>Linux操作系统的设计哲学之一：将所有设备、资源或进程都视为文件或文件类似的对象。</strong></p><p>在Linux中，不仅普通的文本文件、目录、硬件设备和外部设备都被视为文件，甚至系统中的进程、网络连接、硬件接口等也被抽象为文件。这种抽象化使得Linux系统更加统一和灵活，因为它允许对不同资源使用相似的操作方式。</p><p>好处是读写这些资源都可用open()/close()/write()/read()等函数进行处理。屏蔽了硬件的区别，所有设备都抽象成文件，提供统一的接口给用户。虽然类型各不相同，但是对其提供的却是同一套API。更进一步，对文件的操作也可以跨文件系统执行。在Linux系统中有三类文件：普通文件、目录文件和特殊文件。</p><p>网络 I/O 通过网络进行数据传输，通常包括 TCP 或 UDP 等协议。网络 I/O 的延迟较高，取决于网络带宽、路由器、中继设备等，数据包可能需要经过多个中间节点才能到达目标服务器。</p><p>局域网的延迟通常在微秒到毫秒级，而广域网（如互联网）的延迟可能会达到几十毫秒甚至更高。网络 I/O 并发是非常常见的需求，特别是在高并发服务器（如 Web 服务器）中。服务器通常需要同时处理数百甚至数千个网络连接。为了提高性能，使用了 I/O 多路复用（select、poll、epoll）和异步 I/O 来管理大量的并发连接。网络 I/O 带宽受到网络设备（如网卡、路由器）的限制。千兆以太网的带宽是 1 Gbps，大约相当于 125 MB/s，而如今常见的 10 Gbps 网卡能达到 1.25 GB/s，远低于本地存储设备。</p><p>现代服务器（如 Nginx、Node.js）通常使用异步非阻塞 I/O 模型，以最大限度提高 I/O 吞吐量。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;操作系统OS&lt;/h1&gt;
&lt;p&gt;在学习操作系统的过程中，我们会接触到众多复杂的概念，如内核、进程管理、内存管理、文件系统等。为了更好地掌握这些内容，建议采取循序渐进的学习路线，从理论到实践、从基础到进阶，逐步深入。&lt;/p&gt;
&lt;p&gt;学习路线&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;操作系统</summary>
      
    
    
    
    <category term="计算机科学" scheme="https://stan370.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="计算机基础" scheme="https://stan370.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="操作系统" scheme="https://stan370.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>操作系统 I/O 多路复用，select / poll / epoll</title>
    <link href="https://stan370.github.io/2024/09/15/IOandEpoll/Epoll/"/>
    <id>https://stan370.github.io/2024/09/15/IOandEpoll/Epoll/</id>
    <published>2024-09-15T04:16:23.000Z</published>
    <updated>2025-07-28T07:59:35.452Z</updated>
    
    <content type="html"><![CDATA[<p>在现代计算机系统中，I/O 操作是影响性能的关键因素，尤其是在网络服务和本地存储密集型应用中。你是否曾经思考过网络 I/O 和本地 I/O 之间的性能差异？为什么网络传输总是比本地硬盘慢？</p><p>函数select()、poll()和epoll()在网络编程和操作系统中用于监视多个文件描述符，以查看其中任何一个是否可进行 I/O（例如，套接字已准备好进行读/写）。这些主要用于事件驱动编程，特别是在服务器中同时处理多个连接时。那么，epoll 到底为什么如此高效？它如何超越传统的 select() 和 poll()？通过这篇讨论，你将深入了解为什么 epoll 是大规模网络 I/O 管理的首选，以及如何在实践中最大化其优势。</p><p>在操作系统中，程序运行的空间分为内核空间和用户空间， 用户空间所有对io操作的代码（如文件的读写、socket的收发等）都会通过系统调用进入内核空间完成实际的操作。</p><h2 id="阻塞-I-O">阻塞 I/O</h2><p>在阻塞 I/O 模式下，系统调用（如 read() 或 recvfrom()）会一直等待，直到内核把数据准备好并传输到用户空间。此期间，线程会被挂起，CPU将被释放去做其他事情，但这个线程无法执行任何其他任务，直到 I/O 操作完成。这种情况会导致线程阻塞，尤其在高并发环境下，每个 I/O 操作都可能耗费大量时间等待。在linux中，默认情况下所有的socket都是阻塞的，一个典型的读操作流程大概是这样：<img src="https://cdn.jsdelivr.net/gh/Stan370/stan370.github.io@main/source/_posts/IOandEpoll/image-1.png" alt="socket"></p><p>当用户进程调用了 read()/recvfrom() 等系统调用函数，它会进入内核空间中，当这个网络I/O没有数据的时候，内核就要等待数据的到来，而在用户进程这边，整个进程会被阻塞，直到内核空间返回数据。当内核空间的数据准备好了，它就会将数据从内核空间中拷贝到用户空间，此时用户进程才解除阻塞的的状态，重新运行起来。<br>所以，阻塞I/O的特点就是在IO执行的两个阶段（用户空间与内核空间）都被阻塞了。</p><h2 id="非阻塞-I-O">非阻塞 I/O</h2><p>非阻塞 I/O 则允许程序发起 I/O 操作（例如 read() 或 recvfrom()），即使数据还没准备好，内核也不会让进程挂起，而是立即返回。此时用户进程得到的是一个错误，提示数据尚未准备好。用户进程需要不断轮询，重复调用 I/O 操作直到数据可用。这种方式避免了线程被阻塞的情况，但频繁的轮询可能会导致 CPU 使用效率低下。<img src="https://cdn.jsdelivr.net/gh/Stan370/stan370.github.io@main/source/_posts/IOandEpoll/image-2.png" alt="alt text"></p><h2 id="多路复用-I-O">多路复用 I/O</h2><p>协程（英语：coroutine）是计算机程序的一类组件，推广了协作式多任务的子例程，允许执行被挂起与被恢复,协程可以通过yield（取其“退让”之义而非“产生”）来调用其它协程，接下来的每次协程被调用时，从协程上次yield返回的位置接着执行，通过yield方式转移执行权的协程之间不是调用者与被调用者的关系，而是彼此对称、平等的。<br>多路复用 I/O (select()，poll()，epoll()) 允许单个线程监控多个文件描述符（如 socket），从而在多个 I/O 操作之间进行复用。它的基本原理是通过轮询多个 socket，查看是否有数据到达，并在有数据到达时通知应用程序。相比非阻塞 I/O，这种机制更高效，特别适合于处理大量连接的服务器。<br>本地 I/O 操作通常为阻塞模式，即在进行 I/O 操作时，进程会被挂起直到操作完成。然而，现代操作系统也提供了非阻塞本地 I/O 或异步 I/O（如 Linux 的 aio 或 Windows 的 IOCP），允许应用程序继续执行其他任务而不等待 I/O 完成。网络 I/O 同样可以是阻塞的或非阻塞的。在非阻塞网络 I/O 中，进程发起 I/O 操作时不需要等待数据返回，可以继续执行其他操作。网络 I/O 领域中，异步 I/O、多路复用 I/O（如 select()、poll()、epoll()）、以及事件驱动编程（如 libuv、libevent）等技术被广泛使用，以应对高延迟和并发问题。</p><p>将协程与IO多路复用结合起来，可以实现高性能的并发IO程序。socket 是 Unix 中的术语。socket 可以用于同一台主机的不同进程间的通信，也可以用于不同主机间的通信。一个 socket 包含地址、类型和通信协议等信息，通过 socket() 函数创建：<br>int socket(int domain, int type, int protocol)<br>返回的就是这个 socket 对应的文件描述符 fd。操作系统将 socket 映射到进程的一个文件描述符上，进程就可以通过读写这个文件描述符来和远程主机通信。</p><p>可以这样理解：socket 是进程间通信规则的高层抽象，而 fd 提供的是底层的具体实现。socket 与 fd 是一一对应的。通过 socket 通信，实际上就是通过文件描述符 fd 读写文件。这也符合 Unix“一切皆文件”的哲学。使用IO多路复用技术监听多个socket，当有socket可读或可写时，通过事件通知，激活相应的协程进行处理。</p><h2 id="1-select">1.select()</h2><p>用法：允许监视多个文件描述符，以查看它们是否已准备好读取、写入或是否有错误。<br>限制：<br>具有可监控的最大文件描述符数量（通常为 1024）。此数量由 定义FD_SETSIZE，在高并发应用程序中可能会受到限制。<br>当有大量文件描述符时效率低下，因为它每次都必须检查每个描述符。<br>使用单一数据结构来保存读取、写入和错误描述符。</p><p>例子：<br>fd_set readfds; FD_ZERO(&amp;readfds); FD_SET(socket_fd, &amp;readfds); select(socket_fd + 1, &amp;readfds, NULL, NULL, &amp;timeout);</p><h2 id="2-poll">2.poll()</h2><p>poll 和 select 几乎没有区别。poll 在用户态通过数组方式传递文件描述符，在内核会转为链表方式存储，没有最大数量的限制 int poll(struct pollfd *fds, nfds_t nfds, int timeout);</p><p>好处：<br>struct pollfd使用比 使用的位掩码更具可扩展性的数组select()。<br>可以更轻松地处理大量文件描述符。</p><p>例子：<br>struct pollfd fds[2]; fds[0].fd = socket_fd; fds[0].events = POLLIN; poll(fds, 2, timeout);</p><h2 id="3-epoll-（Linux-专用）">3. epoll()（Linux 专用）</h2><p>epoll 有以下几个特点：</p><p>使用红黑树存储文件描述符集合<br>使用队列存储就绪的文件描述符<br>每个文件描述符只需在添加时传入一次；通过事件更改文件描述符状态</p><p>因为它使用基于事件的模型，所以poll()效率更高。内核仅返回已就绪的文件描述符，而不是轮询每个文件描述符。允许边缘触发和电平触发模式，提供灵活性。</p><p>epoll()效率更高，因为它会内部跟踪文件描述符集，并且只在某个文件描述符就绪时通知应用程序。它不需要在每次调用时重新检查所有文件描述符。那为什么epoll可以高效处理数千个连接，达到更好的并发性能？</p><h3 id="高效的事件通知机制">高效的事件通知机制</h3><p>select()和poll()：</p><p>这两个函数每次调用时都会对所有文件描述符执行线性扫描。这意味着即使只有少数文件描述符“就绪”（即数据可供读取/写入），内核也必须在每次调用该函数时检查每个描述符。这使得它们的性能与受监视的文件描述符数量成正比。<br>例如，如果您正在监视 1,000 个文件描述符，但只有 1 个已准备就绪，select()则poll()仍将对所有 1,000 个进行迭代。</p><p>epoll它的工作原理是只向内核注册一次文件描述符（使用epoll_ctl()）。此后，内核会跟踪哪些文件描述符已就绪。当您调用时epoll_wait()，它仅返回具有事件（即数据就绪）的文件描述符，而不会扫描所有文件描述符。这使得它更加高效，尤其是在监视大量描述符时，因为它消除了重复扫描的需要。<br>它不再在每次调用时检查所有文件描述符，epoll而是更像一个“事件驱动”系统：当注册描述符的状态发生变化时，内核会通知您。</p><h3 id="边沿触发和电平触发模式">边沿触发和电平触发模式</h3><p>水平触发（LT，Level Trigger）：当文件描述符就绪时，会触发通知，如果用户程序没有一次性把数据读/写完，下次还会发出可读/可写信号进行通知。<br>边缘触发（ET，Edge Trigger）：仅当描述符从未就绪变为就绪时，通知一次，之后不会再通知。</p><p>select 只支持水平触发，epoll 支持水平触发和边缘触发。区别：边缘触发效率更高，减少了事件被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。</p><p>使用场景：当连接数较多并且有很多的不活跃连接时，epoll 的效率比其它两者高很多。当连接数较少并且都十分活跃的情况下，由于 epoll 需要很多回调，因此性能可能低于其它两者。</p><p>3.大量描述符的 O(1) 性能<br>select()和poll()：<br>两者都具有O(n)复杂度，其中n是被监视的文件描述符的数量。随着描述符数量的增加，检查它们所花费的时间也呈线性增长。<br>epoll()：<br>epoll_wait()对于大多数操作来说，其复杂度为O(1)，这意味着它的性能不会随着文件描述符数量的增加而降低。这使得它在处理数千（甚至数万）个连接时具有更好的扩展性。</p><p>4.内核空间数据结构<br>epoll()使用更先进的内核空间数据结构（如红黑树和链接列表）来高效跟踪文件描述符。一旦文件描述符被注册，它就会存储在树中，从而允许快速查找和更新，进一步提高性能。<br>相比之下，每次调用时select()都poll()需要将所有文件描述符从用户空间复制到内核空间，并且内核必须检查每一个文件描述符，从而导致更多的开销。</p><ul><li><strong><code>select()</code> and <code>poll()</code></strong>:<ul><li>Both have <strong>O(n)</strong> complexity, where <code>n</code> is the number of file descriptors being monitored. As the number of descriptors grows, the time taken to check them grows linearly.</li></ul></li><li><strong><code>epoll()</code></strong>:<ul><li><code>epoll_wait()</code> has <strong>O(1)</strong> complexity for most operations, meaning it doesn’t degrade in performance as the number of file descriptors increases. This allows it to scale much better when handling thousands (or even tens of thousands) of connections.</li></ul></li></ul><h3 id="4-Kernel-Space-Data-Structures">4. <strong>Kernel-Space Data Structures</strong></h3><ul><li><code>epoll()</code> uses more advanced kernel-space data structures (like red-black trees and linked lists) to efficiently track the file descriptors. Once a file descriptor is registered, it is stored in a tree, allowing quick lookups and updates, further improving performance.</li><li>In contrast, <code>select()</code> and <code>poll()</code> need to copy all file descriptors from user space to kernel space on every call, and the kernel has to check each one, leading to more overhead.</li></ul><p>此外还使用了内存映射（ <code>mmap</code> ）技术</p><p>另一个本质的改进在于 <code>epoll</code> 采用基于事件的就绪通知方式。在 <code>select/poll</code> 中，进程只有在调用一定的方法后，内核才对所有监视的socket描述符进行扫描，而 <code>epoll</code> 事先通过 <code>epoll_ctl()</code> 来注册一个socket描述符，一旦检测到epoll管理的socket描述符就绪时，内核会采用类似 <code>callback</code> 的回调机制，迅速激活这个socket描述符，当进程调用 <code>epoll_wait()</code> 时便可以得到通知，也就是说epoll最大的优点就在于它 <strong>只管就绪的socket描述符，而跟socket描述符的总数无关</strong> 。</p><p>5.大量描述符的内存使用率较低<br>在 中select()，您必须提供一个固定大小的位掩码（通常限制为 1024 个描述符，但在某些系统中可以进行调整）。<br>在中poll()，您传递一个数组struct pollfd，该数组随着描述符的数量线性增长。<br>epoll()通过仅维护活动文件描述符（具有事件的文件描述符）列表而不是所有描述符的完整集合来最大限度地减少内存使用量。<br>下面是epoll性能检测的一段代码示例：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/epoll.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> {</span><br><span class="line">    <span class="type">int</span> fd1 = open(<span class="string">"file1.txt"</span>, O_RDONLY);</span><br><span class="line">    <span class="type">int</span> fd2 = open(<span class="string">"file2.txt"</span>, O_RDONLY);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (fd1 &lt; <span class="number">0</span> || fd2 &lt; <span class="number">0</span>) {</span><br><span class="line">        perror(<span class="string">"open failed"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create an epoll instance</span></span><br><span class="line">    <span class="type">int</span> epoll_fd = epoll_create1(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (epoll_fd &lt; <span class="number">0</span>) {</span><br><span class="line">        perror(<span class="string">"epoll_create1 failed"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="comment">// Add fd1 and fd2 to the epoll instance</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> <span class="title">event</span>;</span></span><br><span class="line">    event.events = EPOLLIN;  <span class="comment">// We are interested in read events</span></span><br><span class="line">    event.data.fd = fd1;</span><br><span class="line">    <span class="keyword">if</span> (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, fd1, &amp;event) &lt; <span class="number">0</span>) {</span><br><span class="line">        perror(<span class="string">"epoll_ctl failed for fd1"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    }</span><br><span class="line">    event.data.fd = fd2;</span><br><span class="line">    <span class="keyword">if</span> (epoll_ctl(epoll_fd, EPOLL_CTL_ADD, fd2, &amp;event) &lt; <span class="number">0</span>) {</span><br><span class="line">        perror(<span class="string">"epoll_ctl failed for fd2"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    }</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> <span class="title">events</span>[2];</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) {</span><br><span class="line">        <span class="comment">// Wait for events on the file descriptors</span></span><br><span class="line">        <span class="type">int</span> num_events = epoll_wait(epoll_fd, events, <span class="number">2</span>, <span class="number">-1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (num_events &lt; <span class="number">0</span>) {</span><br><span class="line">            perror(<span class="string">"epoll_wait failed"</span>);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Handle the events that are ready</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num_events; i++) {</span><br><span class="line">            <span class="keyword">if</span> (events[i].data.fd == fd1) {</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">"Data ready on fd1\n"</span>);</span><br><span class="line">            } <span class="keyword">else</span> <span class="keyword">if</span> (events[i].data.fd == fd2) {</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">"Data ready on fd2\n"</span>);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    close(fd1);</span><br><span class="line">    close(fd2);</span><br><span class="line">    close(epoll_fd);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>epoll()速度更快，主要是因为它避免了重复扫描所有文件描述符，而是使用事件驱动模型，仅在必要时通知应用程序。对于大多数操作，它的性能为 O(1)，并且可以高效处理数千个连接，使其成为大型 Web 服务器等高并发场景的理想选择。相比之下，select()和poll()两者都具有 O(n) 性能，随着文件描述符数量的增加，这会导致速度明显变慢。</p><h2 id="Reactor">Reactor</h2><p>最直观的服务器处理多客户端访问的方式，就是为每个连接创建一个线程，或者更早期操作系统里甚至是一个进程。虽然线程比进程更轻量，切换成本也更低，但每连接一个线程在并发量大时仍会面临两个问题：</p><p>线程创建/销毁有系统开销（malloc stack、context switch）。</p><p>线程是稀缺资源，系统线程数有上限（如 Linux 默认 1024~65535）。</p><p>所以，现代服务端架构更倾向于使用线程池来复用线程资源。线程池中每个线程从任务队列中取任务处理，避免了反复创建/销毁的开销。</p><p>但线程池引入后面临另一个问题：I/O 阻塞会浪费线程资源。如果一个线程执行 read(socket) 被阻塞，而连接上没有数据，那么整个线程就“卡住”了，不能服务其他连接。</p><p>为了避免这个问题，我们可以将 socket 设置为非阻塞模式。这样 read() 不会阻塞，而是立即返回，如果没有数据，就返回错误码 EAGAIN。线程就可以在用户空间“轮询”所有 socket。</p><p>但这种方式会导致高 CPU 占用，尤其在连接数多时效率低。</p><p>所以引入了 I/O 多路复用技术（如 select、poll、epoll），它允许一个线程通过一个系统调用（如 epoll_wait）同时监听多个连接的状态，一旦某些连接可读（或可写），内核就通知我们“这些连接准备好了”，我们再去 read()，避免了不必要的轮询。</p><p>这就是像 Nginx、Redis、Node.js、netty 等高并发服务采用的基础模式：I/O 多路复用 + 非阻塞 I/O + 事件驱动模型。Reactor模式称为反应器模式或应答者模式，是基于事件驱动的设计模式，拥有一个或多个并发输入源，有一个服务处理器和多个请求处理器，服务处理器会同步的将输入的请求事件以多路复用的方式分发给相应的请求处理器。Proactor 是把任务交给操作系统 / runtime，让它完成后通知你处理结果</p><p>单 Reactor 单线程（Redis）<br>所有 I/O + 业务逻辑都在一个线程中串行完成</p><p>简单、性能好（但业务处理不能太重）</p><p>单 Reactor 多线程（Nginx）<br>Reactor 只负责监听/调度，业务逻辑交给线程池处理</p><p>主从 Reactor（Netty）<br>主 Reactor 接收连接</p><p>从 Reactor 负责具体数据读写</p><p>分离 accept 和 IO 阶段，提高可扩展性</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在现代计算机系统中，I/O 操作是影响性能的关键因素，尤其是在网络服务和本地存储密集型应用中。你是否曾经思考过网络 I/O 和本地 I/O 之间的性能差异？为什么网络传输总是比本地硬盘慢？&lt;/p&gt;
&lt;p&gt;函数select()、poll()和epoll()在网络编程和操作系统</summary>
      
    
    
    
    <category term="计算机科学" scheme="https://stan370.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="计算机基础" scheme="https://stan370.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    <category term="操作系统" scheme="https://stan370.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>理解数据库系统</title>
    <link href="https://stan370.github.io/2024/08/20/DB/"/>
    <id>https://stan370.github.io/2024/08/20/DB/</id>
    <published>2024-08-19T16:09:14.000Z</published>
    <updated>2025-03-19T12:12:05.245Z</updated>
    
    <content type="html"><![CDATA[<h1>Database</h1><p>数据库是一个存储数据的系统，它可以存储大量的数据，并且能够高效地检索这些数据。数据库中的数据被组织成表格的形式，这些表格称为表。表中的每一行代表一个记录，每一列代表一个字段。</p><blockquote><p>对于数据库而言，重要的不是数据量，而是当数据量增加时运算如何增加。时间复杂度用来检验某个算法处理一定量的数据要花多长时间，时间复杂度不会给出确切的运算次数，但是给出的是一种理念。</p></blockquote><p><strong>根据数据模型分类：</strong></p><p><strong>关系型数据库（RDBMS）</strong>：</p><ul><li>使用表格（表）和行列结构存储数据。</li><li>数据以严格的结构（模式）存在，具有预定义的模式（Schema）。</li><li>常见的关系型数据库包括 MySQL、PostgreSQL、Oracle 和 SQL Server 等。</li></ul><p><strong>非关系型数据库（NoSQL）</strong>：</p><p>键值（Key-Value）数据库<br>概述：键值数据库就像在传统语言中使用的哈希表。你可以通过key来添加、查询或者删除数据，鉴于使用主键访问，所以会获得不错的性能及扩展性。</p><p>产品：Riak、Redis、Memcached、Amazon’s Dynamo、Project Voldemort</p><p>适用的场景：</p><p><strong>储存用户信息，比如会话、配置文件、参数、购物车等等。这些信息一般都和ID（键）挂钩，这种情景下键值数据库是个很好的选择。</strong></p><p>不适用场景</p><p>需要通过值来查询。Key-Value数据库中根本没有通过值查询的途径</p><p>需要储存数据之间的关系。在Key-Value数据库中不能通过两个或以上的键来关联数据。</p><p>需要事务的支持。在Key-Value数据库中故障产生时不可以进行回滚。</p><p>二、 面向文档（Document-Oriented）数据库<br>概述：面向文档数据库会将数据以文档的形式储存。每个文档都是自包含的数据单元，是一系列数据项的集合。<br>每个数据项都有一个名称与对应的值，值既可以是简单的数据类型，如字符串、数字和日期等；也可以是复杂的类型，如有序列表和关联对象。<br>数据存储的最小单位是文档，同一个表中存储的文档属性可以是不同的，数据可以使用XML、JSON或者JSONB等多种形式存储。</p><p>产品：MongoDB、CouchDB、RavenDB</p><p>适用的场景</p><p>日志。企业环境下，每个应用程序都有不同的日志信息。Document-Oriented数据库并没有固定的模式，所以我们可以使用它储存不同的信息。</p><p>分析。鉴于它的弱模式结构，不改变模式下就可以储存不同的度量方法及添加新的度量。</p><p>不适用场景</p><p>在不同的文档上添加事务。Document-Oriented数据库并不支持文档间的事务，如果对这方面有需求则不应该选用这个解决方案。</p><p>三、 列存储数据库<br>概述：列存储数据库将数据储存在列族中，一个列族存储经常被一起查询的相关数据。<br><strong>举个例子，如果我们有一个Person类，我们通常会一起查询他们的姓名和年龄而不是薪资。这种情况下，姓名和年龄就会被放入一个列族中，而薪资则在另一个列族中。</strong></p><p>产品：Cassandra、HBase</p><p>有谁在使用：Ebay （Cassandra）、Instagram （Cassandra）、NASA （Cassandra）、Twitter （Cassandra and HBase）、Facebook （HBase）、Yahoo!（HBase）</p><p>适用的场景</p><p>日志。因为我们可以将数据储存在不同的列中，每个应用程序可以将信息写入自己的列族中。</p><p>博客平台。我们储存每个信息到不同的列族中。举个例子，标签可以储存在一个，类别可以在一个，而文章则在另一个。</p><p>不适用场景</p><p>如果我们需要ACID事务。Vassandra就不支持事务。</p><p>原型设计。如果我们分析Cassandra的数据结构，我们就会发现结构是基于我们期望的数据查询方式而定。在模型设计之初，我们根本不可能去预测它的查询方式，而一旦查询方式改变，我们就必须重新设计列族。</p><p>四、 图（Graph-Oriented）数据库<br>概述：图数据库允许我们将数据以图的方式储存。实体会被作为顶点，而实体之间的关系则会被作为边。<br>比如我们有三个实体，Steve Jobs、Apple和Next，则会有两个“Founded by”的边将Apple和Next连接到Steve Jobs。</p><p>产品：Neo4J、Infinite Graph、OrientDB</p><p><strong>NoSQL 不适合处理多对多的场景，SQL 不适合节点的数据类型多变，且不支持递归的关系查找，关系也没有属性附着</strong></p><p><strong>根据用途分类：</strong></p><p><strong>事务处理数据库（OLTP）</strong>：</p><ul><li>用于处理日常的交易和操作，例如在线交易处理、电子商务等。</li><li>需要快速读写、维护数据的一致性和完整性。</li><li>常见的关系型数据库常用于 OLTP。</li></ul><p><strong>在线分析处理数据库（OLAP）</strong>：</p><ul><li>用于分析大量数据，支持复杂的查询和数据分析。</li><li>重视对数据的高效读取和汇总，用于决策支持和报告。</li><li>数据仓库和一些大数据平台通常用于 OLAP。</li></ul><p>OLTP vs OLAP</p><h2 id="Mysql">Mysql</h2><p><img src="https://cdn.jsdelivr.net/gh/Stan370/stan370.github.io@main/themes/hexo-theme-matery/source/medias/SQL.png" alt="sql"></p><p>MySQL 的架构共分为两层：<strong>Server 层和存储引擎层</strong>，</p><ul><li><strong>Server 层负责建立连接、分析和执行 SQL</strong>。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。</li><li><strong>存储引擎层负责数据的存储和提取</strong>。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，从 MySQL 5.5 版本开始， InnoDB 成为了 MySQL 的默认存储引擎。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 ，且是默认使用，也就是说在数据表中创建的主键索引和二级索引默认使用的是 B+ 树索引。</li></ul><p>执行一条 SQL 查询语句，期间发生了什么？</p><ul><li>连接器：建立连接，管理连接、校验用户身份；</li><li>查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；</li><li>解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；</li><li>执行 SQL：执行 SQL 共有三个阶段：<ul><li>预处理阶段：检查表或字段是否存在；将 <code>select *</code> 中的 `` 符号扩展为表上的所有列。</li><li>优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；</li><li>执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；</li></ul></li></ul><p>连接的过程需要先经过 TCP 三次握手，因为 MySQL 是基于 TCP 协议进行传输的</p><blockquote><p>怎么解决长连接占用内存的问题？</p></blockquote><p>有两种解决方式。</p><p>第一种，<strong>定期断开长连接</strong>。既然断开连接后就会释放连接占用的内存资源，那么我们可以定期断开长连接。</p><p>第二种，<strong>客户端主动重置连接</strong>。MySQL 5.7 版本实现了 <code>mysql_reset_connection()</code> 函数的接口，注意这是接口函数不是命令，那么当客户端执行了一个很大的操作后，在代码里调用 mysql_reset_connection 函数来重置连接，达到释放内存的效果。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</p><h3 id="InnoDB-的架构">InnoDB 的架构</h3><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/ea503cf6-9325-47ab-9fb3-3e33e40583ef/b4b375d5-303b-467c-9bfb-613f15101592/image.png" alt="image.png"></p><p><strong>1. 入口点：Handler API</strong></p><ul><li>这是应用程序与 InnoDB 存储引擎交互的接口。SQL 语句（如选择，插入，更新，删除) 通过此 API 进行处理。</li></ul><p><strong>2.执行引擎：</strong></p><ul><li><strong>MTR1（阅读视图）：</strong> 管理事务的一致读取视图，确保每个事务都能看到数据库的一致快照。</li><li>**MTR2（交易）：**处理事务管理，包括启动、提交和回滚事务。</li><li>**命令：**表示要执行的已解析 SQL 语句（例如从用户中选择 *）。</li></ul><p><strong>3.缓冲池（内存中）：</strong></p><ul><li>**InnoDB的核心：**一个大型内存区域，用于缓存数据库文件中经常访问的数据页。这可最大限度地减少磁盘 I/O 并显著提高性能。</li><li><strong>LRU 列表：</strong> 实施最近最少使用 (LRU) 算法来管理缓存页面。经常使用的页面保留在内存中，而较少使用的页面则被逐出，为新数据腾出空间。</li><li>**空闲列表：**跟踪缓冲池中可用于新数据的页面。</li><li><strong>冲洗清单：</strong> 保存需要写回磁盘的页面（由于修改）。</li><li><strong>自适应哈希索引：</strong> 通过在哈希表中缓存经常访问的索引条目来进一步加快索引查找速度。</li></ul><p><strong>4. 更换缓冲液：</strong></p><ul><li><strong>优化写入：</strong> 内存中的一种特殊数据结构，用于临时存储对二级索引的更改。InnoDB 不会立即将这些更改写入磁盘，而是将它们缓冲在更改缓冲区中。这减少了磁盘 I/O，尤其是对于写入密集型工作负载。</li><li><strong>合并：</strong> 更改缓冲区会定期与磁盘上的二级索引合并，从而使更改持久化。</li></ul><p><strong>5. 撤消缓冲区：</strong></p><ul><li>**支持回滚：**存储有关以前版本数据的信息，允许 InnoDB 撤消事务并提供一致的读取视图。</li></ul><p><strong>6.重做日志缓冲区：</strong></p><ul><li>**预写日志：**内存缓冲区，用于记录对数据库所做的所有更改，在将其写入磁盘之前。这可确保数据持久性和崩溃恢复。</li></ul><p><strong>7.磁盘存储：</strong></p><ul><li>**InnoDB 表空间：**InnoDB 将数据和索引存储在表空间文件中。<ul><li>**系统表空间（.ibd）：**保存数据字典信息，如果配置的话可能包含用户表。</li><li><strong>每个表的文件表空间 (.ibd)：</strong> 每个表都有自己的.ibd 文件，提高了可管理性。</li><li>**通用表空间（diy.ibd）：**允许您创建共享表空间来存储多个表。</li><li><strong>临时表空间（ibtmp1）：</strong> 用于临时表和内部操作。</li></ul></li><li><strong>双写缓冲区：</strong> 一种有助于防止崩溃恢复期间数据损坏的机制。更改首先写入磁盘上的双写缓冲区，然后写入实际数据文件。</li><li><strong>撤消表空间 (.mother)：</strong> 将撤消信息存储在磁盘上。</li><li><strong>重做日志（ib_logfile[0/1]）：</strong> 重做日志的持久存储，对于崩溃恢复至关重要。</li></ul><p><strong>数据流：</strong></p><ol><li><strong>SQL 语句：</strong> 应用程序通过 Handler API 发送 SQL 语句。</li><li><strong>解析和执行：</strong> 执行引擎处理该语句。</li><li><strong>缓冲池：</strong> InnoDB 检查所需数据是否已在缓冲池中。如果没有，它将数据从磁盘读入缓冲池。</li><li><strong>变化：</strong> 如果该语句修改了数据，则更改将应用于缓冲池，记录在重做日志缓冲区中，并可能缓冲在更改缓冲区中。</li><li><strong>重做日志：</strong> 重做日志缓冲区会定期刷新到磁盘上的重做日志文件。</li><li><strong>检查点：</strong> InnoDB 执行检查点，将修改后的页面从缓冲池写入磁盘。</li><li><strong>耐用性：</strong> 重做日志确保所有已提交的更改都安全地保存在磁盘上，即使发生崩溃。</li></ol><p>该架构突出了 InnoDB 的主要特性，如 ACID 属性（原子性、一致性、隔离性、持久性）、崩溃恢复以及通过缓冲和日志记录实现的性能优化。</p><p>查询语句的那一套流程，更新语句也是同样会走一遍：</p><ul><li>客户端先通过连接器建立连接，连接器自会判断用户身份；</li><li>因为这是一条 update 语句，所以不需要经过查询缓存，但是表上有更新语句，是会把整个表的查询缓存清空的，所以说查询缓存很鸡肋，在 MySQL 8.0 就被移除这个功能了；</li><li>解析器会通过词法分析识别出关键字 update，表名等等，构建出语法树，接着还会做语法分析，判断输入的语句是否符合 MySQL 语法；</li><li>预处理器会判断表和字段是否存在；</li><li>优化器确定执行计划，因为 where 条件中的 id 是主键索引，所以决定要使用 id 这个索引；</li><li><strong>Handler API到</strong>执行器负责具体执行，找到这一行，然后更新。</li></ul><p>不过，更新语句的流程会涉及到 undo log（回滚日志）、redo log（重做日志） 、binlog （归档日志）这三种日志：</p><ul><li><strong>undo log（回滚日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>原子性</strong>，主要<strong>用于事务回滚和 MVCC</strong>。</li><li><strong>redo log（重做日志）</strong>：是 Innodb 存储引擎层生成的日志，实现了事务中的<strong>持久性</strong>，主要<strong>用于掉电等故障恢复</strong>；</li><li><strong>binlog （归档日志）</strong>：是 Server 层生成的日志，主要<strong>用于数据备份和主从复制</strong>；</li></ul><p>undo log 和 redo log 用于<strong>记录事务对数据的修改</strong>，以保证原子性和持久性，而 binlog 用于记录数据库的整体变更，MVCC 则用于控制并发，确保读写之间的隔离性。这些机制相互协作，确保数据库在事务执行和并发访问时的一致性和可靠性。</p><p>CREATE INDEX ,ALTER TABLE</p><p>最基本的分页方式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT ... FROM ... WHERE ... ORDER BY ... LIMIT ...</span><br></pre></td></tr></table></figure><p>在中小数据量的情况下，这样的 SQL 足够用了，唯一需要注意的问题就是确保使用了索引。</p><p>举例来说，如果实际 SQL 类似下面语句，那么在 category_id, id 两列上建立复合索引比较好。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM articles WHERE category_id = 123 ORDER BY id LIMIT 50, 10</span><br></pre></td></tr></table></figure><ol><li>分解大连接查询<br>将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样做的好处有：</li></ol><p><strong>缓存之所以能够大幅提高系统的性能，关键在于数据的访问具有局部性，也就是二八定律：「百分之八十的数据访问是集中在 20% 的数据上」。这部分数据也被叫做热点数据。</strong></p><p>让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。<br>分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。<br>减少锁竞争；<br>在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。<br>查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。</p><h3 id="Optimization">Optimization</h3><p><a href="https://developer.aliyun.com/article/1497219">https://developer.aliyun.com/article/1497219</a></p><p>在实际场景中进行 MySQL 查询优化时，通常需要根据具体的业务需求和数据库环境采取针对性的措施。以下是一个系统化的优化步骤和方法：</p><ol><li><strong>了解业务需求与数据特点</strong></li></ol><p><strong>明确查询的业务需求</strong>：了解查询的具体业务需求，包括查询的频率、重要性、响应时间要求等。</p><p><strong>数据分布与访问模式</strong>：分析数据的分布特点（如数据量、表结构、索引情况）和访问模式（读多写少还是读写并重，随机访问还是顺序访问）。</p><ol start="2"><li><strong>分析现有查询性能</strong></li></ol><p><strong>使用 <code>EXPLAIN</code> 分析查询计划</strong>：通过 <code>EXPLAIN</code> 了解查询的执行计划，判断查询是否合理利用了索引，以及优化器whether正确连接表，是否存在全表扫描、文件排序等性能瓶颈。</p><p><strong>慢查询日志</strong>：启用 MySQL 慢查询日志，找出执行时间较长的查询，并集中优化这些查询。mysqldumpslow -s t /path/to/slow.log</p><p><strong>查询执行时间</strong>：使用 <code>SHOW PROFILES</code> 或 <code>SHOW STATUS</code> 查看查询的执行时间、CPU 使用率、磁盘 IO 等性能指标。</p><ol start="3"><li><strong>索引优化</strong></li></ol><p><strong>创建适当的索引</strong>：为查询中的 <code>WHERE</code>、<code>JOIN</code>、<code>ORDER BY</code>、<code>GROUP BY</code> 等条件创建索引，特别是选择性高的列。</p><p><strong>避免冗余索引</strong>：检查并删除冗余或未被使用的索引，以减少维护开销。</p><p><strong>覆盖索引</strong>：通过覆盖索引（即查询字段都在同一索引中）来减少查询的回表操作。</p><ol start="4"><li><strong>查询语句优化</strong></li></ol><p><strong>优化 <code>JOIN</code> 查询</strong>：避免在连接条件中使用函数或计算，尽量使用等值连接（<code>INNER JOIN</code>）而非笛卡尔积（<code>CROSS JOIN</code>）。</p><p><strong>减少返回的数据量</strong>：避免 <code>SELECT *</code>，只选择需要的列；使用 <code>LIMIT</code> 限制返回的行数。</p><p><strong>子查询优化</strong>：将复杂的子查询改写为 <code>JOIN</code> 或使用 <code>EXISTS</code>，避免嵌套子查询带来的性能问题。</p><ol start="5"><li><strong>表结构优化</strong></li></ol><p><strong>规范化与反规范化</strong>：根据查询模式适当选择规范化或反规范化策略，减少表之间的连接次数或查询的复杂度。</p><p><strong>分区表</strong>：对大表进行分区，如按时间或范围分区，可以加快查询性能。</p><p><strong>优化表的数据类型</strong>：选择更合适的字段类型，避免使用过大或不必要的精度，如用 <code>TINYINT</code> 而不是 <code>INT</code>。</p><ol start="6"><li><strong>利用缓存与存储过程</strong></li></ol><p><strong>缓存热点数据</strong>：将高频访问的数据缓存到内存中（如使用 Redis），减少数据库查询次数。</p><p><strong>预计算与存储过程</strong>：对于计算复杂且频繁的查询，可以通过预计算将结果缓存到表中，或者使用存储过程加快查询速度。</p><ol start="7"><li><strong>事务与锁优化</strong></li></ol><p><strong>合理管理事务</strong>：避免长事务或在事务中执行大量查询，尽量缩短事务的执行时间。</p><p><strong>减少锁定范围</strong>：使用合适的锁级别（如行级锁而非表级锁），减少锁争用，提高并发性能。</p><ol start="8"><li><strong>数据维护与归档</strong></li></ol><p><strong>定期归档历史数据</strong>：将不常用的历史数据迁移到冷存储或归档表，减小主表的体积，提升查询性能。</p><p><strong>碎片整理</strong>：定期执行 <code>OPTIMIZE TABLE</code>，整理表碎片，特别是对于频繁更新、删除的表。</p><ol start="9"><li><strong>监控与持续优化</strong></li></ol><p><strong>监控查询性能</strong>：使用监控工具（如 MySQL Enterprise Monitor、Percona Toolkit、Prometheus 等）持续监控查询性能，发现并优化潜在的性能瓶颈。</p><p><strong>调整数据库参数</strong>：根据监控结果调整 MySQL 的配置参数（如 <code>query_cache_size</code>、<code>innodb_buffer_pool_size</code>），优化数据库整体性能。</p><p>实际案例分析</p><p>案例1：优化电商系统中的订单查询</p><p><strong>场景描述</strong>：某电商系统中的订单表非常大，用户经常查询自己最近一年的订单。</p><p><strong>优化方法</strong>：</p><ul><li><strong>分区表</strong>：按年份或月份对订单表进行分区，查询最近一年订单时，只扫描相关分区。</li><li><strong>覆盖索引</strong>：在订单表的 <code>user_id</code>、<code>order_date</code> 上建立联合索引，避免回表。</li><li><strong>缓存</strong>：将最近一年的订单数据缓存到 Redis 中，减少数据库查询。</li></ul><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable constant_">CREATE</span> <span class="variable constant_">TABLE</span> <span class="title function_">orders</span> (</span><br><span class="line">    order_id <span class="variable constant_">INT</span> <span class="variable constant_">PRIMARY</span> <span class="variable constant_">KEY</span>,</span><br><span class="line">    user_id <span class="variable constant_">INT</span>,</span><br><span class="line">    order_date <span class="variable constant_">DATE</span>,</span><br><span class="line">    order_amount <span class="title function_">DECIMAL</span>(<span class="number">10</span>, <span class="number">2</span>),</span><br><span class="line">    product_id <span class="variable constant_">INT</span></span><br><span class="line">);</span><br><span class="line">你有一个查询需要经常获取特定用户在某个日期范围内的订单信息，例如：在没有索引的情况下，</span><br><span class="line">库需要对 orders 表进行**全表扫描**，查找符合条件的记录。这可能会导致查询速度变慢，</span><br><span class="line">尤其是在订单表数据量非常大的情况下。</span><br><span class="line"></span><br><span class="line"><span class="variable constant_">CREATE</span> <span class="variable constant_">INDEX</span> idx_user_order_date </span><br><span class="line"><span class="variable constant_">ON</span> <span class="title function_">orders</span>(user_id, order_date);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>案例2：优化社交平台中的用户动态查询</p><p><strong>场景描述</strong>：社交平台用户的动态查询经常发生，涉及多表连接，如用户信息表、动态表、评论表等。</p><p><strong>优化方法</strong>：</p><ul><li><strong>拆分连接查询</strong>：将用户信息与动态内容的查询分开，先查询用户信息表，再通过 <code>IN()</code> 方式获取动态内容。</li><li><strong>水平拆分</strong>：将动态表按用户 ID 或时间进行水平拆分，减少单表数据量，提升查询效率。</li><li><strong>缓存用户信息</strong>：将用户信息缓存到 Redis 或内存中，减少数据库查询。</li></ul><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="variable constant_">CREATE</span> <span class="variable constant_">TABLE</span> <span class="title function_">comments</span> (</span><br><span class="line">    comment_id <span class="variable constant_">INT</span> <span class="variable constant_">PRIMARY</span> <span class="variable constant_">KEY</span>,</span><br><span class="line">    post_id <span class="variable constant_">INT</span>,</span><br><span class="line">    user_id <span class="variable constant_">INT</span>,</span><br><span class="line">    comment_content <span class="variable constant_">TEXT</span>,</span><br><span class="line">    comment_date <span class="variable constant_">DATETIME</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">假设我们需要查询某个用户的所有动态及其对应的评论，通常会使用如下查询：</span><br><span class="line"></span><br><span class="line"><span class="variable constant_">SELECT</span> u.<span class="property">username</span>, p.<span class="property">post_content</span>, c.<span class="property">comment_content</span></span><br><span class="line"><span class="variable constant_">FROM</span> users u</span><br><span class="line"><span class="variable constant_">JOIN</span> posts p <span class="variable constant_">ON</span> u.<span class="property">user_id</span> = p.<span class="property">user_id</span></span><br><span class="line"><span class="variable constant_">LEFT</span> <span class="variable constant_">JOIN</span> comments c <span class="variable constant_">ON</span> p.<span class="property">post_id</span> = c.<span class="property">post_id</span></span><br><span class="line"><span class="variable constant_">WHERE</span> u.<span class="property">user_id</span> = <span class="number">12345</span></span><br><span class="line"><span class="variable constant_">ORDER</span> <span class="variable constant_">BY</span> p.<span class="property">post_date</span> <span class="variable constant_">DESC</span>;</span><br><span class="line">为了优化上述查询，我们可以在相关表上创建合适的索引。</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span>在 posts 表上创建联合索引，优化 user_id 和 post_date 的查询和排序：</span><br><span class="line"><span class="variable constant_">CREATE</span> <span class="variable constant_">INDEX</span> idx_user_post_date <span class="variable constant_">ON</span> <span class="title function_">posts</span>(user_id, post_date <span class="variable constant_">DESC</span>);</span><br><span class="line">在 comments 表上创建索引以优化 post_id 的连接查询：</span><br><span class="line"><span class="variable constant_">CREATE</span> <span class="variable constant_">INDEX</span> idx_post_id <span class="variable constant_">ON</span> <span class="title function_">comments</span>(post_id);</span><br><span class="line"><span class="number">2.</span>覆盖索引</span><br><span class="line"><span class="variable constant_">CREATE</span> <span class="variable constant_">INDEX</span> idx_user_post_content <span class="variable constant_">ON</span> <span class="title function_">posts</span>(user_id, post_date <span class="variable constant_">DESC</span>, post_content);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>case 3:以<code>%</code>开头的 LIKE 查询会导致索引失效</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 原始查询SELECT * FROM products WHERE product_name LIKE 'abc%';</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 优化后的查询SELECT * FROM products WHERE product_name &gt;= 'abc' AND product_name &lt; 'abd'; or 为文本列添加全文索引</span></span><br></pre></td></tr></table></figure><p>通过以上的步骤和方法，你可以在实际场景中系统地优化 MySQL 查询，提升数据库的响应速度和系统的整体性能。</p><h2 id="索引">索引</h2><p>数据库索引是对数据库表的一列或者多列的值进行排序一种<strong>结构</strong>，使用索引可以快速访问数据表中的特定信息。</p><p><strong>索引的优缺点？</strong></p><p>优点：</p><ul><li>大大加快数据检索的速度。</li><li>将随机I/O变成顺序I/O(因为B+树的叶子节点是连接在一起的)</li></ul><p>缺点：</p><ul><li>从空间角度考虑，建立索引需要占用物理空间</li><li>从时间角度 考虑，创建和维护索引都需要花费时间，例如对数据进行增删改的时候都需要维护索引。</li></ul><p>索引的实现通常使用<strong>Hash索引和B+树</strong>（MySQL常用的索引就是B+树）。除了数据之外，数据库系统还维护为满足特定查找算法的数据结构，这些数据结构以某种方式引用数据，这种数据结构就是索引。简言之，索引就类似于书本，字典的目录。以下是一些关键概念和要点与数据库索引相关：</p><ol><li><strong>索引类型</strong>：<ul><li><strong>B树索引</strong>：是最常见的索引类型，适用于大多数数据库系统。B树索引在树结构中进行数据划分，使得在平均情况下，检索时间复杂度为O(log n)。</li><li><strong>哈希索引</strong>：基于哈希算法，适用于等值查询。但是，哈希索引不适用于范围查询，且不适合于有序数据。</li><li><strong>全文索引</strong>：用于文本数据的高效搜索，支持关键词搜索、模糊查询等。</li><li><strong>空间索引</strong>：用于地理空间数据的索引，可以支持地理坐标查询和范围查询。</li></ul></li></ol><h3 id="什么时候不需要创建索引？"><strong>什么时候不需要创建索引？</strong></h3><ul><li>只读或极少写的表（如配置表、代码表），很少被查询的信息（log</li><li><code>WHERE</code> 条件，<code>GROUP BY</code>，<code>ORDER BY</code> 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。</li><li>字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。</li><li>表数据太少的时候，不需要创建索引；</li><li>经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。</li></ul><p><strong>MySQL 索引</strong><br>索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。InnoDB将磁盘数据建立索引并储存在B+树中</p><ol><li>B+Tree 索引<br>是大多数 MySQL 存储引擎的默认索引类型。</li></ol><p>B树是一种多路平衡查找树</p><p>B+ 树<strong>查询效率更稳定</strong>。因为 B+ 树每次只有访问到叶子节点才能找到对应的数据，而在 B 树中，非叶子节点也会存储数据，这样就会造成查询效率不稳定的情况，有时候访问到了非叶子节点就可以找到关键字，而有时需要访问到叶子节点才能找到关键字。</p><p>其次，B+ 树的查询效率更高，这是因为通常 B+ 树比 B 树更矮胖（阶数更大，深度更低），查询所需要的磁盘 I/O 也会更少。同样的磁盘页大小，B+ 树可以存储更多的节点关键字。</p><p>**B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，**所以 B+Tree 的单个节点的数据量更小，<strong>在相同的磁盘 I/O 次数下，就能查询更多的节点</strong>。 另外，B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。</p><p>2、B+Tree vs Hash， Hash 在做等值查询的时候效率贼快，搜索复杂度为 O(1)。 但是 Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。</p><p>红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，这是因为使用 B+ 树访问磁盘数据有更高的性能。</p><p>Why innodb use b+ tree as index?</p><ol><li><strong>适合范围查询和范围扫描</strong>：B+ 树索引适用于范围查询，例如 <strong><code>BETWEEN</code></strong>、<strong><code>&lt;</code></strong>、<strong><code>&gt;</code></strong> 等操作。B+ 树的特性使得在索引中查找范围更为高效。</li><li><strong>有序性</strong>：B+ 树是一种有序树结构，叶子节点形成了一个有序链表。这使得范围扫描变得更加高效，因为它们能够顺序访问索引页。</li><li><strong>减少磁盘 I/O</strong>：B+ 树索引的叶子节点通常构成一个链表，这有助于减少范围查询时需要读取的磁盘页数量。另外，由于索引节点存储了更多的键值对，相较于其他树结构（如 B 树），在内存中更有可能读取到所需的节点。</li><li><strong>支持聚集索引</strong>：在 InnoDB 中，主键索引（如果定义了主键）被称为聚集索引，它决定了数据的物理存储顺序。B+ 树作为主键索引提供了对表数据物理存储顺序的优化。</li><li><strong>范围分裂</strong>：B+ 树的分裂不会影响叶子节点，只有非叶子节点才会发生分裂。这有助于保持叶子节点的紧凑性，避免了频繁的平衡操作，提高了性能。</li><li><strong>支持多版本并发控制（MVCC）</strong>：InnoDB 使用了 MVCC（多版本并发控制）来处理事务隔离性，而 B+ 树索引能够有效地支持这种并发控制模型。</li></ol><p>二叉搜索树查询效率无疑是最高的，因为平均来说每次比较都能缩小一半的搜索范围  所以表面上来看我们使用 B、B+ 树没有 二叉查找树效率高，但是实际上由于 B、B+ 树降低了树高，减少了磁盘 IO 次数，反而大大提升了速度。</p><ul><li>聚簇索引：<strong>将<a href="https://cloud.tencent.com/product/cdcs?from_column=20065&amp;from=20065">数据存储</a>与索引放到了一块</strong>，找到索引也就找到了数据 聚簇索引的叶子节点就是实际的数据行</li><li>非聚簇索引：一个表可以有多个非聚簇索引，这些索引在逻辑上只是指向数据行的指针。 将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因</li></ul><p>区别就在于叶子节点存放的是什么数据：</p><ul><li>聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点；</li><li>二级索引的叶子节点存放的是主键值，而不是实际数据。</li></ul><p><strong>如果某个查询语句使用了二级索引，但是查询的数据不是主键值，这时在二级索引找到主键值后，需要去聚簇索引中获得数据行，这个过程就叫作「回表」，也就是说要查两个 B+ 树才能查到数据。不过，当查询的数据是主键值时，因为只在二级索引就能查询到，不用再去聚簇索引查，这个过程就叫作「索引覆盖」，也就是只需要查一个 B+ 树就能找到数据。</strong></p><p><strong>什么是覆盖索引和索引下推？</strong></p><p>覆盖索引，也就是 covering index 。 <strong>指的是一个查询语句的执行只用从索引中就能获取到目标数据，不必从数据表中读取</strong>。</p><ol><li><strong>覆盖索引:</strong> 当查询所需的全部列数据都能在索引中找到时，我们称之为覆盖索引。这意味着查询可以直接从索引中获取结果，无需回表查询主键索引。</li></ol><p><code>CREATE INDEX idx_name_age ON users (name, age);</code></p><p>在这个例子中，我们创建了一个名为 <code>idx_name_age</code> 的覆盖索引，它包含了 <code>name</code> 和 <code>age</code> 两个列。如果查询需要根据 <code>name</code> 和 <code>age</code> 来查找用户，那么这个索引就可以覆盖查询，无需访问表本身。</p><p><strong>查询时使用覆盖索引:</strong></p><p>当查询条件能够通过覆盖索引找到所需数据时，MySQL 会自动使用覆盖索引。</p><p><strong>示例查询:</strong></p><p><code>SELECT name, age FROM users WHERE name = 'John' AND age = 30;</code></p><p>在这个例子中，如果 <code>idx_name_age</code> 索引存在，并且包含了 <code>name</code> 和 <code>age</code> 的值，那么 MySQL 会使用覆盖索引来执行查询，直接返回结果，而无需访问表本身</p><p>Mysql5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><p>现在有下面这条查询语句：</p><p><code>select * from t_user  where age &gt; 20 and reward = 100000;</code></p><p>联合索引当遇到范围查询 (&gt;、&lt;) 就会停止匹配，也就是 <strong>age 字段能用到联合索引，但是 reward 字段则无法利用到索引</strong>。具体原因这里可以看这篇：<a href="https://xiaolincoding.com/mysql/index/index_interview.html#%E6%8C%89%E5%AD%97%E6%AE%B5%E4%B8%AA%E6%95%B0%E5%88%86%E7%B1%BB"><strong>索引常见面试题(opens new window)</strong></a></p><p>那么，不使用索引下推（MySQL 5.6 之前的版本）时，执行器与存储引擎的执行流程是这样的：</p><ul><li>Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录；</li><li>存储引擎根据二级索引的 B+ 树快速定位到这条记录后，获取主键值，然后<strong>进行回表操作</strong>，将完整的记录返回给 Server 层；</li><li>Server 层在判断该记录的 reward 是否等于 100000，如果成立则将其发送给客户端；否则跳过该记录；</li><li>接着，继续向存储引擎索要下一条记录，存储引擎在二级索引定位到记录后，获取主键值，然后回表操作，将完整的记录返回给 Server 层；</li><li>如此往复，直到存储引擎把表中的所有记录读完。</li></ul><p>可以看到，没有索引下推的时候，每查询到一条二级索引记录，都要进行回表操作，然后将记录返回给 Server，接着 Server 再判断该记录的 reward 是否等于 100000。而使用索引下推后，判断记录的 reward 是否等于 100000 的工作交给了存储引擎层，过程如下 ：</p><ul><li>Server 层首先调用存储引擎的接口定位到满足查询条件的第一条二级索引记录，也就是定位到 age &gt; 20 的第一条记录；</li><li>存储引擎定位到二级索引后，<strong>先不执行回表</strong>操作，而是先判断一下该索引中包含的列（reward列）的条件（reward 是否等于 100000）是否成立。如果<strong>条件不成立</strong>，则直接<strong>跳过该二级索引</strong>。如果<strong>成立</strong>，则<strong>执行回表</strong>操作，将完成记录返回给 Server 层。</li><li>Server 层在判断其他的查询条件（本次查询没有其他条件）是否成立，如果成立则将其发送给客户端；否则跳过该记录，然后向存储引擎索要下一条记录。</li><li>如此往复，直到存储引擎把表中的所有记录读完。</li></ul><p>可以看到，使用了索引下推后，虽然 reward 列无法使用到联合索引，但是因为它包含在联合索引（age，reward）里，所以直接在存储引擎过滤出满足 reward = 100000 的记录后，才去执行回表操作获取整个记录。相比于没有使用索引下推，节省了很多回表操作。</p><p>InnoDB以页面（Page）为基本单位来组织和管理数据。这些页面是数据库中数据和索引的物理存储单元。</p><p>以下是 InnoDB 页面的一些关键特点：</p><ol><li><strong>固定大小的页</strong>：InnoDB 使用固定大小的数据页（通常是默认大小为 16KB）。每个页都有一个地址和唯一的页号，并用于存储数据、索引、事务日志等信息。</li><li><strong>页类型</strong>：InnoDB 中有不同类型的页，如数据页（Data Page）、索引页（Index Page）、Undo 页（Undo Page）、事务日志页（Log Page）等。每种类型的页用于存储不同的信息。</li><li><strong>数据页</strong>：主要用于存储表的数据。数据页中包含了行记录以及一些管理信息，例如行格式、行的版本信息（用于 MVCC）等。</li><li><strong>索引页</strong>：用于存储索引的节点信息，B+ 树结构中的分支节点和叶子节点。</li><li><strong>管理和缓存</strong>：InnoDB 通过缓冲池（Buffer Pool）来管理数据页的内存缓存。数据页在内存中进行读取和写入，以提高访问速度。LRU（Least Recently Used）算法用于管理缓冲池中的页。</li></ol><p>Explain查询创建的索引是否真正有效</p><p><img src="https://prod-files-secure.s3.us-west-2.amazonaws.com/ea503cf6-9325-47ab-9fb3-3e33e40583ef/84e344c3-a1df-4da0-a8c1-52a0f32055ac/image.png" alt="image.png"></p><p>The <code>EXPLAIN</code> statement in MySQL provides insight into how MySQL executes a query, specifically detailing how tables are joined. The <code>type</code> column in the <code>EXPLAIN</code> output describes the join method used, which indicates the efficiency of the query. Here’s a summary of the join types listed from best to worst:</p><ol><li><strong>system</strong></li></ol><p><strong>Description</strong>: The table has only one row, making it a “system table.” This is a special case of the <code>const</code> join type.</p><p><strong>Efficiency</strong>: Fastest, as there’s only one row to retrieve.</p><ol start="2"><li><strong>const</strong></li></ol><p><strong>Description</strong>: The table has at most one matching row, which is read at the start of the query. The result is treated as a constant by the optimizer.</p><p><strong>Usage</strong>: Typically used when querying a table with a primary key or a unique index where the result is a single row.</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl_name <span class="keyword">WHERE</span> primary_key <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="3"><li><strong>eq_ref</strong></li></ol><p><strong>Description</strong>: For each row from the previous tables, exactly one row is read from this table. This type is used when all parts of a primary key or unique index are used.</p><p><strong>Usage</strong>: Used in join queries where the indexed column is compared with a constant or an expression involving columns from previously read tables.</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> ref_table, other_table <span class="keyword">WHERE</span> ref_table.key_column <span class="operator">=</span> other_table.column;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="4"><li><strong>ref</strong></li></ol><p><strong>Description</strong>: All rows with matching index values are read from this table for each combination of rows from the previous tables. This type is used when the join uses only a leftmost prefix of the key or if the key is not a primary key or unique index.</p><p><strong>Usage</strong>: Applicable when there are multiple rows that match the join condition.</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> ref_table <span class="keyword">WHERE</span> key_column <span class="operator">=</span> expr;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="5"><li><strong>fulltext</strong></li></ol><p><strong>Description</strong>: The join is performed using a <code>FULLTEXT</code> index.</p><p><strong>Usage</strong>: Used when a <code>FULLTEXT</code> index is involved in the query.</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> articles <span class="keyword">WHERE</span> <span class="keyword">MATCH</span> (title, body) AGAINST (<span class="string">'text'</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="6"><li><strong>ref_or_null</strong></li></ol><p><strong>Description</strong>: Similar to <code>ref</code>, but includes an additional search for <code>NULL</code> values. Often used in queries that involve <code>OR</code> conditions with <code>NULL</code>.</p><p><strong>Usage</strong>: When the query checks for both specific values and <code>NULL</code> in the indexed column.</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> ref_table <span class="keyword">WHERE</span> key_column <span class="operator">=</span> expr <span class="keyword">OR</span> key_column <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="7"><li><strong>index_merge</strong></li></ol><p><strong>Description</strong>: Indicates that the <code>Index Merge</code> optimization is used, where multiple indexes are used to satisfy the query.</p><p><strong>Usage</strong>: When the query can use more than one index.</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl_name <span class="keyword">WHERE</span> key1 <span class="operator">=</span> <span class="number">10</span> <span class="keyword">OR</span> key2 <span class="operator">=</span> <span class="number">20</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="8"><li><strong>unique_subquery</strong></li></ol><p><strong>Description</strong>: Replaces <code>eq_ref</code> for some <code>IN</code> subqueries. It functions as an index lookup and replaces the subquery for efficiency.</p><p><strong>Usage</strong>: For efficient <code>IN</code> subqueries.</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl_name <span class="keyword">WHERE</span> id <span class="keyword">IN</span> (<span class="keyword">SELECT</span> primary_key <span class="keyword">FROM</span> single_table <span class="keyword">WHERE</span> <span class="keyword">condition</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="9"><li><strong>index_subquery</strong></li></ol><p><strong>Description</strong>: Similar to <code>unique_subquery</code>, but works for non-unique indexes.</p><p><strong>Usage</strong>: For <code>IN</code> subqueries involving non-unique indexes.</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl_name <span class="keyword">WHERE</span> id <span class="keyword">IN</span> (<span class="keyword">SELECT</span> key_column <span class="keyword">FROM</span> single_table <span class="keyword">WHERE</span> <span class="keyword">condition</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="10"><li><strong>range</strong></li></ol><p><strong>Description</strong>: Only rows within a certain range are retrieved using an index. The index allows for range scans.</p><p><strong>Usage</strong>: When the query involves conditions that limit the result set to a specific range.</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl_name <span class="keyword">WHERE</span> key_column <span class="keyword">BETWEEN</span> <span class="number">10</span> <span class="keyword">AND</span> <span class="number">20</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="11"><li><strong>index</strong></li></ol><p><strong>Description</strong>: Similar to <code>ALL</code>, but instead of scanning the entire table, only the index is scanned. It’s used when the query can be satisfied by the index alone.</p><p><strong>Usage</strong>: When the index is covering (contains all needed columns).</p><p><strong>Example</strong>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> indexed_column <span class="keyword">FROM</span> tbl_name;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="12"><li><strong>ALL</strong></li></ol><ul><li><p><strong>Description</strong>: A full table scan is performed for each combination of rows from the previous tables. This is generally the least efficient join type.</p></li><li><p><strong>Usage</strong>: When no indexes are available, or the query optimizer determines that a full table scan is faster.</p></li><li><p><strong>Example</strong>:</p>  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> tbl_name;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p><strong>Best Types</strong>: <code>system</code>, <code>const</code>, <code>eq_ref</code> are the most efficient, meaning they minimize the number of rows scanned.</p></li><li><p><strong>Good Types</strong>: <code>ref</code>, <code>range</code>, <code>index_merge</code> are generally efficient, depending on the specific query and index design.</p></li><li><p><strong>Less Optimal Types</strong>: <code>index</code>, <code>ALL</code> are less efficient, as they may involve scanning large portions of the table.</p></li></ul><p>Understanding and optimizing these join types is key to improving query performance in MySQL.</p><h2 id="Redis">Redis</h2><p>Redis（Remote Dictionary Server )，即远程字典服务。C语言开发的一个开源的（遵从BSD协议）高性能键值对（key-value）的内存数据库，可以用作数据库、缓存、消息中间件等。它是一种NoSQL（not-only sql，泛指<a href="https://www.zhihu.com/search?q=%E9%9D%9E%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22118561398%22%7D">非关系型数据库</a>）的数据库。</p><p>Redis的基本概念和用法：</p><ol><li><strong>高性能</strong>：Redis完全存储在内存中，这使得它能够以非常高的速度执行读写操作。</li><li><strong>多种数据结构</strong>：除了键值对，Redis还支持字符串、哈希表、列表、集合、有序集合等多种数据结构，允许更灵活的数据操作。</li><li><strong>持久化</strong>：Redis支持将数据持久化到硬盘，以便在重启后恢复数据。它提供了两种持久化方式：快照（Snapshotting）和AOF（Append-Only File）。</li><li><strong>发布/订阅</strong>：Redis提供了发布（publish）和订阅（subscribe）的功能，允许不同部分之间通过消息进行通信。</li><li><strong>事务</strong>：Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化，<strong>Redis 在事务失败时不进行回滚，而是继续执行余下的命令。Redis官方认为事务是原子性的：所有的命令，要么全部执行（但不一定成功），要么全部不执行。</strong></li><li><strong>缓存</strong>：Redis常用于作为缓存层，将频繁访问的数据存储在内存中，以提高读取性能。</li><li><strong>计数器和排行榜</strong>：Redis适用于计数器和排行榜等需要快速处理增减操作的场景。</li><li><strong>分布式锁</strong>：Redis可以用来实现分布式锁，以确保在多个节点上的操作不会互相干扰。</li><li><strong>消息队列</strong>：使用Redis的列表数据结构，可以实现简单的消息队列，用于异步处理任务。</li></ol><p><strong>Redis这么快？</strong></p><blockquote><p>第一：Redis完全基于内存，绝大部分请求是纯粹的内存操作，非常迅速，数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度是O(1)。第二：数据结构简单，对数据操作也简单。第三：采用单线程，避免了不必要的上下文切换和竞争条件，不存在多线程导致的CPU切换，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有死锁问题导致的性能消耗。虽然 Redis 的主要工作（网络 I/O 和执行命令）一直是单线程模型，但是<strong>在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求</strong>，<strong>这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上</strong>。</p></blockquote><p>第四：使用多路复用IO模型，非阻塞IO。</p><p>String、Hash、List、Set、SortedSet。</p><ol><li><strong>Hashes:</strong> Hashes are maps between string fields and string values. They are useful for representing objects with multiple fields, such as user profiles.</li><li><strong>String</strong> data up to 512 MB 。String类型是<strong>二进制安全</strong>的(其本质是将操作输入作为原始的、无任何特殊字符意义的数据流)，意思是 redis 的 string 可以包含任何数据。如数字，字符串，jpg图片或者序列化的对象。</li><li><strong>Lists:</strong> 双向链表实现Lists are ordered collections of strings. You can add elements to the head (left) or tail (right) of a list. Lists can be used for task queues, message queues, and more.</li><li><strong>Sets:</strong> Sets are unordered collections of unique strings. They are used for storing unique values. You can perform set operations like union, intersection, and difference.</li><li><strong>Sorted Sets (ZSETs):</strong> Similar to sets, but each member has a score associated with it. Sorted sets are used for tasks that require ordering by score, such as leaderboards.</li><li><strong>Bitmaps:</strong> Bitmaps are used for bit-level operations. They are often used to represent sets with a large number of unique items in a very memory-efficient way.</li></ol><ul><li>Redis 的字符串表示为 <code>sds(simple dynamic string)</code> ，而不是 C 字符串（以 <code>\0</code> 结尾的 <code>char*</code>）。</li><li>对比 C 字符串， <code>sds</code> 有以下特性：<ul><li>可以高效地执行长度计算（<code>strlen</code>）；</li><li>可以高效地执行追加操作（<code>append</code>）；</li><li>二进制安全；</li></ul></li><li><code>sds</code> 会为追加操作进行优化：加快追加操作的速度，并降低内存分配的次数，代价是多占用了一些内存，而且这些内存不会被主动释放。</li></ul><p>struct sdshdr{<br>int len;//buf数组中已经使用的字节的数量，也就是SDS字符串长度<br>int  free;//buf数组中未使用的字节的数量<br>char buf[];//字节数组，字符串就保存在这里面<br>};</p><p>Redis需要对数据设置过期时间，并采用的是惰性删除+定期删除两种策略对过期键删除。<a href="https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247484386&amp;idx=1&amp;sn=323ddc84dc851a975530090fcd6e2326&amp;chksm=ebd742e3dca0cbf52bc65d430447e639d81cc13e0ac34613edf464dae3950b10e2e1df74dcc5&amp;token=1834317504&amp;lang=zh_CN&amp;scene=21#wechat_redirect">Redis对过期键的策略+持久化</a></p><ol><li><strong>数据过期清除策略</strong>：<ol><li>定期删除：Redis会定期（默认每隔100ms）随机抽取一些设置了过期时间TTL 的键，检查其是否过期，如果有过期的键就删除。这个策略确实是为了避免全局扫描而引入的，以减少CPU负载。</li><li>惰性删除：当你尝试访问某个键时，Redis会检查该键是否已过期，如果已过期，则删除它。这个策略确保在获取键的时候处理过期数据，称为"惰性"，因为它不主动扫描键。</li></ol></li><li>内存淘汰策略：<ul><li>Redis是一个内存数据库，当内存用尽时，需要根据一定的策略来释放一些键以腾出内存空间。这个策略称为内存淘汰策略（Memory Eviction Policy）。</li><li>Redis提供了不同的内存淘汰策略，常见的策略包括：<ul><li>LRU（Least Recently Used）：删除最近最少使用的键。</li><li>LFU（Least Frequently Used）：删除最不频繁使用的键。</li><li>Random（随机淘汰）：随机选择一个键进行删除。</li><li>TTL（Time To Live）：根据键的TTL来删除过期的键。</li></ul></li><li>你可以根据需要在Redis配置文件中选择适合你的内存淘汰策略，默认使用LRU策略。</li></ul></li></ol><p>如果缓存数据<strong>设置的过期时间是相同</strong>的，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存<strong>同时失效</strong>，全部请求到数据库中。</p><p>跳表是<strong>可以实现二分查找的有序链表</strong>。</p><ul><li>Multi开始事务。</li><li>命令入队。</li><li>Exec执行事务。</li></ul><p><strong>持久化</strong></p><p>Reids 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。</p><ul><li><strong>避免额外的检查开销</strong>：因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。</li><li><strong>不会阻塞当前写操作命令的执行</strong>：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</li></ul><p><strong>RDB 快照</strong>：将某一时刻的内存数据，以二进制的方式写入磁盘</p><p>所以，RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据   因此在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。</p><blockquote><p>RDB 做快照时会阻塞线程吗？</p></blockquote><p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：</p><ul><li>执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，<strong>会阻塞主线程</strong>；</li><li>执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>；</li></ul><p>Redis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置：</p><p><code>save 900 1 save 300 10 save 60 10000</code></p><p>别看选项名叫 save，实际上执行的是 bgsave 命令，也就是会创建子进程来生成 RDB 快照文件。 只要满足上面条件的任意一个，就会执行 bgsave，它们的意思分别是：</p><ul><li>900 秒之内，对数据库进行了至少 1 次修改；</li><li>300 秒之内，对数据库进行了至少 10 次修改；</li><li>60 秒之内，对数据库进行了至少 10000 次修改。</li></ul><p>这里提一点，Redis 的快照是<strong>全量快照</strong>，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。所以执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。</p><p><strong>AOF 是一种持久化方式，它通过将 Redis 所有的写操作（包括写命令）以追加（append）的方式记录到一个文件中。AOF 文件包含了可以重放（replay）重建数据集的写命令序列，因此，它记录了数据库状态的完整变更历史。</strong></p><p>缺点：</p><p><strong>文件较大</strong>：由于记录了所有写操作，AOF 文件可能会比 RDB 文件更大。</p><p><strong>恢复速度相对较慢</strong>：在恢复时，可能会因为需要重新执行大量写操作而导致恢复速度较慢。</p><h3 id="缓存">缓存</h3><p><strong>缓存雪崩 Cache avalanche</strong></p><ul><li>Redis挂掉了，请求全部走数据库。</li><li>对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。</li></ul><p>缓存雪崩如果发生了，很可能就把我们的数据库<strong>搞垮</strong>，导致整个服务瘫痪！</p><p><strong>如何解决缓存雪崩？</strong></p><ul><li>解决方法：考虑用<strong>加锁或者队列</strong>的方式保证来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上；还有一个解决方案，原有的失效时间基础上增加一个随机值，这样就会大幅度的<strong>减少缓存在同一时间过期</strong>。</li></ul><p>对于“Redis挂掉了，请求全部走数据库”这种情况，我们可以有以下的思路：</p><ul><li>事发前：实现Redis的<strong>高可用</strong>(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。</li><li>事发中：万一Redis真的挂了，我们可以设置<strong>本地缓存(ehcache)+限流(hystrix)</strong>，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)</li><li>事发后：redis持久化，重启后自动从磁盘上加载数据，<strong>快速恢复缓存数据</strong>。</li></ul><p><strong>缓存击穿   Hotspot data set is invalid</strong></p><p>However, for some hot data with very high requests, once the valid time has passed, there will be a large number of requests falling on the database at this moment, which may cause the database to crash.</p><p>应对缓存击穿可以采取前面说到两种方案：</p><ul><li>互斥锁方案，<strong>保证同一时间只有一个业务线程更新缓存</strong>，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</li><li><strong>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；</strong></li></ul><p><strong>缓存穿透</strong></p><p>是指查询一个一定<strong>不存在的数据</strong>。由于缓存不命中，并且出于容错考虑，如果从<strong>数据库查不到数据则不写入缓存</strong>，这将导致这个不存在的数据<strong>每次请求都要到数据库去查询</strong>，失去了缓存的意义。</p><p>缓存穿透也有两种方案：</p><ul><li>由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter<strong>提前拦截</strong>，不合法就不让这个请求到数据库层！</li><li>当我们从数据库找不到的时候，我们也将这个<strong>空对象设置到缓存里边去</strong>。下次再请求的时候，就可以从缓存里边获取了。</li><li>这种情况我们一般会将空对象设置一个<strong>较短的过期时间</strong>。</li></ul><p>可以发现缓存击穿跟缓存雪崩很相似，如果缓存中的<strong>某个热点数据过期</strong>了，此时大量的请求直接访问数据库就是</p><p><strong>缓存与数据库双写一致</strong></p><p>只要我们设置了<strong>键的过期时间</strong>，我们就能保证缓存和数据库的数据<strong>最终是一致</strong>的。因为只要缓存数据过期了，就会被删除。随后读的时候，因为缓存里没有，就可以查数据库的数据，然后将数据库查出来的数据写入到缓存中。</p><p>除了设置过期时间，我们还需要做更多的措施来<strong>尽量避免</strong>数据库与缓存处于不一致的情况发生。分布式环境下非常容易出现缓存和数据库间数据一致性问题，针对这一点，如果项目对缓存的要求是强一致性的，那么就不要使用缓存。我们只能采取合适的策略来降低缓存和数据库间数据不一致的概率，而无法保证两者间的强一致性。合适的策略包括合适的<strong>缓存更新策略</strong>，更新数据库后<strong>及时更新缓存、缓存失败时增加重试机制。</strong></p><p>两种策略各自有优缺点：</p><ul><li>先删除缓存，再更新数据库</li><li>在高并发下表现不如意，在原子性被破坏时表现优异</li><li>先更新数据库，再删除缓存(<code>Cache Aside Pattern</code>设计模式)</li></ul><p><strong>缓存更新的策略</strong></p><ul><li>Cache Aside（旁路缓存）策略；</li><li>Read/Write Through（读穿 / 写穿）策略；</li><li>Write Back（写回）策略；</li></ul><p>主要分为两类 <strong>Cache-Aside</strong> 和 <strong>Cache-As-SoR。</strong> SoR 即「System Of Record，记录系统」，表示数据库。 实际开发中，Redis 和 MySQL 的更新策略用的是 Cache Aside，另外两种策略主要应用在计算机系统里</p><ul><li><strong>Cache Aside 策略</strong>：应用程序直接<strong>与数据库和缓存交互</strong>，并负责维护缓存的一致性。这种策略简单易用，但是需要维护缓存和数据库的一致性，可能出现缓存穿透或缓存雪崩的问题，一般采用<strong>延迟双删</strong>来保证最终一致性</li></ul><blockquote><p>查询：先查询缓存，如果缓存中没有，则查询数据库，并将结果写入缓存</p><p>更新：先更新数据库，然后删除缓存或者更新缓存</p></blockquote><p>Cache-As-SoR **可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。**数据库由缓存代理，缓存未命中时由缓存加载数据库数据然后应用从缓存读，写数据时更新完缓存后同步写数据库。应用只感知缓存而不感知数据库。</p><ul><li><strong>Read/Write Through 策略</strong>：应用程序<strong>只和缓存交互</strong>，使用缓存与数据库交互.  better integrity and consistency, less performance</li></ul><blockquote><p>查询：先查询缓存，如果缓存中没有，则缓存从数据库中加载数据，并写入缓存</p><p>更新：先更新缓存，再由缓存同步更新数据库</p></blockquote><ul><li><strong>Write Behind 策略</strong>：应用程序<strong>只和缓存交互</strong>。回写式，数据写入缓存即可返回，缓存内部会异步的去更新数据源，这样好处是<strong>写操作特别快</strong>，因为只需要更新缓存。并且缓存内部可以合并对相同数据项的多次更新，但是带来的问题就是<strong>数据不一致</strong>，可能发生写丢失。</li><li><strong>Refresh-Ahead 策略</strong>：应用程序<strong>只和缓存交互</strong>，由后台服务与数据库交互</li></ul><blockquote><p>查询：只查询缓存</p><p>更新：由后台服务<strong>自动从数据库中查询最新的数据</strong>，并将数据写入缓存中，</p></blockquote><p><strong>性能</strong></p><p><code>Cache Aside</code> 的性能较高，它<strong>只在缓存未命中</strong>时才访问数据库</p><p><code>Read/Write Through</code> 的性能较低，它在<strong>每次读写时都需要访问数据库</strong></p><p><code>Write Behind Caching</code> 的性能最高，它<strong>只在缓存未命中</strong>时才访问数据库，而<strong>写入操作是异步的</strong></p><p><code>Refresh-Ahead</code> 的性能介于 <code>Cache Aside</code> 和 <code>Write Behind Caching</code> 之间，它<strong>只在即将过期时</strong>才访问数据库，并且<strong>写入操作也是异步的</strong></p><p><strong>数据一致性</strong></p><p><code>Cache Aside</code> 的数据一致性较低，它<strong>只在缓存未命中时</strong>才更新缓存，而写入操作则是<strong>直接更新数据库</strong>，<strong>并将缓存中的数据删除或更新</strong></p><p><code>Read/Write Through</code> 的数据一致性最高，它在<strong>每次读写时都</strong>更新数据库和缓存</p><p><code>Write Behind Caching</code> 的数据一致性最低，它<strong>只在缓存未命中</strong>时才更新缓存，而写入操作则是先更新缓存，并在<strong>异步更新数据库</strong>，有较大的延迟。</p><p><code>Refresh-Ahead</code> 的数据一致性介于 <code>Read/Write Through</code> 和 <code>Cache Aside</code> 之间，它保证了缓存中的数据<strong>总是最新</strong>的，但是有一定的延迟</p><p>Redis 持久化策略，其实就是为了减少服务宕机后数据丢失，以及快速恢复数据，也算是支持高可用的一种实现。 除此之外，Redis 还提供了其它几种方式来保证**系统高可用，**业务中最常用的莫过于主从同步（也称作主从复制）、Sentinel 哨兵机制以及 Cluster 集群。</p><h3 id="主从复制"><strong>主从复制</strong></h3><p>Redis 同时支持主从复制和读写分离：一个 Redis 实例作为主节点 Master，负责写操作。其它实例（可能有 1 或多个）作为从节点 Slave，负责复制主节点的数据。</p><p>主节点 Master 数据更新：Master 负责处理所有的写操作，包括写入、更新和删除等。 数据同步：写操作在 Master 上执行，然后 Master 将写操作的结果同步到所有从节点 Slave 上。 从节点 Slave 数据读取：Slave 负责处理读操作，例如获取数据、查询等。 数据同步：Slave 从 Master 复制数据，并在本地保存一份与主节点相同的数据副本。</p><p>2.2 为什么要读写分离 1）防止并发2）易于扩展 我们都知道，大部分使用 Redis 的业务都是读多写少的。所以，我们可以根据业务量的规模来确定挂载几个从节点 Slave，当缓存数据增大时，我们可以很方便的扩展从节点的数量，实现弹性扩展。 同时，读写分离还可以实现数据备份和负载均衡，从而提高可靠性和性能。 3）高可用保障 不仅如此，Redis 还可以手动切换主从节点，来做故障隔离和恢复。</p><p><strong>主从复制过程</strong></p><ul><li>从服务器连接主服务器，发送SYNC命令；主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；从服务器完成对快照的载入，开始接受命令请求，并执行来自主服务器缓冲区的写命令；（从服务器初始化完成）主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令（从服务器初始化完成后的操作）</li><li>一般主从配置可以缓解请求压力，做读写分离，写服务器不开启持久化，从服务器开启，从服务器还负责读取的操作，而且从服务器可以是多个，可以有效缓解主服务器的压力；但是坏处在于，如果主服务器宕机，无法自动切换恢复；</li></ul><p>bgsave 过程中，Redis 依然<strong>可以继续处理操作命令</strong>的，也就是数据是能被修改的，关键的技术就在于**写时复制技术（Copy-On-Write, COW）。**执行 bgsave 命令的时候，会通过 fork() 创建子进程</p><p><strong>写入时复制</strong>（英语：<strong>Copy-on-write</strong>，简称<strong>COW</strong>）是一种计算机<a href="https://zh.wikipedia.org/wiki/%E7%A8%8B%E5%BC%8F%E8%A8%AD%E8%A8%88">程序设计</a>领域的优化策略。其核心思想是，如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是<a href="https://zh.wikipedia.org/wiki/%E9%80%8F%E6%98%8E">透明</a>的。此作法主要的优点是如果调用者没有修改该资源，就不会有副本（private copy）被建立，因此多个调用者只是读取操作时可以共享同一份资源。</p><p>Redis的<strong>持久化策略</strong></p><p>有两种：1、RDB：快照形式是直接把内存中的数据保存到一个dump的文件中，定时保存，保存策略。2、AOF：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。Redis默认是快照RDB的持久化方式。当Redis重启的时候，它会优先使用<a href="https://www.zhihu.com/search?q=AOF%E6%96%87%E4%BB%B6&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22118561398%22%7D">AOF文件</a>来还原数据集，因为AOF文件保存的数据集通常比RDB文件所保存的数据集更完整。你甚至可以关闭<a href="https://www.zhihu.com/search?q=%E6%8C%81%E4%B9%85%E5%8C%96%E5%8A%9F%E8%83%BD&amp;search_source=Entity&amp;hybrid_search_source=Entity&amp;hybrid_search_extra=%7B%22sourceType%22%3A%22article%22%2C%22sourceId%22%3A%22118561398%22%7D">持久化功能</a>，让数据只在服务器运行时存。</p><p><strong>集群原理</strong></p><p>在Redis集群中，所有Redis节点彼此互联，节点内部使用二进制协议优化传输速度和带宽。当一个节点宕机后，集群中超过半数节点检测失效才认为该节点失效。不同于Tomcat集群需要反向代理服务器，Redis集群中任意节点都可以直接和Java客户端连接。Redis集群上的数据分配采用哈希槽。Redis集群中内置了16384个哈希槽，当有数据要存储时，Redis会首先使用CRC16算法对key进行计算，将计算结果对16384取余，这样每个key都会对应一个取值在16384之间的哈希槽。开发者可根据每个Redis实例性能来调整每个Redis实例上哈希槽的分布范围。</p><p>DELETE FROM messages WHERE create &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH);</p><p>一般业务刚上线的时候，直接使用单机数据库就够了，但是随着用户量上来之后，系统就面临着大量的写操作和读操作，单机数据库处理能力有限，容易成为系统瓶颈。由于存在读写锁冲突，并且很多大型互联网业务往往<strong>读多写少</strong>，读操作会首先成为数据库瓶颈，我们希望消除读写锁冲突从而提升数据库整体的读写能力。</p><p>那么就需要采用读写分离的数据库集群方式，一主多从，主库会同步数据到从库。写操作都到主库，读操作都去从库。</p><p>读写分离的主要思想是将数据库的读和写操作分开处理，从而减轻主数据库的负担，提高整个系统的并发能力和性能。</p><p>常见的读写分离架构包括：</p><ol><li><strong>主从复制</strong>：通过在主数据库上进行写操作，并将写操作同步到多个从数据库（只读副本）。读操作则可以在从数据库上执行，分担了主数据库的读压力。</li><li><strong>Sharding分片</strong>：按照某种规则（例如按照用户ID、地理位置等）将数据分散存储在不同的数据库节点上，每个节点负责一部分数据。这样可以水平扩展数据库系统，提高了系统整体的读写能力。</li></ol><p>Mysql<strong>表格设计</strong>？</p><p>平衡范式与冗余(效率优先；往往牺牲范式)拒绝3B(拒绝大<a href="https://so.csdn.net/so/search?q=sql%E8%AF%AD%E5%8F%A5&amp;spm=1001.2101.3001.7020">sql语句</a>：big sql、拒绝大事务：big transaction、拒绝大批量：big batch);</p><p>第一范式（1NF）是指数据库表的<strong>每一列都是不可分割的基本数据项</strong>，同一列中不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。如果出现重复的属性，就可能需要定义一个新的实体，新的实体由重复的属性构成，新实体与原实体之间为一对多关系。在第一范式（1NF）中表的每一行只包含一个实例的信息。简而言之，第一范式就是无重复的列。</p><p>说明：在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，<strong>不满足第一范式（1NF）的数据库就不是关系数据库。</strong></p><p>第一范式存在问题：冗余度大、会引起修改操作的不一致性、数据插入异常、数据删除异常。</p><ol><li><strong>冗余度大</strong>：<ul><li>1NF要求每列都是原子性的，这可能导致数据的冗余。当数据重复存储在不同的表中，会增加存储空间，增加了数据不一致性的风险。</li></ul></li><li><strong>修改操作的不一致性</strong>：<ul><li>如果某个信息在多个地方存储，当需要修改这个信息时，需要在所有存储位置进行同样的修改。如果有一个位置的信息修改了而其他位置未修改，数据就会不一致。</li></ul></li><li><strong>数据插入异常</strong>：<ul><li>数据插入异常指的是由于表中的部分列被留空或无法插入新行，而导致无法插入需要的数据。在1NF中，如果表中的某列是必填项，而其他列不是，当插入新行时，可能会出现无法插入数据的情况。</li></ul></li><li><strong>数据删除异常</strong>：<ul><li>当从表中删除数据时，可能会意外删除其他相关数据，从而造成数据丢失。这种情况在存在多个依赖于相同键的表时较为常见。如果删除某个主键相关的信息，可能会导致其他数据不完整或不一致。</li></ul></li></ol><p><strong>第二范式</strong>，强调记录的唯一性约束，数据表必须有一个主键，并且没有包含在主键中的列必须<strong>完全依赖</strong>于主键，而不能只依赖于主键的一部分。</p><p>举例：</p><p>学生信息（学号，身份证，姓名）学号-》姓名 ，学号，身份证-》姓名 所以姓名部分依赖于（学号，身份证）该表不是2NF。</p><p><strong>2.3 3NF 第三范式</strong></p><p>第三范式，强调数据属性冗余性的约束，也就是非主键列必须直接依赖于主键。也就是消除了非主属性对码的传递函数依赖的2NF。</p><p>BCNF消除主键的某一列会依赖于主键的其他列</p><p><strong>4NF 第四范式</strong></p><p>非主属性不应该有多值。如果有多值就违反了第四范式。4NF是限制关系模式的属性间不允许有非平凡且非函数依赖的多值依赖。</p><p>举例：用户联系方式表(用户id，固定电话，移动电话)，其中用户id是主键，这个满足了BCNF,但是一个用户有可能会有多个固定电话或者多个移动电话，那么这种设计就不合理，应该改为(用户id，联系方式类型，电话号码)。</p><p>说明：如果只考虑函数依赖，关系模式规范化程度最高的范式是BCNF;如果考虑多值依赖则是4NF。</p><p>先建立索引或者分区，然后再查询</p><h3 id="事务">事务</h3><p>数据库环境中的事务有两个主要目的：</p><ol><li>提供可靠的工作单元，即使在系统发生故障的情况下，也可以从故障中正确恢复并保持数据库的一致性。例如：当执行过早且意外停止（完全或部分）时，在这种情况下，数据库上的许多操作仍未完成，状态不明确。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;Database&lt;/h1&gt;
&lt;p&gt;数据库是一个存储数据的系统，它可以存储大量的数据，并且能够高效地检索这些数据。数据库中的数据被组织成表格的形式，这些表格称为表。表中的每一行代表一个记录，每一列代表一个字段。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于数据库而言，重要的</summary>
      
    
    
    
    
    <category term="数据库" scheme="https://stan370.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统中的一致性模型</title>
    <link href="https://stan370.github.io/2024/07/21/Distributed/"/>
    <id>https://stan370.github.io/2024/07/21/Distributed/</id>
    <published>2024-07-21T11:43:33.000Z</published>
    <updated>2025-03-19T12:12:05.245Z</updated>
    
    <content type="html"><![CDATA[<h1>一致性模型概述</h1><p>一致性模型是分布式系统中对数据读写操作顺序和结果的约定。不同的一致性模型定义了在不同情况下系统对数据的一致性保证程度。而其之所以这么重要正是因为其复杂而又直接关系到一个分布式系统的正确性，所以值得被反复讨论。</p><p>在开发单机多线程程序的时候，不同线程如果不加任何措施同时对同一片内存进行操作会冲突造成不可预知的后果。分布式系统同样是个并发系统，这个问题依旧，不同的结点同时对同一个数据进行修改同样会造成不可预知的后果，造成数据一致性被破坏，同时加上分布式系统中可用性和性能等因素，使得这一问题更加棘手。</p><p>对于并发操作来说，其实本质上是一个顺序的操作序列，只是不同进程的操作被交织在了一起，而一致性模型就是用于判断这个操作序列是否合法。因此，一致性模型其实就是一种约定，如果一个系统声称满足某个一致性模型，那么它就保证了在一定条件下，对于数据的读写操作都是可预期的。</p><p>这边引用 <a href="https://jepsen.io/consistency">Jepson</a> 的一张关于一致性模型的图</p><p><img src="https://zinglix.xyz/img/in-post/Consistency-model/1.png" alt=""></p><p>这张图中，从下往上，模型对于操作序列的要求更严格，称为更强（stronger）的一致性模型，反之要求则更宽松，称为更弱（weaker）。而箭头 <code>A-&gt;B</code> 则表示满足 B 则一定满足 A，也就是说满足 B 的操作是满足 A 的操作的一个子集。</p><p>根据 CAP 理论，当追求 C 时势必需要放弃 A 或 P。如果发生了网络错误，图中红色的表示必须暂停服务，黄色的表示客户端仍可以继续在同一个未发生错误的结点上继续工作，蓝色的表示即使网络完全错误，仍可以切换至正常的结点上继续工作。</p><p>在对每个模型进行介绍之前，还需先明确最理想的状态是怎么样的，也就是一致性模型所需要保证的目标。最强的一致性模型自然是图中位于最上方的 Strict Serializability。其实说来简单，就是单机执行的状态，所有事务的子操作不交错，根据实际发生的次序顺序执行。这其实正好对应了图中指向它的 Serializability 和 Linearizable，背后其实对应的是 <strong>隔离性（数据库事务 ACID 中的 I）和一致性（分布式系统 CAP 的 C）</strong>。</p><h2 id="隔离性">隔离性<a href="#%E9%9A%94%E7%A6%BB%E6%80%A7"></a></h2><p>隔离性指的是各个事务执行过程相互隔离，防止并发执行导致数据不一致。在解释各个隔离性的模型之前，让我们首先看看少了隔离性会遇到什么样的问题。</p><h3 id="潜在的问题">潜在的问题<a href="#%E6%BD%9C%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"></a></h3><h4 id="P0-Dirty-Write">P0 Dirty Write<a href="#p0-dirty-write"></a></h4><p>Dirty Write 就是一个事务修改了另一个尚未提交的事务已经修改的值，如下</p><pre><code>+------+-------+-------+-------+-------+| T1   | Wx(1) |       |       | Wy(1) |+------+-------+-------+-------+-------+| T2   |       | Wx(2) | Wy(2) |       |+------+-------+-------+-------+-------+| x(0) | 1     | 2     | 2     | 2     |+------+-------+-------+-------+-------+| y(0) | 0     | 0     | 2     | 1     |+------+-------+-------+-------+-------+</code></pre><p>T2 的 Wx(2) 覆盖了 T1 的 Wx(1)，造成该修改的丢失。</p><h4 id="P1-Dirty-Read">P1 Dirty Read<a href="#p1-dirty-read"></a></h4><p>Dirty Read 指一个事务读取到了另一个执行到一半的事务中修改的值，如下</p><pre><code>+-------+--------+--------+--------+--------+| T1    | Wx(40) |        |        | Wy(60) |+-------+--------+--------+--------+--------+| T2    |        | Rx(10) | Ry(50) |        |+-------+--------+--------+--------+--------+| x(50) | 40     | 10     | 10     | 10     |+-------+--------+--------+--------+--------+| y(50) | 50     | 50     | 50     | 60     |+-------+--------+--------+--------+--------+</code></pre><p>假设原本 x 与 y 存款均为50，现在 T1 负责 x 向 y 转账 10，T2 负责读取 x 和 y 的存款。那么无论如何转账，两人存款之和必定是 100，Dirty Read 使得这一约束无法得到保证。</p><h4 id="P2-Non-Repeatable-Read">P2 Non-Repeatable Read<a href="#p2-non-repeatable-read"></a></h4><p>Non-Repeatable Read 也称 Fuzzy Read，指一个事务读取过程中读到了另一个事务更新后的结果，如下</p><pre><code>+-------+--------+--------+--------+--------+| T1    | Rx(50) |        |        | Ry(60) |+-------+--------+--------+--------+--------+| T2    |        | Wx(40) | Wy(60) |        |+-------+--------+--------+--------+--------+| x(50) | 50     | 40     | 40     | 40     |+-------+--------+--------+--------+--------+| y(50) | 50     | 50     | 60     | 60     |+-------+--------+--------+--------+--------+</code></pre><p>同样转账的例子，T1 读取到一半时插入 T2 的更新操作，导致约束条件再次被破坏。</p><h4 id="P3-Phantom">P3 Phantom<a href="#p3-phantom"></a></h4><p>Phantom 指的是某一事务 A 先挑选出了符合一定条件的数据，之后另一个事务 B 修改了符合该条件的数据，此时 A 再进行的操作都是基于旧的数据，从而产生不一致，例如</p><pre><code>+----------------+--------+-----------+-----------+-----------+| T1             | {a, b} |           |           | R(3)      |+----------------+--------+-----------+-----------+-----------+| T2             |        | W(c)      | W(3)      |           |+----------------+--------+-----------+-----------+-----------+| Employees      | {a, b} | {a, b, c} | {a, b, c} | {a, b, c} |+----------------+--------+-----------+-----------+-----------+| Employee Count | 2      | 2         | 3         | 3         |+----------------+--------+-----------+-----------+-----------+</code></pre><p>T1 前后两次读由于 T2 的存在打破了约束，使得两次读的结果不一致。</p><h4 id="P4-Lost-Update">P4 Lost Update<a href="#p4-lost-update"></a></h4><p>Lost Update 指的是更新被另一个事务覆盖，例如</p><pre><code>1234567+--------+-----+---------+---------+| T1     |     |         | Wx(110) |+--------+-----+---------+---------+| T2     |     | Wx(120) |         |+--------+-----+---------+---------+| x(100) | 100 | 120     | 110     |+--------+-----+---------+---------+</code></pre><p>T2 执行于 T1 执行过程中间，两个事务之间并没有发生任何 Dirty Read，但 T2 的更新被丢失了，相当于并没有被执行。</p><h4 id="P4C-Cursor-Lost-Update">P4C Cursor Lost Update<a href="#p4c-cursor-lost-update"></a></h4><p>Cursor Lost Update 与前者类似，只是发生于 cursor 的操作过程之中，例如</p><pre><code>1234567+--------+----------+---------+----------+| T1     | RCx(100) |         | Wx(110)  |+--------+----------+---------+----------+| T2     |          | Wx(75)  |          |+--------+----------+---------+----------+| x(100) | 100      | 75      | 110      |+--------+----------+---------+----------+</code></pre><p>RCx 表示通过 cursor 读取，这样导致 T2 的更新操作被丢失了。</p><h4 id="A5A-Read-Skew">A5A Read Skew<a href="#a5a-read-skew"></a></h4><p>Read Skew 由于事务的交叉导致读取到了不一致的数据，例如转账的例子</p><pre><code>+-------+--------+--------+--------+--------+| T1    | Rx(50) |        |        | Ry(75) |+-------+--------+--------+--------+--------+| T2    |        | Wx(25) | Wy(75) |        |+-------+--------+--------+--------+--------+| x(50) | 50     | 25     | 25     | 25     |+-------+--------+--------+--------+--------+| y(50) | 50     | 50     | 75     | 75     |+-------+--------+--------+--------+--------+</code></pre><h4 id="A5B-Write-Skew">A5B Write Skew<a href="#a5b-write-skew"></a></h4><p>Write Skew 指两个事务同时读取到了一致的数据，然后分别进行了满足条件的修改，但最终结果破坏了一致性，例如</p><pre><code>+-------+--------+--------+--------+--------+| T1    | Rx(30) | Ry(10) | Wy(60) |        |+-------+--------+--------+--------+--------+| T2    | Rx(30) | Ry(10) |        | Wx(50) |+-------+--------+--------+--------+--------+| x(30) | 30     | 30     | 30     | 50     |+-------+--------+--------+--------+--------+| y(10) | 10     | 10     | 60     | 60     |+-------+--------+--------+--------+--------+</code></pre><p>要求 x+y &lt;= 100，T1 和 T2 都读取到了符合条件的数据，并在要求范围内修改了数据，但最后结果破坏了约束。</p><h3 id="隔离级别">隔离级别<a href="#%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB"></a></h3><p>想要避免上述问题，付出的代价是不同的。为了确定上述情况是否会发生，同时能够根据场景选择付出怎么样的代价，因此产生了隔离级别这一概念，用于指明可能发生的问题，共有如下数种隔离级别：</p><ul><li><strong>Read Uncommitted</strong>：事务执行过程中能够读到未提交的修改。</li><li><strong>Read Committed</strong>：事务执行过程中能够读到已提交的修改。</li><li><strong>Cursor Stability</strong>：使用 cursor 读取某个数据时，这个不能被其他事务修改直至 cursor 释放或事务结束。</li><li><strong>Monotonic Atomic View</strong>：在 Read Committed 的基础上加上了原子性的约束，观测到其他事务的修改时会观察到完整的修改。</li><li><strong>Repeatable Read</strong>：即使其他事务修改了数据，重复读取都会读到一样的数据。</li><li><strong>Snapshot</strong>：每个事务在独立、一致的 snapshot 上进行操作，直至提交后其他事务才可见。</li><li><strong>Serializable</strong>：事务按照一定的次序顺序执行。</li></ul><p>对应的可能发生的问题如下</p><p></p><p>P0</p><p>P1</p><p>P4C</p><p>P4</p><p>P2</p><p>P3</p><p>A5A</p><p>A5B</p><p>Read Uncommitted</p><p>NP</p><p>P</p><p>P</p><p>P</p><p>P</p><p>P</p><p>P</p><p>P</p><p>Read Committed</p><p>NP</p><p>NP</p><p>P</p><p>P</p><p>P</p><p>P</p><p>P</p><p>P</p><p>Cursor Stability</p><p>NP</p><p>NP</p><p>NP</p><p>SP</p><p>SP</p><p>P</p><p>P</p><p>SP</p><p>Repeatable Read</p><p>NP</p><p>NP</p><p>NP</p><p>NP</p><p>NP</p><p>P</p><p>NP</p><p>NP</p><p>Snapshot</p><p>NP</p><p>NP</p><p>NP</p><p>NP</p><p>NP</p><p>SP</p><p>NP</p><p>P</p><p>Serializable</p><p>NP</p><p>NP</p><p>NP</p><p>NP</p><p>NP</p><p>NP</p><p>NP</p><p>NP</p><blockquote><p>NP(Not Possible)：不可能发生</p><p>SP(Sometimes Possible)：有时候可能发生</p><p>P(Possible)：会发生</p></blockquote><p>MySQL 中只采用了 Read Uncommitted、Read Committed、Repeatable Read、Serializable 四种级别。</p><h2 id="一致性">一致性<a href="#%E4%B8%80%E8%87%B4%E6%80%A7"></a></h2><p>隔离性并不保证其他节点看到数据的顺序，这一点由一致性来进行保证。一致性指的是所有结点都能访问到最新的数据副本，并因此衍生出了不同级别的一致性，以表示所能看到的数据发生的顺序。<br>强一致性（Strong Consistency）：</p><p>严格串行化（Strict Serializability）：<br>定义：所有操作都可以看作是按照某个全局的、线性的顺序执行的，且每个操作的效果立刻对后续操作可见。<br>应用场景：强一致性要求很高的系统，如银行交易系统。<br>线性化（Linearizability）：<br>定义：每个操作在某个点上“原子的”发生，且这个点必须在操作开始和结束之间。<br>应用场景：需要保证最新写入立刻对所有后续读可见的系统，如某些分布式数据库和文件系统。<br>弱一致性（Weak Consistency）：</p><p>最终一致性（Eventual Consistency）：<br>定义：如果没有新的更新操作，系统最终会达到一致状态，即所有副本的数据最终会收敛到相同的状态。<br>应用场景：高可用性和性能要求高的系统，如 DNS、CDN 等。<br>因果一致性（Causal Consistency）：</p><p>定义：如果一个操作影响了另一个操作，那么前一个操作的结果必须在后一个操作之前可见。<br>应用场景：需要保证因果关系的系统，如社交网络中的动态更新。<br>序列一致性（Sequential Consistency）：</p><p>定义：所有操作按照某个顺序执行，但这个顺序不必与实际时间顺序一致，只需对所有进程可见的顺序一致。<br>应用场景：需要保证全局操作顺序一致性的系统，如某些分布式存储系统。<br>弱化的隔离级别：</p><p>读已提交（Read Committed）：<br>定义：只能读取已经提交的数据，但不同事务之间的操作顺序不一定一致。<br>应用场景：数据库系统中，读已提交是一个常见的隔离级别。<br>可重复读（Repeatable Read）：<br>定义：在同一事务内多次读取同一数据项，结果必须一致。<br>应用场景：需要避免“不可重复读”问题的系统，如某些事务处理系统</p><ul><li><strong>Writes Follow Reads</strong>：如果一个进程读到了操作 <em>w1</em> 修改的值，并之后执行了操作 <em>w2</em>，那么 <em>w2</em> 只有在 <em>w1</em> 后可见，也就是说如果看到了 <em>w2</em> 那么一定看到了 <em>w1</em>。</li><li><strong>Monotonic Reads</strong>：如果一个进程进行了读取 <em>r1</em>，再进行 <em>r2</em>，那么 <em>r2</em> 不可能看到 <em>r1</em> 发生前的数据。</li><li><strong>Monotonic Writes</strong>：如果一个进程进行了写入 <em>w1</em>，再进行 <em>w2</em>，那么其他进程都会看到 <em>w1</em> 发生于 <em>w2</em> 之前。</li><li><strong>Read Your Writes</strong>：如果一个进程进行了写入 <em>w</em>，再进行读取 <em>r</em>，那么 <em>r</em> 一定能看到 <em>w</em> 所进行的修改。</li><li><strong>PRAM</strong> (Pipeline Random Access Memory)：单进程的写操作被观察到都是顺序的，不同进程间的写操作被观察到的顺序则可能不同。PRAM = Monotonic Writes + Monotonic Reads + Read Your Writes.</li><li><strong>Casual</strong>：存在因果关系的操作在任何地方被观察的顺序是一致的。</li><li><strong>Sequential</strong>：保证操作一定按一定顺序发生，且任何地方观测到的都是一致的。</li><li><strong>Linearizable</strong>：所有操作都按操作发生的时间顺序原子地发生。</li></ul><h2 id="参考">参考<a href="#%E5%8F%82%E8%80%83"></a></h2><ul><li><a href="https://www.jianshu.com/p/3673e612cce2">一致性模型</a></li><li><a href="https://jepsen.io/consistency">Jepson</a></li><li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf">A Critique of ANSI SQL Isolation Levels</a></li></ul><hr><h5 id="CATALOG"><a href="#">CATALOG</a></h5><ul><li><a href="#%E9%9A%94%E7%A6%BB%E6%80%A7">隔离性</a></li><li><a href="#%E6%BD%9C%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98">潜在的问题</a></li><li><a href="#p0-dirty-write">P0 Dirty Write</a></li><li><a href="#p1-dirty-read">P1 Dirty Read</a></li><li><a href="#p2-non-repeatable-read">P2 Non-Repeatable Read</a></li><li><a href="#p3-phantom">P3 Phantom</a></li><li><a href="#p4-lost-update">P4 Lost Update</a></li><li><a href="#p4c-cursor-lost-update">P4C Cursor Lost Update</a></li><li><a href="#a5a-read-skew">A5A Read Skew</a></li><li><a href="#a5b-write-skew">A5B Write Skew</a></li><li><a href="#%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB">隔离级别</a></li><li><a href="#%E4%B8%80%E8%87%B4%E6%80%A7">一致性</a></li><li><a href="#%E5%8F%82%E8%80%83">参考</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1&gt;一致性模型概述&lt;/h1&gt;
&lt;p&gt;一致性模型是分布式系统中对数据读写操作顺序和结果的约定。不同的一致性模型定义了在不同情况下系统对数据的一致性保证程度。而其之所以这么重要正是因为其复杂而又直接关系到一个分布式系统的正确性，所以值得被反复讨论。&lt;/p&gt;
&lt;p&gt;在开发单机多线程</summary>
      
    
    
    
    <category term="计算机科学" scheme="https://stan370.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
    <category term="数据库" scheme="https://stan370.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="分布式系统" scheme="https://stan370.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
